{"id":"94111","title":"Grammar-Based Robust Natural Language Processing","abstractText":"'From the late &apos;50s until the early &apos;70s, theoretical linguistics, computational linguistics, and psycholinguistics, were united by a common model based on Chomskian transformational generative grammar formalism. This consensus fell apart in the later 70s, because of disagreements about the role of semantics. Formal syntax has abandoned semantics and any interest in formal constraint. Semantically based functional and cognitive theories of grammar are agnostic about formalism. Current psycholinguistic theories mainly ignore formal linguistic theory, while in computational linguistics, the dominant models are generally low-level finite-state or context-free systems that are known to to be incomplete with respect to the full range of of human language. While the latter methods, aided by machine-learning, have made considerable progress in practical applications such as automatic speech recognition, machine translation, and parsing, they place inherent limits on performance that are already yielding near-asymptotic performance in some applications. The aim of the proposal is to restore grammatical theory to its necessary place in the theory of human language behaviour, by providing a more restricted theory of constructions than others on offer. This formalism is both efficiently parsable, and expressive enough to support semantic interpretation. The project seeks both to establish the explanatory adequacy of the theory in linguistic terms, and to generalize existing treebank-based computational models derived by supervised learning methods. It uses unsupervised and semi-supervised methods based on unlabeled data. A crucial component will be a fully articulated Natural Semantics closely related to the surface grammar, supporting entailment directly.'","grantUrl":"","grantId":"249520","fundValue":"1910998","fundStart":"2010-06-01","fundEnd":"2015-05-31","dataset":"fp7"}