{"id":"22D1CDC6-8AAE-4D7C-82AC-305ADB35537D","title":"Imperfect data: accuracy, impacts and extraction of meaningful information","abstractText":"Meaningful information is a fundamental requirement for informed, logical and reasoned activity. Extracting meaningful information from data can, however, be a challenge, especially given problems that data may, amongst other things, be inaccurate, incomplete, and possibly contradictory as arise from a variety of sources of variable quality and trust level. \n\nData imperfections are a generic problem in information extraction and decision making and so the work is relevant in many disciplines. Imperfect data are, for example, evident in medical diagnosis (e.g. a patient's test results are typically only an imperfect indicator of a condition), in defining nature reserves for species conservation (e.g. the species distribution maps and models are often highly sensitive to 'absence' data - was the species actually present but not observed?) and in security and defence applications (e.g. sub-pixel target detection algorithms applied to surveillance imagery vary in performance and utility between environments). Some problems with imperfect data were recently highly apparent in relation to the response to the Haiti earthquake of 2010, especially in relation to damage mapping to inform relief activities. Vast amounts of well-intentioned assistance was provided by numerous professional and amateur bodies with unprecedented data rates but the volumes of data and the problems with them were a concerns. Key problems were that maps were inaccurate, inconsistent and sometimes contradictory. As such a major mapping challenges arises in how to work with such data. One key issue is the need for information on the accuracy of data sources and methods to help use imperfect data. This project seeks to contribute to this task. It aims to illustrate the impacts of using imperfect data, explore methods to characterise the quality of the data and methods to combine data sources to yield an enhanced product of known accuracy.\n\nA range of methods will be used but the core focus is on the use of latent class modelling. This type of analysis is based on multiple observations or data from a variety of sources. The relationships between the observers/data sources are used to attempt to explain their quality and suggest how the data could be interpreted to yield information. The approach is a form of statistical modelling and is highly attractive for the specific research proposal because if a model can be formed that fits the observed data, then model's parameters define the accuracy of the data sources and its outputs can be used to form new products of known accuracy. As such the modelling analysis may add value to data by indicating its quality and combining it usefully for extraction of information.\n\nAs the problems of imperfect data are generic the proposal has broad potential impacts. For the specific DaISy call there are clear impacts in relation to security and defence. For example methods that enable rapid and qualified information to be derived from sources of variable accuracy, completeness and trust level will increase effectiveness and the quality of decision making. Additionally as a model based approach it removes/reduces the need for reference data to be acquired for validation which could otherwise require deployment of personnel to dangerous locations and so of considerable benefit to health and well-being.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/J020230/1","grantId":"EP/J020230/1","fundValue":"69249","fundStart":"2012-05-04","fundEnd":"2013-07-31","funder":"EPSRC","impactText":"  The outputs have only recently been published - but already attracting citations. Too early to say more.  ","person":"Giles  Foody","coPersons":[],"organisation":"University of Nottingham","findingsText":" The key finding is that a set of imperfect data sets on the same issue may be used to produced refined and relatively accurate estimates. This is perhaps most useful in crowdsourcing - a set of annotators may each provide labels to a set of objects. Each annotator may be inaccurate but from the data alone can get a guide to what the actual labels are. Can also get a guide to the quality of each annotator. \n\nThe project did not proceed exactly as planned but did reveal the key issue which was the value of latent class modelling when dealing with imperfect data. Could help web based crowdsourcing projects. Am working with some at the moment to see if the methods can be used. Environment,Other","dataset":"gtr"}