{"id":"EAD5B8AA-2B5C-4527-A040-CDDF17A3EFC1","title":"Understanding age-related changes in processing facial emotion","abstractText":"It is estimated that, by 2060, one quarter of the British population will be over 65, many of whom may still be working. The brain ages as dramatically as the body over a lifetime, but despite this the functional consequences of brain aging are not understood. While we can all identify the appearance cognitive deficits related to age and illness, current research suggests that maintained cognitive performance masks massive re-arrangement, and reorganizing of cortical processes. \nCognitive aging manifests itself damagingly in the decline of the basic and essential task of interpreting social signals. Research has established that ageing adults show specific differences in the emotional interpretation of facial expressions, particularly anger. Differences in perception of emotion can have a drastic impact on everyday social interactions and decision-making. Failure to accurately interpret social signals may lead to vulnerabilities in identifying deception and in predicting the behavioural intentions of others. \nOur first step in understanding aging adults vulnerabilities in emotion perception, will be to accurately characterize how the aging brain perceives emotion. While it is widely acknowledged that facial and bodily biological motion carry important information for categorizing social signals, most research on the cortical representation of faces and bodies has been done with static images. Thanks to recent developments in 4-D graphics, we have become able to investigate the way the brain extracts relevant information from rapidly changing dynamic cues. Our research will first investigate the processing of key social signals, emotionally expressive faces, using newly developed state-of-the-art realistic 4-D dynamic face stimuli with tightly controlled motion parameters. Combining eye tracking and random variation in the parameters, we will first establish which of these parameters contain the crucial emotion information that older adults rely on when categorizing realistic faces.\nWe know that cortical regions interact with each other on a fast, millisecond time scale, forming relatively specialized networks. An important hypothesis is that, with aging, the specialized network loose function and other brain regions get recruited to compensate. We will test this hypothesis by characterizing the cortical network that encodes and integrates rapidly changing motion parameters in facial expressions. For this, we will use the time-resolved brain signal (magnetoencephalograpy, or MEG). From the signal we will estimate both when and where motion information is encoded in the cortex. We have a working hypothesis based on previous work that different oscillatory bands in the brain code different face features (a bit like different frequencies code different radio programmes). This is known as multiplexing. To quantify precisely which aspects of the signal are carrying information about the diagnostic features of facial motion, we will use a powerful and general method for measuring how much information one signal carries about a second. the mutual information framework. We will record MEG data from three groups of older participants 20-35, 40-55, and 60-75 years old. \nWe expect the older participants to show different strategies of encoding based on cortical slowing, and anticipate that older participants recruit both more and different brain areas to perform some specialized cortical tasks, at the same level of competence as younger participants.\nOur research will give us insight into the fundamental coding schemes of the cortex and it will also give insight into the adaptive strategies available to the older brain: For example, do older adults require the recruitment of more brain areas, that are usually involved in tasks other than specialized computation of facial information? Finally, we anticipate that the cortical strategies older participants use may be predictable from general changes within the brain.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=BB/J018929/1","grantId":"BB/J018929/1","fundValue":"355508","fundStart":"2012-09-01","fundEnd":"2015-08-31","funder":"BBSRC","impactText":"","person":"Philippe Georges Schyns","coPersons":["Guillaume Alexis Rousselet"],"organisation":"University of Glasgow","findingsText":"","dataset":"gtr"}