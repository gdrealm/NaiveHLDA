{"id":"F0F8F872-18D2-451A-A960-0B03B77BABA5","title":"Bayesian Inference for Big Data with Stochastic Gradient Markov Chain Monte Carlo","abstractText":"We are in the midst of an information revolution, where advances in science and technology, as well as the day-to-day operation of successful organisations and businesses, are increasingly reliant on the analyses of data. Driving these advances is a deluge of data, which is far outstripping the increase in computational power available. The importance of managing, analysing, and deriving useful understanding from such large scale data is highlighted by high-profile reports by McKinsey and The Economist as well as other outlets, and by the EPSRC's recent ICT priority of &quot;Towards an Intelligent Information Infrastructure&quot;.\n\nBayesian analysis is one of the most successful family of methods for analysing data, and one now widely adopted in the statistical sciences as well as in AI technologies like machine learning. The Bayesian approach offers a number of attractive advantages over other methods: flexibility in constructing complex models from simple parts; fully coherent inferences from data; natural incorporation of prior knowledge; explicit modelling assumptions; precise reasoning of uncertainties over model order and parameters; and protection against overfitting. \n\nOn the other hand, there is a general perception that they can be too slow to be practically useful on big data sets. This is because exact Bayesian computations are typically intractable, so a range of more practical approximate algorithms are needed, including variational approximations, sequential Monte Carlo (SMC) and Markov chain Monte Carlo (MCMC). MCMC methods arguably form the most popular class of Bayesian computational techniques, due to their flexibility, general applicability and asymptotic exactness. Unfortunately, MCMC methods do not scale well to big data sets, since they require many iterations to reduce Monte Carlo noise, and each iteration already involves an expensive sweep through the whole data set.\n\nIn this project we propose to develop the theoretical foundations for a new class of MCMC inference procedures that can scale to billions of data items, thus unlocking the strengths of Bayesian methods for big data. The basic idea is to use a small subset of the data during each parameter update iteration of the algorithm, so that many iterations can be performed cheaply. This introduces excess stochasticity in the algorithm, which can be controlled by annealing the update step sizes towards zero as the number of iterations increases. The resulting algorithm is a cross between an MCMC and a stochastic optimization algorithm. An initial exploration of this procedure, which we call stochastic gradient Langevin dynamics (SGLD), was initiated by us recently (Welling and Teh, ICML 2011). \n\nOur proposal is to lay the mathematical foundations for understanding the theoretical properties of such stochastic MCMC algorithms, and to build on these foundations to develop more sophisticated algorithms. We aim to understand the conditions under which the algorithm is guaranteed to converge, and the type and speed of convergence. Using this understanding, we aim to develop algorithmic extensions and generalizations with better convergence properties, including preconditioning, adaptive and Riemannian methods, Hamiltonian Monte Carlo methods, Online Bayesian learning methods, and approximate methods with large step sizes. These algorithms will be empirically validated on real world problems, including large scale data analysis problems for text processing and collaborative filtering which are standard problems in machine learning, and large scale data from ID Analytics, a partner company interested in detecting identity theft and fraud.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/K009362/1","grantId":"EP/K009362/1","fundValue":"200070","fundStart":"2013-08-01","fundEnd":"2016-07-31","funder":"EPSRC","impactText":"","person":"Yee Whye Teh","coPersons":[],"organisation":"University of Oxford","findingsText":" We are on track in terms of meeting original objectives.\n\nThe major question we set out to investigate on the first phase of this grant is on the theoretical foundations of stochastic gradient MCMC methods for Bayesian inference on Big Data problems. A first answer is in a recent preprint (Teh, Thiery, Vollmer 2014), which has been submitted to the Journal of Machine Learning Research (JMLR), the top journal in machine learning. \n\nWe showed that SGLD is indeed a consistent method, and developed a central limit theorem which indicates that the rate of convergence is O(m^{-1/3}) where m is the number of iterations of the algorithm. This is slower than standard Monte Carlo convergence rates of O(m^{-1/2}), and is due to the decreasing step sizes of SGLD. We are following this result up with a finite time analysis of SGLD to shed light on the behaviour of the algorithm in the non-asymptotic regime. Initial results are positive, and based on this analysis we have also developed a modification of SGLD which better matches the Euler-Maruyama discretization scheme that the algorithm is based on.\n\nWe have published an extension of SGLD (Patterson and Teh) taking into account Riemannian manifold structure of probabilistic models at Neural Information Processing Systems 2013, the premier international conference in machine learning. This allowed SGLD type inference algorithms to be applicable to a large class of models defined over probability simplices.\n\nWe have also started developing methods for Bayesian inference for Big Data using distributed and parallel computing architectures. This culminated in two recent papers (Xu et al and Paige et al) at NIPS 2014.\n\nIn addition a number of side projects investigated computational methods based on sequential Monte Carlo and Markov chain Monte Carlo and been published/in review as well. Development of Bayesian inference algorithms that are scalable are hugely important in scaling up the powerful methods for data analysis based on Bayesian statistics to the age of Big Data. The project partners held a project meeting in August 2014, and we are currently preparing an invited letter to the President's Newsletter of the International Society for Bayesian Analysis reporting on the progress we have made on the project.\n\nA number of research groups around the world have built on our work and developed a number of sophisticated extensions. This includes the stochastic gradient Hamilitonian Monte Carlo method (Chen et al ICML 2014) and the stochastic gradient thermostat (Ding et al NIPS 2014). Digital/Communication/Information Technologies (including Software)","dataset":"gtr"}