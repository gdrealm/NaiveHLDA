{"id":"657E1CF4-E426-444F-B55A-8B0BFDB834EB","title":"Hierarchical Analysis of Unit Nonresponse in Sample Surveys","abstractText":"<p>Nonresponse is a major problem facing research in the social sciences. Response rates in many surveys have been falling, both in the UK and elsewhere. This project aims to improve understanding of response and possible adjustments to data in surveys with a hierarchical structure, hence informing efforts of survey practitioners to increase response rates and reduce nonresponse bias, and to advance methodology for adjusting for nonresponse. In particular, the project will expand knowledge about the determinants of response in multistage surveys and the impact of interviewers on response rates. The research will be organised into four sub-projects which will: 1) develop models for nonresponse in multistage surveys, 2) analyse the effects of interviewers in surveys, 3) improve models for non-response that use data collected on the calling patterns of interviewers, and 4) develop post-survey adjustment methods for non-response with hierarchical survey data. </p>\n\n<p>The research will exploit several unique databases in which linkage of data from several sources to both respondents and non-respondents has been achieved, including the 2001 UK Survey Nonresponse Census Link database. Experience from other countries will be taken into account through the use of expert international consultants from the US and the Netherlands. Dissemination will include a short course and an international research symposium on nonresponse.</p>","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/E017150/1","grantId":"ES/E017150/1","fundValue":"473876","fundStart":"2007-09-01","fundEnd":"2011-02-28","funder":"ESRC","impactText":"  A full impact report was submitted to ESRC and is available on request. \n\nThe research findings and scientific impacts all have wide ranging implications for survey practice. Methods to reduce nonresponse and to mitigate its effects on data analysis are of relevance to any survey researcher, social scientist and data analyst concerned with nonresponse in their data. Economic and societal impact therefore has to be seen in terms of returns to improvements in the quality and efficiency of sample surveys.\n\nMore specifically: \n1. Models developed for the analysis of hierarchical survey data have informed survey practice about key predictors of nonresponse, both of contact and refusal, and helped to gain a better understanding of the processes of nonresponse. \n2. Analysis of interviewer effects has provided guidance to survey practitioners on training, recruitment and allocation of interviewers to sample members. \n3. Research on call record data has informed survey practice when and how best to call to reduce non-contacts and refusals. It has provided guidance on efficient and effective interviewer calling behaviours. The research findings will help to improve survey design processes and will impact on the use and implementation of responsive survey designs with wide ranging implications for cost savings and efficiency increases. \n4. Research on the adjustment of nonresponse, evaluation and comparison of existing weighting methods and the development of new methods for the case of hierarchical nonresponse can be used in survey practice to mitigate the negative impacts of nonresponse after data collection. Government, Democracy and Justice Societal,Policy & public services","person":"Gabriele B. Durrant","coPersons":["Chris  Skinner","John  Micklewright","Fiona Alison Steele"],"organisation":"University of Southampton","findingsText":" The project was organised into four subprojects and the findings are reported for each: \n\nAnalysis of Nonresponse\nThe findings in Durrant and Steele (2009) indicate a systematic correlation between different types of non-response and socio-economic and demographic household characteristics. A comparison of the results for refusal and non-contact revealed two quite distinct nonresponse processes. The modelling was guided by current conceptual frameworks and the findings supported some of the theories. \n\nThis work was extended by Steele and Durrant (2011) to investigate how best to model different types of nonresponse. A multilevel extension of a sample selection model to allow for both interviewer effects and dependency between noncontact and refusal rates was proposed. After controlling for household characteristics, there is little evidence, however, of correlation between the unobserved characteristics affecting noncontact and refusal propensities. Results from a multinomial and a sequential model were surprisingly similar, due to noncontact and refusal having largely different predictors.\n\nInterviewer Effects\nDurrant et al. (2010) found empirical support for several key mechanisms through which interviewers affect survey cooperation rates. These include significant effects of pay grade, experience, interviewer confidence and attitudes. There was some evidence that similarity in attributes of interviewers and sample members tends to produce higher cooperation rates. The research identifies practical implications for the field, for example regarding interviewer training and allocation of interviewers to sample units. Once other factors were controlled, area effects were no longer significant. \n\nUsing Call Record Data to Inform Interviewer Practices\nThe results in Durrant et al. (2011a, 2011b) suggest that the best times to call depend on household characteristics, especially markers for at home patterns. Call record information plays a key role in predicting the outcome of the next call. Characteristics of the interaction process between the interviewer and the householder were of particular relevance. There is substantial evidence that interviewer observations about a household are useful for predicting best times of contact and may be recommended as a standard tool to obtain information about potential nonrespondents and to guide calling and interviewing strategies. This information can also contribute to the tailoring of contact and interviewing strategies to particular sample units.\n\nAdjustment of nonresponse\nMicklewright et al. (2011) focus on the relationship between nonresponse rates and bias in the PISA surveys for England. Clear evidence of biases was found in the 2003 survey, but no indication that the slightly higher response rates in the 2000 survey were associated with higher quality data, which underlines the danger of using response rate thresholds as a guide to data quality. Various weighting methods to adjust for non-response bias were considered. A weighting approach employing the generalized regression estimator performed most promisingly.\n\nSkinner and D'Arrigo (2011) use the multilevel modelling approaches explored earlier to investigate weighting methods under correlated nonresponse within clusters. It is shown that response propensity weights based on a marginal model and weights based on predicted random effects can lead to bias but that a new method based upon conditional logistic regression can avoid this bias. The research will inform future work on nonresponse, interviewer effects and the use of paradata, in particular call record data. Government, Democracy and Justice","dataset":"gtr"}