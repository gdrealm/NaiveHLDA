{"id":"C905D2E0-3381-4086-93CD-E79ABF8501C1","title":"Neural Representation of the Identities and Expressions of Human Faces","abstractText":"<p>Although a person's facial identity is immutable, faces are dynamic and undergo complex movements which signal critical social cues (viewpoint, eye gaze, speech movements, expressions of emotion and pain).&nbsp; These movements can confuse automated systems, yet humans recognise moving faces robustly.</p>\n\n<p>Our objective is to discover the stimulus information, neural representations and computational mechanisms that the human brain uses when recognising social categories from moving faces. We will use human brain imaging to put an existing theory to the test. This theory proposes that recognition of changeable attributes (eg, expression) and facial identity are each recognised separately by two different brain pathways, each in a different part of the temporal lobe of the brain.</p>\n\n<p>The evidence we provide might indeed support and fill in many gaps in this theory. Nevertheless, we expect instead to instantiate a new alternative theory. By this new theory, some brain areas can recognise both identities and expressions, using unified representations, with one of the two pathways specialised for representing movement. Thus, the successful completion of our project will provide a new theoretical framework sufficient to motivate improved automated visual systems and advance new directions of research on human social perception. </p>","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/I01134X/1","grantId":"ES/I01134X/1","fundValue":"257980","fundStart":"2011-09-26","fundEnd":"2014-06-30","funder":"ESRC","impactText":"","person":"Nicholas  Furl","coPersons":["Andrew  Calder","Richard  Henson","Karl John Friston"],"organisation":"MRC Centre Cambridge","findingsText":" In a recent Journal of Neuroscience paper, we analyzed functional magnetic resonance images of the brains of macaque monkeys to measure their brain responses while they viewed dynamic and static facial expressions and various other pictures. We found areas in their brains that were sensitive to motion and these areas also signaled the facial expression being viewed, whether the expression was moving or static. We also found areas that were sensitive to faces versus other pictures, but these areas signaled less information about expressions. Most theories assume that these latter, face-selective areas are primarily responsible for coding information about faces. Our results show that areas responsing to motion are also important for representing information about facial categories such as expressions. \n\n\n\nSee:\n\nFurl N*, Hadj-Bouziane F*, Liu N, Averbeck BB, Ungerleider LG. 2012. Dynamic and static facial expressions decoded from motion-sensitive areas in the macaque monkey. J Neurosci 32:15953-62. *co-first authors\n\n\n\nA second study is now in press at the journal Cerebral Cortex. Here, we analyzed a large dataset of magnetoencephalographic (MEG) scans of healthy human participants. MEG allows us to measure the rhythmic activity of brain cells, known as oscillatory activity. This way, we could map how much oscillatory power was associated with faster or slower rhythms. We formulated a large set of computational models to predict these data. Different models simulated different hypothetical ways that face-selective areas in the brain could be connected. We then found the connectivity that most accurately and parsomoniously predicted the MEG data. The best model conformed to a popular theory: there were two pathways in the human temporal lobe which operated independently and both pathways were connected in a feedforward manner. Most importantly, we were able to visualise complex computations used by these pathways. These computations were revealed by complex transformations in the pattern of brain oscillations when one area communicates with another. This finding not only confirms a prevailing theory of face perception, but also offers a new method for studying brain computations. This method may be applied to studying disorders such as schizophrenia, which are typified by abnormal oscillatory communication between brain areas.\n\n\n\nSee:\n\nFurl N, Coppola R, Averbeck BB, Weinberger D. 2013. Cross-frequency power coupling among hierarchically-organized face-selective areas. Cerebral Cortex. In Press. As mentioned above, our research has applications in developing artificial visual recognition systems for video information as well as developing clinical models of brain disorders. These studies suggest ways that abstract visual information can be coded by neurons as well as the computations these neurons perform when coding. This knowledge can be used to devise and improve artificial visual recognition systems. Particularly, our results using dynamic facial stimuli can help develop software which can visually recognise video. Our research using the macaque monkey will help develop animal models of visual function.Our research on oscillatory communication between brain regions is a first step towards developing sophisticated models of disorders such as schizophrenia. Education","dataset":"gtr"}