{"id":"FA9903DD-FE9A-4DC9-ADA6-AED74CF674B7","title":"An Integrated Audio-Symbolic Model of Music Similarity","abstractText":"Similarity is a central aspect of music. It can help as a benchmark for testing theories of music perception and cognition, it is useful to answer for practical applications, such as music retrieval and recommendation, and it is an overarching question that relates to many aspects of music. However, theories of musical similarity have mostly focused on symbolic representations, where musical structures such as melodic and harmonic development are addressed but the aspects or expressive performance, such as micro-timing and timbre are ignored. On the other hand, audio based models, typically distances based on audio features, can capture details of the performance such as timbre, dynamics and tempo changes, but little of the musical structure as it unfolds over time.\n\nRecent progress in audio transcription and alignment and the availability of music analysis tools for music collections with audio and symbolic content, which are being developed in the Digital Music Lab (DML) project, are changing the landscape of research in music. Large datasets of acoustic and symbolic music data that are generated or unveiled through the DML and &quot;Optical Music Recognition from Multiple Sources&quot; Big Data projects encourage an approach that can combine symbolic and audio based analyses into a joint similarity mode. This opens a great potential to new tools for research in music information retrieval and musicology, as the interaction between symbolic structure and acoustic information such as timbral texture has rarely been addressed and it could reveal aspects that have been unnoticed or unexplained so far. If successful, it might contribute to breaking the glass ceiling in music recommendation. \n\nThe aim of this project is to develop an initial framework and conduct experiments on an integration of symbolic melodic and structural similarity models with audio based models. The models ability to capture various notions of similarity will be evaluated on cultural information in music collections (e.g. genre, style, composer) as well as user annotations or ratings of similarity. This work will build on the experience of the participants in modelling audio similarity (Wolff &amp; Weyde 2013), audio transcription and the integration of symbolic and audio based models (Benetos, Ewert &amp; Weyde 2014), symbolic melodic similarity (Marsden 2012) and probabilistic music and performance modelling (Spiro, Gold &amp; Rink 2010, Abdallah et al 2012).","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=AH/M002454/1","grantId":"AH/M002454/1","fundValue":"61570","fundStart":"2014-09-01","fundEnd":"2015-10-31","funder":"AHRC","impactText":"","person":"Tillman Erik Weyde","coPersons":["Emmanouil  Benetos","Daniel  Wolff","Nicolas  Gold","Alan Alexander Marsden"],"organisation":"City University London","findingsText":"","dataset":"gtr"}