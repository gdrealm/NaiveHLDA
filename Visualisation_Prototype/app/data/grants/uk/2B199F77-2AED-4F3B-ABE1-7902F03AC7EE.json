{"id":"2B199F77-2AED-4F3B-ABE1-7902F03AC7EE","title":"Planning an Argument","abstractText":"While in the past machines waited passively for our commands, we are moving to a future where humans and machines work in partnership, where machines are proactive and guide humans' activities (coined Human-Agent Collectives in the ongoing EPSRC project EP/I011587/1). A key challenge is how to allow humans to engage with these machines (which may be software systems or robots) in order to understand and engage with the decisions the machines take. These machines must be able to justify their choices and explain why a particular course of action is appropriate, and humans must be able to challenge these justifications and input into the machine's decision making process. Argument dialogues are an established approach to managing such interactions; they provide a principled way of structuring rational interactions between participants (machines or human) who may, e.g., assert arguments, beliefs and preferences, and question or challenge one another's assertions. A key benefit of argument dialogues is that they provide a familiar mechanism through which a human can engage with a machine's reasoning.\n\nWhen a machine engages in an argument dialogue it must determine which of the available speech acts to make in order to try and achieve its dialogue goals, this is called its argument dialogue strategy. This proposal addresses the important open problem of how to generate an argument dialogue strategy, by leveraging the results of many years of automated planning research. Automated planning is one of the most well developed sub-fields of artificial intelligence and focuses on developing efficient and general approaches to determine which actions to perform in order to achieve some goal. This is exactly the problem we must solve in order to generate argument dialogue strategies, where the actions are the communicative speech acts and the goals typically refer to social constructs or commitments rather than physical states of the world. \n\nIn order to apply automated planning techniques to generate an argument dialogue strategy, we must represent our argument dialogue strategy generation problem in a language that automated planners can understand; one of the main contributions of this work will be a set of implemented translations that take an argument dialogue strategy generation problem and output a planning problem (represented in a standard planning language), which can then be solved by an existing automated planner. This will provide the first general approach to generating argument dialogue strategies that is not tied to a particular type of dialogue (e.g., persuasion or negotiation) and does not assume the strategiser has knowledge of its interlocutor's dialogue strategy.\n\nOur objectives are: \n\nO1: Define a general framework for representing an argument dialogue strategy generation problem (DSP). \nO2: Develop a set of benchmark DSPs, represented in the framework of O1, on which to evaluate our approach. This will include DSPs developed using real clinical knowledge.\nO3: For each of two specified classes of DSPs (distinguished by the certainty of the beliefs the strategiser has about its interlocutor), formally define and implement translations that map from a DSP of that class to a planning problem defined in a standard planning language.\nO4: Evaluate existing planning algorithms for solving the planning problems that result from applying the translations of O3 to the benchmark DSPs of O2, identifying the limitations of existing planning algorithms for solving the benchmark DSPs.\n\nThis work will allow humans to engage with and understand a machine's decision making process, which is crucial if we are to trust machines to take decisions for us. In this 14 month project we focus particularly on healthcare applications but the potential applications are wide ranging, including robots that do dangerous tasks and smart homes that manage our domestic life.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/M01892X/1","grantId":"EP/M01892X/1","fundValue":"98726","fundStart":"2015-05-26","fundEnd":"2016-10-25","funder":"EPSRC","impactText":"","person":"Elizabeth  Black","coPersons":[],"organisation":"King's College London","findingsText":"","dataset":"gtr"}