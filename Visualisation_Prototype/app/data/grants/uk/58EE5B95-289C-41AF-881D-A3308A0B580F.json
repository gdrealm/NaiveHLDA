{"id":"58EE5B95-289C-41AF-881D-A3308A0B580F","title":"Enhanced Acoustic Modelling for Auralisation using Hybrid Boundary Integral Methods","abstractText":"This project will develop a new acoustic modelling method, ideally suited for simulation of rooms and city squares, which will outperform existing methods either in its accuracy or computational efficiency. Developing such an algorithm is a particular concern for practitioners who use auralisation as a consultation tool in acoustic design of built spaces. In this process the data from the simulation model is rendered as sound by a loudspeaker system allowing a client or stakeholder, who is unlikely to be an expert in acoustics, to form a judgement on whether the acoustic design fits their needs. This process is of course only valid if the acoustic model delivers accurate prediction of how sound behaves in the space, and current commercial software does not always succeed in this task because the high-frequency geometric propagation assumption on which it is based breaks down at low frequencies and in spaces where diffraction effects are significant. Although alternate numerical methods exist they are typically limited to modelling only low frequencies since their computational cost becomes impractical as frequency or time-resolution is increased. In response to these shortcomings, this project will develop a new hybrid method which combines the best features of geometric methods and fully numerical boundary element method (BEM) solvers to provide a scheme that inherits desirable characteristics from both approaches; i.e. fully error controllable schemes, more accurate than geometric methods for low to mid range frequencies, but with reduced computational cost at higher frequencies compared to standard BEM, all achieved within a single unified framework. Such a model would potentially include all wave terms, geometric and diffracted, but lower energy reflections would only be included where necessary to achieve a given accuracy criterion (e.g. an SPL threshold or a function of the ear's perceptible difference limen) hence computational efficiency would be maximised.\n\nIntroducing an element of interactivity to the auralisation process, where a user would be able to explore the space and/or make dynamic changes to the sources and building geometry or materials, would be desirable from a consultation-productivity perspective but place extremely high demands on the acoustic model. Not only must the model dynamically update to reflect the modifications made by the user, but the requirement for accuracy is even more pressing since any feature the client chooses to introduce must be accurately rendered, even if it has a strong acoustic effect (e.g. concave focussing surfaces, room resonances, unusual echo patterns), and there will be little or no opportunity for an expert to check that the sound is realistic. The new algorithm we propose will address these needs since, as well as having improved accuracy, it also has the desirable characteristic that only a small easily identified subset of the acoustic interaction data needs to be re-computed when a change in building geometry or source location occurs; incorporating support for modelling time variant and interactive scenarios would hence be relatively straightforward. Towards this goal the project will also develop a new auralisation orientated audio platform which will represent acoustic interactions by a network of digital filters and output sound direct to audio hardware, and the simulation algorithm will be geared towards outputting reduced acoustic models in this format. Pilot studies will investigate how interactivity might be supported, as dynamic modifications of scenario objects and corresponding filter network elements, and how standard lumped parameter sound insulation and stochastic reverberation models may be incorporated. The project will conclude with a work package dedicated to modelling some real-world scenarios which would cause difficulties for current acoustic modelling software.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/J022071/1","grantId":"EP/J022071/1","fundValue":"249719","fundStart":"2012-10-01","fundEnd":"2015-09-30","funder":"EPSRC","impactText":"","person":"Yiu Wai Lam","coPersons":[],"organisation":"University of Salford","findingsText":"","dataset":"gtr"}