{"id":"3F11A446-846B-444F-A591-691D936958D9","title":"The Birth, Life and Death of Semantic Mutants","abstractText":"Traditional Mutation Testing produces test cases that distinguish between some description N and variants of it. Each variant is produced by applying a mutation operator to N. A test set that is good at distinguishing N from variants of N is likely to be good at finding faults that are similar to applications of the mutation operators. Mutation testing was originally applied to programs but more recently it has been applied to other forms of descriptions such as specifications. Mutants are produced through the application of mutation operators, each of which may be applied to a relevant point in a program in order to produce a mutant. The mutation operators carry out small syntactic changes. For example, + might be replaced by -, &gt; might be replaced by &gt;=, a variable in an expression may be replaced by a constant, or part of an expression may be deleted. The mutation operators are designed to represent syntactically small errors. Typically, mutants are used to either judge the adequacy of a test set (does it distinguish between N and its mutants?) and also to drive test generation (we want a test set that distinguishes between N and its mutants).Traditional mutation testing produces mutants that represent small slips or mistakes in programming and thus represent a class of faults. A mutant program differs from the program under test by a small syntactic change (e.g. a / replaces a * ). However, real developers will also suffer from misunderstandings, especially when moving between description notations. They misapprehend the semantics of the description before them. They may, for example, import their understanding from a previously used programming language, or else from an understanding of how a particular tool interprets the notation. We believe that a semantically oriented mutation testing approach may assist in the discovery of such problems. We seek to show that a semantically oriented mutation testing approach is feasible and can find faults not found by traditional syntactic mutation (and likely, by other popular testing strategies).Misunderstanding the semantics of descriptive notations is a common source of problems in software development. We believe that these misunderstandings can be represented as semantic mutants over descriptions and that test data produced to kill semantic mutants is effective at finding faults caused by such misunderstandings: It will often find faults that are typically missed by test sets produced by extant testing strategies (and in particular, by test sets that are produced to kill traditional syntactic mutants). We also believe that he production of semantic mutants and the generation of test data to kill them can be automated.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/G043604/1","grantId":"EP/G043604/1","fundValue":"136252","fundStart":"2009-10-01","fundEnd":"2013-09-30","funder":"EPSRC","impactText":"  They are beginning to be used. We have used our research on mutation testing and presented to MoD and also as part of a proposal to DSTL. The application is multi-core. This is currently under negotiation. We were allowed by the EPSRC to charge to the grant for an extra 6 months (up to March 2014) to allow development of a mutation tool for multicore. It is this that forms part of our current bid. We may be able to provide an update on this matter (but not in the 2014 outcomes window). Aerospace, Defence and Marine Economic","person":"John Andrew Clark","coPersons":["Manuel Yves Oriol","Robert David Alexander"],"organisation":"University of York","findingsText":" Our work has concerned mutation testing. Suppose someone asked you to test a software system with the aim of discovering errors. You would supply it with inputs and judge whether the system behaved as expected, i.e. gave the 'right' outputs. But how would they know you had made a good fist of testing it - that the testing was sufficiently thorough? One way is to inject (one at a time) different faults into a system (i.e. make small syntactic code changes) and see whether the system with a fault injected into it behaves differently to the original system when subjected to your suite of tests. \n\nIf your test suite has at least one test that gives different behaviours then it has 'killed' the mutant. If an injected fault goes undetected by all tests, then it is said to be'live'. Live mutants either indicate that the injected fault is actually semantically the same as the original, or else your test suite just isn't thorough enough to discover it. If the latter you might usefully consider generating an additional test that can distinguish the original and mutant systems.\n\nHowever, all mutant fault injection to date is syntactic - it aims by and large to discover programmer 'slips'. However, faults may be more subtle. In particular faults in a system may arise when two users simply have different interpretations of what the code or design actually represents. This may arise simply because the underpinning programmign languages are semantically ambiguous. \n\nWe have developed a prototype fault injection engine that aims to target those parts of a program or design that might prove problematic. Test can be generated to target those. \n\nWe have also developed test data generation technqiues based ion operations research based optimisation texchnqiues, that allows efficient mutant killing test data generation startegies to be discovered. Using a form of evolutionary computation we can 'home in' on highly effective test data generations strategies. \n\nThus, in collaboration with our project partner at Brunel, we are able to generate new forms of mutant to give a radically different yardstick for test thoroughness and we have potentially very strong methods of generatign test data to kill mutants (whether syntactic or semantic). Yes. The principles of our underpinning work leading to the journal paper Semantic Mutation Testing; can be extended to other systems and other notations. Although published in 2013, the paper has already attracted a fair amount of academic interest and citations. It represents both a novel contribution to mutation testing itself, but also clearly has practical applications. (In fact, the grant proposal was actually motivated by significantly practical concerns.) \n\nWe would hope that the ideas of mutation testing, semantic mutation testing and automated test data generation for mutation testign in teh context of multi-core systems will prove a promising route to impact. Multi-core systems will find application everywhere but we believe there are significant issues faced by the defence sector that makes that sector in real need of assistance. However, any modern software is likely to have to run on a multi-core chip (and so we identify IT as an exploitation sector too). Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software)","dataset":"gtr"}