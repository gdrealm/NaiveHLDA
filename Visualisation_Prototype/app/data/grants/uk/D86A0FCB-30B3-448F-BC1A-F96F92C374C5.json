{"id":"D86A0FCB-30B3-448F-BC1A-F96F92C374C5","title":"Motor contributions to the perception of facial expressions","abstractText":"<p>This project seeks to understand the psychological mechanisms that allow us to interpret the facial expressions of others. Facial expressions provide a wealth of information about our social environment, making accurate perception essential. Convergent experiments will determine whether knowledge of how we perform facial expressions improves our ability to perceive the expressions we observe.</p>\n\n<p>First, neuroimaging will be used to study the patterns of brain activation when people view facial expressions. By analysing how those patterns change over time, it is possible to estimate the amount of information flowing from ‘motor’ areas responsible for performing expressions, to visual areas responsible for expression recognition.</p>\n\n<p>The second work package studies a phenomenon known as ‘adaptation’; a process whereby the mechanisms responsible for expression recognition ‘recalibrate’ following prolonged visual exposure to a particular expression. The experiments proposed in this package will determine whether repeated expression performance can elicit similar recalibration.</p>\n\n<p>&nbsp;</p>\n\n<p>The third work package will determine whether training people with clinically impaired expression recognition to perform particular expressions improves their visual recognition of the trained expressions. If performance expertise contributes to visual perception, perfecting expression execution should improve visual expression recognition.</p>","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/K008226/1","grantId":"ES/K008226/1","fundValue":"246233","fundStart":"2013-11-01","fundEnd":"2015-10-31","funder":"ESRC","impactText":"","person":"Richard  Cook","coPersons":[],"organisation":"City University London","findingsText":"","dataset":"gtr"}