{"id":"AF95F820-C55B-460E-8AF8-7247BB25F1A6","title":"Body Shape Recognition for Online Fashion","abstractText":"We are proposing to develop an online tool that will give potential benefit to many, allowing an untrained user to realise their body size and shape, from their own home, using a standard digital camera/webcam. At present, the majority of body scanning technologies deployed in retail environments are expensive and require dedicated technical support, confining their use to high-end department stores and specialist sports retailers. The fashion, social and economic benefits that body scanning offers are therefore inaccessible to the majority of the general public. This project aims to exploit low cost webcam/cameras to reformat this technology into a service that isn't reliant upon specialist hardware, and to reprogram the experience out from the controlled retail environment and into the home.There are both technical and cultural challenges to be addressed before we can achieve our goal and we have created a collaborative partnership to deal with them. Our proposed scanning technology is based upon photogrammetry, a branch of Computer Science that aims to extract 3D information from one or more 2D images. The images are usually taken from known locations with calibrated cameras, however these are two dependencies that we plan to remove from this technology from the outset. If enough prior knowledge about standard body shape, structure and posture is known, both physiological and fashion insights included, a tool can be designed to be more intelligent and less reliant upon resolution or use of multiple views. Through a double-pronged approach that uses innovative Computer Vision techniques to construct an initial model, to refinement by the application of style ontologies and retailer metadata, we aim to create a tool that will offer benefits to consumer, retailer and manufacturer alike. We will work closely with our industry partner to help us define the base requirements of our data capture tool. This will include online clothing brands that also have production interests and are working with Bodymetrics@Selfridges to develop custom fit clothing. The potential for this home sizing tool to enable a wider infrastructure of rapid manufacturing and leaner distribution networks has led us to approach a particular type of retailer that would benefit greatly from a reduction in purchase returns and greater market insights. We plan to develop a prototype for integration within our industry partner's website, we will link to its stock database and our initial trial will aim to size a user group, and recommend them items from the partner's stock. Results will be judged upon the user group's feedback, and the webcam-based tool will be re-specified as new knowledge is gained. Qualitative research will also be undertaken on the user experience arising from using a webcam and solutions will be developed to encourage the user, with possible amendments made to account for cultural differences and perceptions on trust and security. The research offers the potential for the project team to research the user experience, which is a significant contributor to the slow take up to date of scanning technology. The project will help to catalyse the uptake of mass-customisation of garments, which is fundamentally a new business model. In this paradigm, garments are produced 'on-demand' for a particular customer's fit and style preferences. This allows the retailer to obtain monies from customers before the products are produced; a 'reverse' of the standard cash-flow dynamics of retail and establishing a very attractive business model for clothing retailers.The project can also develop the efficiencies of the current business models practised by on-line retailers by helping to 'lower the cost of information'. The method that the project is aiming to pioneer can be seen as an efficient way to 'search for clothes' on-line as it helps to match an individual's body with garments that fit that person.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/I032169/1","grantId":"EP/I032169/1","fundValue":"163387","fundStart":"2011-10-01","fundEnd":"2013-12-30","funder":"EPSRC","impactText":"","person":"Philip  Delamore","coPersons":[],"organisation":"University of the Arts London","findingsText":"","dataset":"gtr"}