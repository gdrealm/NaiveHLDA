{"id":"D2E7AA2C-D7AA-4426-AF96-B63696295607","title":"Dynamically Reconfigurable Hardware Architectures for Context-Based Statistical Compression of Visual and Data Content","abstractText":"The purpose of this work is to investigate algorithms and hardware architectures for context-based statistical lossless compression of visual and data content using dynamically reconfigurable hardware to support optimal modelling strategies for each data and compression type. Entropy coding of the modelling output will be performed using a statically configured arithmetic coding engine. The current trend of network convergence where visual and data content are transmitted along the same physical channel suggests a technology capable of delivering optimal compression ratios and fast adaptation to the nature of the content will become increasingly important. These are the two key concepts that will drive this research effort. Context-based statistical compression differs fundamentally from dictionary-based compression as used in popular algorithms such as the ZIP family and it is recognised as being able to offer superior compression ratios to these. However, this has been only achieved with complex software algorithms that require considerable amounts of memory capacity and have very low throughputs in the range of thousands of CPU cycles per byte. This means that power-hungry Pentium 4 class microprocessors running at GHz rates are needed to provide the required computing power to run these advanced statistical algorithms and even these CPUs will find difficult to support applications such as telemedicine where still images, video and scientific data would require lossless real-time compression with high bandwidths. Other applications such as data, video and image transmission in space require the performance to be achieved in an energy and silicon efficient platform. To achieve the demands set by these applications we propose the first universal lossless compression hardware core combining context-based variable-order statistical modelling and arithmetic coding. At present, there are no practical hardware realisations of these techniques, since no satisfactory solutions have yet been proposed for a viable architecture.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D011639/1","grantId":"EP/D011639/1","fundValue":"166019","fundStart":"2006-02-22","fundEnd":"2009-02-21","funder":"EPSRC","impactText":"  The data compression has been used by different entities such as Intel and the European Space Agency to evaluate the benefits of this new type of algorithms compared with the current versions. A high-speed version is currently being developed to be used in financial computing systems Digital/Communication/Information Technologies (including Software),Electronics,Financial Services, and Management Consultancy Cultural,Societal","person":"Jose Luis Nunez Yanez","coPersons":["Nishan  Canagarajah","David  Bull"],"organisation":"University of Bristol","findingsText":" The project demonstrated a hardware-amenable statistical modelling technique for lossless visual and data compression that combines predictive coding, context-based modelling and arithmetic coding. THe hardware included an universal arithmetic coding engine able to support probability data obtained from both visual and general data modelling engines. \n\n\n\nA dynamic reconfigurable platform that supports both modelling engines and the common entropy coding module.\n\nwas developed. This allow the architecture to change as different data types were being compressed. The resulting system could deliver better compression than current algorithms at a lower energy and area profiles. Data compression is of interest to many commercial organizations. Exploitation routes are being explored. The research was proposed to the European Space Agency that funded farther development trough their innovation triangle initiative. A prototype was built that demonstrated the potential of the technology using standard FPGAs. The results were demonstrated to ESA. A currently ongoing project is using the data compression engines originally developed to demonstrate how the energy of a generic computing system can be lowered by transmitting data in compressed state. A collaboration is on-going with Sydney University exploring how to use this data compression technologies in financial computing applications. Healthcare","dataset":"gtr"}