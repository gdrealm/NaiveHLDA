{"id":"8965EEB5-E625-4361-AB77-AE6B9B1FC015","title":"Generating and using &quot;big data&quot; to identify hearing aid patterns of usage in order to optimise and personalise fitting.","abstractText":"The successful use of a hearing aid depends on many factors. Conventionally, a simple measure is taken of the hearing loss, the audiogram. The aid is then set up automatically using assumptions based on an &quot;average&quot; listener. Finally, fine tuning of the settings is performed mostly by verbal feedback to the clinician from the aid user in response to simulated listening situations, or, on repeat visits to the clinic, on verbal feedback from the user, based on their experience in &quot;real-world&quot; listening environments.\n\nThe &quot;average&quot; listener is a rare commodity. The pattern of hearing loss is nearly unique to each listener as it involves damage accumulated over many years through very different lifestyles. The audiogram is commonly recognised as being insufficient to define that pattern. Additionally, each listener varies in the range of environments from the quiet living room to the loud rock concert in which they expect their hearing aid to operate and restore their hearing to &quot;normal&quot;. Other factors beyond the hearing loss also contribute to the success, or otherwise, of the device. For example, the ability of the brain to make sense of the resulting acoustic input depends on factors such as experience with the acoustic scenario as well as the residual cognitive ability. Cognitive ability declines with a long-term factor such as age and a short-term factor such as fatigue. Personalising a hearing aid to reflect the disabilities, abilities and demands of the wearer is therefore unlikely to be accomplished in a session of &quot;fine tuning&quot; in clinic time.\n\nModern hearing aids possess the ability to record the general characteristics of the acoustic environment in which the aid operates as well as the pattern of use by the wearer, such as what settings were used and for how long. These recordings can be made for periods of up to about one month. For reasons of privacy they do not record the actual acoustic signal. Along with knowledge of the hearing loss, this data provides a valuable tool for fine tuning of the hearing aid to the requirements of the wearer and monitoring of the aid's effectiveness.\n\nWhen hearing aids are tested on a wearer in a clinical setting, it is common for the wearer to be seated while test sounds are presented from loudspeakers in fixed positions, either directly ahead, or distributed around the room. Real world use of hearing aids is far more dynamic: in practice both the wearer and the sound sources are moving relative to each other, and the wearer can additionally use head movements to re-direct their attention. Miniature gyroscopes and measures of position and inclination are routinely included in consumer electronic products such as tablets or &quot;smartphones&quot;. These data, available in real time, are potentially useful measures of how the aid wearer is interacting with their acoustic environment.\n\nThe proposal here is to build a network of academics, clinicians and representatives from manufacturers of hearing aids and clinical diagnostic equipment to identify how to use this data to build a fuller picture of the aid user. This picture should take into account the nature of the hearing loss, the capabilities of the wearer, the situations in which the aid is to be used and the behaviour of the wearer when using the device. With a more accurate profile of the user, it will be possible to provide a more systematic but personalised fitting.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=MR/M026132/1","grantId":"MR/M026132/1","fundValue":"104571","fundStart":"2015-07-01","fundEnd":"2016-12-31","funder":"MRC","impactText":"","person":"John  Keane","coPersons":["Michael  Stone"],"organisation":"The University of Manchester","findingsText":"","dataset":"gtr"}