{"id":"894F2CF9-C59C-46C5-A2F4-097D583C2996","title":"Categories and gradience in intonation: Evidence from linguistics and neurobiology.","abstractText":"<p>Intonation, or the melody of speech, plays a central role in human communication, since it can provide immediate cues to the start of new words or phrases in the speech stream, and to the meaning of utterances. Consequently, wrong intonation often leads to communication breakdown.</p>\n\n<p>However, intonation is difficult to analyse, because it signals multiple functions simultaneously. Form and meaning are closely intertwined, and the relationship between them is difficult to formalise in a theoretical model.</p>\n\n<p>The main objective of this research is to test the central principle of the predominant theoretical framework for intonation analysis (the ‘Autosegmental-Metrical approach’) which crucially distinguishes between categorical information in intonation and gradiently varying information. This allows the identification of critical intonational features, which can be used to define intonation’s role in speech perception and its neural substrates.</p>\n\n<p>Combining experimental tasks with the latest scanning techniques, the project findings provide evidence not only for the key principle on which virtually all current research in intonation hinges, but also the first neurobiological evidence for a refined, linguistically informed model of the neural underpinnings of intonation. Our understanding of human communication and the neural and cognitive systems that support it crucially depends on such insights.<br /><br />&nbsp;</p>","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/G001928/1","grantId":"ES/G001928/1","fundValue":"290999","fundStart":"2009-01-01","fundEnd":"2012-09-30","funder":"ESRC","impactText":"  A. The project has had two main kinds of impact: research-based (i) and (ii), and enabling (iii)\n\n(i) The project findings have the key implication that any formal linguistic model of intonation needs to distinguish between linguistic and paralinguistic meaning, while accommodating the complexities of the mapping relations between cues, meanings and various types of linguistic structures in the language. The production work which we carried out in this context on French phrasing and intonation as well as the work on the cueing of discourse structure is used as a starting point in a number of research projects - D (i) below.\n\n(ii) The second key finding that a specialised neural system supports the processing of linguistic phonological information in intonation as distinct from paralinguistic phonetic information has started to attract interest among neurolinguists - D (ii).\n\n(iii) The work on data collection and transcription which integrated project insights relating to intonational segmentation, abstraction, and categorisation is enabling the further development of semi-automated analysis of prosodic phenomena - D (iii).\n\n\nB. The findings and outputs from the project which have had the impacts are the following:\n\n(i) The impacts from the speech production and perception experiments concerned the finding that linguistic information in intonation is signalled, perceived, and processed in a systematically different way from paralinguistic information, as has been hypothesised in linguistic theory ('Autosegmental-Metrical theory'):\n\na) multiple phonetic parameters (pitch, duration, loudness, tempo, voice quality and spectral properties) covary in different ways to communicate different intonational meanings, which is true for different types of categorical intonational information: 'grammatical' meaning (e.g. statement, question, or listing; phrasing; Post 2011a, 2011b, Delais-Roussarie et al. 2011, Hudson et al. 2010, Post et al. in prep), as well as discourse meaning (Zellers et al. 2009, 2010, Zellers and Post 2010, 2012)\n\nb) the listener immediately perceives and exploits these multiple cues in the incoming signal in online interpretation (Zellers and Post 2010, Post et al. in prep)\n\n(ii) Elsewhere, impact was achieved with the findings from the neuroimaging studies which, in confirmation of the findings mentioned in B(i) above, showed differential processing for linguistic and paralinguistic meaning in intonation (Post et al. 2009, 2010, 2011, 2012a, 2012b, 2013, in prep. b; Post et al. under revision):\n\na) distinct, but overlapping neural systems are engaged depending on type of meaning (i.e. linguistic or paralinguistic)\n\nb) the subsystems which are engaged in the linguistic interpretation of intonational information are the same as those which support abstraction and categorisation for other types of categorical linguistic information in the speech signal (e.g. consonants and vowels); dissociations in lower-level auditory and higher-level linguistic subprocesses reflect distinctions made in current intonational theory\n\n(iii) See C for outputs related to enabling impact.\n\n\nC. Impact was achieved through the usual channels: publications, and a substantial number of conference presentations as listed under publications and engagement activities:\n\n(i)-a On cueing 'grammatical meaning', e.g.:\n- Post, B (2011). Metrical structure and the prosodic hierarchy. In Language and Music as Cognitive Systems. Oxford: Oxford University Press, 32-42.\n- Post, B (2011). The multi-faceted relation between phrasing and intonation in French. In Hamburger Studies in Multilingualism 10. Amsterdam: John Benjamins, 44-74.\n- Disentangling linguistic and paralinguistic intonational information: An fMRI study. BAAP, Leeds, Mar 2012.\n\n(i)-b On cueing discourse categories, e.g.:\n- Zellers, M and B Post (2012). Combining Formal and Functional Approaches to Discourse Structure. Language and Speech 55: 119-139.\n- Zellers, M and B Post (2010). Aperiodicity at Topic Structure Boundaries. Speech Prosody 2010, 100845: 1-4.\n- Zellers, M, M Gubbian and B Post (2010). Redescribing Intonational Categories with Functional Data Analysis. 11th Interspeech, 1141-1144.\n\n(ii) On neural processing, e.g.:\n- Post, B, E Stamatakis, I Bohr, F Nolan, and C Cummins (2013). Categories and gradience in intonation. An fMRI study. In J. Romero and M. Riera (eds.) Phonetics and Phonology in Iberia.\n- Post, B, F Nolan, E Stamatakis and T Hudson (2009). Categories and gradience in intonation: Evidence from linguistics and neurobiology. 10th Interspeech. Brighton: Causal Productions Pty Ltd., 2307-2310.\n\n(iii) On data collection and transcription, e.g.:\n- Delais-Roussarie, ? and B Post (2013). Corpus annotation: methodology and transcription systems. In The Handbook of Corpus Phonology. OUP.\n- Post, B and F Nolan (2012). Data collection for prosodic analysis of continuous speech and dialectal variation. In The Oxford Handbook of Laboratory Phonology. OUP, 538-547.\n- Prosodic transcription, Invited workshop at 'The Prosody-Discourse Interface', Salford, Sept 2011\n\n\nD. The research has been taken up by:\n\n(i)-a Dr Mathieu Avanzi (Universit? de Neuch?tel) in a Swiss National Science Foundation Post-doctoral Fellowship awarded for a visit to our Lab (2014-2015) to apply our work on phrasing and accentuation to dialect variation\n\n(i)-a Aline Russ (University of Konstanz) and Nadine Richter (Freie Universit?t Berlin) in undergraduate projects on polar questions and focus in French\n\n(i)-a Dr Simone Graetzer (University of Melbourne) in a study of the role of prosody in coarticulation, thus testing predictions of Post (2011a, b; planned for 2014-2016).\n\n(i)-b Ms Imme Lammertink (Radboud University &amp; Max Planck Institute Nijmegen) during a Lab visit (Jan-July 2014) for an MA dissertation on the processing of intonational cues to conversational discourse by infants (using eyetracking), applying our research in the domain of acquisition.\n\n(i)-a&amp;b Calbert Graham (University of Cambridge) in the doctoral dissertation The Phonetics and Phonology of Late Bilingual Prosodic Acquisition: A Cross-linguistic Investigation (2013), separating gradient phonetic and categorical phonological aspects of intonation in the acquisition of grammatical and discourse meaning by L2 learners of English\n\n(ii) Joan Borr?s Comes (Universitat Pompeu Fabr?) in the doctoral dissertation The role of intonation and facial gestures in conveying interrogativity (2012) in an exploration of the neural traces for intonation-based discourse categories (using ERP)\n\n(ii) Dr Kai Alter &amp; team (University of Newcastle; establishing a new research network) in an ERP study showing evidence of different timecourses for the processing of linguistic and paralinguistic intonational information.\n\n(ii) indirectly, the Standing Committee of the international conference Phonetics and Phonology in Europe, who asked us to host the conference in 2015 after hearing our contributions at TIE 2010 and PaPI 2011.\n\n(iii) Dr Avanzi (see (i)-a above) in his work on semi-automated annotation and analysis of intonation.\n\n\nUnexpected and Potential Future Impacts \n\nUnexpected Impacts\n\nWe expected the production work to garner the usual interest among Linguists, but we had not anticipated that it would form an important basis for Avanzi's successful external application for post-doctoral funding (see D(i)-a). Also, we had not anticipated the work on discourse at the application stage, in particular the results obtained with the multiple methods approach advocated in Zellers and Post (2012).\n\nThe role of the neuroimaging research in attracting a major conference to Cambridge, and in sparking off ERP work on the same questions, was wholly unforeseen.\n\n\nPotential Future Impacts\n\nScientific impacts\nIncreasing uptake of further outcomes through (invited) lectures and forthcoming publications, in particular:\n- Intonation has a dual function which is supported by distinct cognitive and neural mechanisms, the one being encoded in the linguistic system, and the other reflecting biological imperatives much more directly (cf. Biological Codes explaining correlations between pitch cues and speaker attitudes/feelings).\n- Hierarchically organised processing is a universal characteristic of speech processing; dissociations in lower-level auditory and higher-level linguistic subprocesses reflect distinctions made in current intonational theory.\nIn e.g.:\n- Post et al. (under revision). Question or surprise? J Cog Neurosci.\n- Post et al. (in prep). The effect of intonational function on cue dependencies in intonational rises. JASA.\n- Post (2013). Intonation: from animal communication to grammatical encoding. International Conference Language Sciences in the 21st century, Cambridge, UK.\n\nEconomic and societal impacts \nThe research could also find application in language therapy, language teaching and speech synthesis and recognition. In all of these disciplines, computer-aided programmes are being developed to optimise speech processing conditions for their respective user groups. For the neuropsychologist, knowing which areas of the brain are crucially implicated in processing intonation for different functions will allow fine-tuning diagnostics and treatments for stroke rehabilitation and speech therapy (e.g. schizophrenia and Parkinson's disease). In second language teaching, a better understanding of form-function mappings in intonation can be used to help learners focus on the most critical aspects to acquire, as prefigured in Graham's PhD. In speech synthesis and recognition, it can be used to help improve naturalness and lift success rates that cannot be achieved with computational techniques alone.  ","person":"Brechtje Maria Post","coPersons":["Emmanuel Andreas Stamatakis"],"organisation":"University of Cambridge","findingsText":" Intonation, or the melody of speech, plays a central role in human communication. It is one of many elements in the speech signal that needs to be decoded to translate speech sound into meaning, but its role in speech understanding is crucial, since it can give us immediate cues to the start of a new word or phrase in the speech stream, and to the meaning of utterances. As a consequence, when the intonation is wrong, communication often breaks down. \n\nIn spite of its importance, intonation is still very poorly understood. It is notoriously difficult to analyse because it is carried by a continuous sound signal, it has multiple functions, and it interacts with other elements in the speech signal that convey meaning. We know that at some stage in the comprehension process, some of this continuous information is interpreted categorically and decoded into distinct meaningful units, such as a rising pattern that marks a question. However, sometimes it makes a more gradient contribution to meaning, when gradual increases or decreases in a particular feature like pitch convey, for instance, a more angry or less timid tone of voice. These variations in form and their contribution to meaning are closely intertwined, and difficult to disentangle. To make matters worse, they are ignored in virtually all cognitive, neuropsychological and neurobiological studies of intonation. As a result, it is unclear exactly how intonation is realised in speech, what units are involved, how it contributes to speech comprehension, and how it is processed in the brain. This lack of understanding holds back progress in the speech sciences.\n\nThe main objective of this research is to test the central principle of the currently predominant theoretical framework for intonation analysis (the 'Autosegmental-Metrical approach'). This principle allows us to analyse the intonational features of the speech signal in a discrete, insightful way by disentangling the interaction between the categorical and gradient information mentioned above. Since it helps us identify the critical features of intonation patterns, we can use it to pin down their role in language processing and the neural architecture that supports it, which is the second aim of this research. \n\nCombining a number of well-established speech production and perception tasks with the latest scanning techniques, we examined the acoustic and perceptual correlates of the relevant categorical and gradient information in the speech signal, and we identified the brain systems that are involved in processing the different types of intonation. \n\nThe speech production and perception experiments confirmed that the categorical information in question is signalled, perceived, and processed in a systematically different way from gradient information as proposed in Autosegmental-Metrical (AM) theory. We also found that the listener immediately perceives and exploits the cues to the categorical information in the incoming signal in online interpretation.\n\nThe neuroimaging results also provided evidence for AM's central principle, since we found that distinct neural systems were engaged in processing intonation depending on the type of information it conveyed. Also, the subsystems which were active in processing categorical intonational information were the same as those that have been observed for other types of categorical linguistic information in the speech signal (e.g. consonants and vowels).\n\nThis project has done much to reinforce the key theoretical construct of a separation between categorical and gradient information in prosody, thus supporting the key principle that underlies almost all current linguistic research in the area; to date, decisive evidence had been elusive. The research also shows, for the first time, that hierarchically organised processing is a universal characteristic of speech processing, encompassing both segmental and intonational properties.\n\nThe findings also confirm that intonation is not merely a side effect of biological imperatives related to animal communication (e.g. high pitch being associated with questions or with an uncertain attitude just as high pitch signals fear or danger in small and frightened animals). Instead, we can conclude that much of intonation is in fact properly part of the linguistic system.\n\nThis research is also innovative in its methodology in combining acoustic analysis, statistical modelling, and auditory analysis with fMRI, EEG, and perception tests, as well as developing or further enhancing existing analysis techniques. In this way, the project has provided the tools to develop a unified model of prosody which can integrate insights from different research disciplines (i.e. phonetics, linguistic typology, cognitive psychology, and neurobiology), and it offers a template for further research. The fundamental research carried out in this project will only have scientific impacts, but indirectly, it may benefit non-academic communities in the longer term. \n\nThe findings allow linguists, cognitive psychologists, neuropsychologists, speech engineers and computer scientists to improve their theories and models of language and speech processing. Secondary beneficiaries are applied researchers in neuropsychology, language teaching and speech synthesis and recognition. In these disciplines it has long been known that deficiencies in prosodic performance are a major factor in impeding communication (eg cross-culturally, or in aphasic speech). This is not surprising given the crucial role that prosody and intonation have been shown to play in (human) speech segmentation and recognition. \n\nIn all of these disciplines, computer-aided programmes are being developed to optimise speech processing conditions for their respective user groups. For the neuropsychologist, knowing which areas of the brain are crucially implicated in processing intonation for different functions will allow fine-tuning of treatments for stroke rehabilitation and speech therapy. In second language teaching, a better understanding of which aspects of an intonation contour crucially affect how they are processed and perceived by a listener can be used improve teaching methods by helping learners' attention focus on the most critical aspects of the spoken L2. Similarly, in speech synthesis and recognition, a better understanding of the categorical phonological and gradient phonetic information in intonation can be used to help lift success rates which are no longer showing the improvements that are offered by computational and engineering techniques alone. \n\nMore generally, the findings advance our insight into the integration of the cues to channels of communication that simultaneously convey linguistic messages, but also information about the speaker's state of mind (such as their attitude or feelings). Our understanding of human communication and the neural and cognitive systems that support it crucially hinges on such insights.\n\nThe relevant audience is being reached through publications in international peer-reviewed journals and edited volumes, as well as presentations at specialist workshops and conferences. Education,Healthcare","dataset":"gtr"}