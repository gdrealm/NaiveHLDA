{"id":"7035C3F9-5781-4030-A45A-39CAD60315C1","title":"Robotic Assisted Surgical Guidance and Visualisation","abstractText":"The use of augmented reality in surgery has risen dramatically in recent years, contributing to a range of new methods for training, education and diagnosis. In surgery, advances in medical imaging have permitted detailed pre-operative planning and intra-operative surgical guidance. One of the most promising advances in surgical technology in recent years is the introduction of robotic assisted Minimally Invasive Surgery which allows the performance of procedures that are otherwise prohibited by the confines of the operating environment. The purpose of this project is to develop novel visualisation techniques that permit in situ, in vivo integration of complex anatomical and functional information of the operating field through the use of multi-modal, multi-scale imaging data for safer and more effective surgical navigation.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=DT/E011101/1","grantId":"DT/E011101/1","fundValue":"879942","fundStart":"2007-06-01","fundEnd":"2010-11-30","funder":"EPSRC","impactText":"  The work has resulted in a surgical guidance and visualisation platform used for robotic surgery. The augmented reality visualisation framework - Inverse Realism has now been successfully translated clinically. Digital/Communication/Information Technologies (including Software),Healthcare Economic","person":"Guang-Zhong  Yang","coPersons":["Ara Warkes Darzi","Daniel  Elson"],"organisation":"Imperial College London","findingsText":" In surgery, advances in medical imaging have permitted detailed pre-operative planning and intra-operative surgical guidance. One of the most promising advances in surgical technology in recent years is the introduction of robotic assisted Minimally Invasive Surgery which allows the performance of procedures that are otherwise prohibited by the confines of the operating environment. The purpose of this project is to develop new visualisation and navigation techniques that permit in situ, in vivo integration of complex anatomical and functional information of the operating field through the use of multi-modal, multi-scale imaging and haptic feedback for safer and more effective surgical operation. The project has resulted in a real-time augmented reality system for pre- and intra-operative visualisation and navigation; integration of 3D functional imaging to provide in vivo, in situ tissue characterisation and &quot;see-through&quot; vision; dynamic motion stabilisation; and gaze contingent collaborative visualisation and tele-mentoring. The augmented reality visualisation methods developed can have a wide range of applications including entertainment, oil exploration, and industrial inspection. The project is in collaboration with Intuitive Surgical Inc, the leading manufacturer for surgical robots. Digital/Communication/Information Technologies (including Software),Healthcare","dataset":"gtr"}