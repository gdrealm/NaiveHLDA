{"id":"B90A4822-2930-477E-A4C5-4A024F4789B1","title":"A multichannel adaptive integrated MEMS/CMOS microphone","abstractText":"There are many different types of microphones: their primary function is transduction: converting pressure waves (within some range of frequencies) into a single electrical signal, usually as precisely as possible. After this, the signal may be used for recording or for interpretation (which is our interest here). A major problem in interpretation is that the signal may have a large amount of energy in some parts of the auditory spectrum, but much less in others, and that this distribution may alter rapidly. Often, it is the energy in these lower energy areas that is critical for interpretation. Current practice is to filter the single electrical signal from the microphone (whether using FFTs, or bandpass filters), then examine the signal so produced. We propose a different approach in which the pressure wave is directly transduced into multiple electrical signals, corresponding to different parts of the audible spectrum. By making the transducers active (i.e. providing them with a rapidly adjusting gain control), we will be able to increase the sensitivity of the filters in those areas where additional sensitivity can be useful in the interpretation task, and reduce the sensitivity in those areas where the signal is very strong. The auditory interpretation tasks undertaken by animals (solving the what and where tasks when there are - as is normally the case - multiple sound sources in a reverberant environment) is the same task that an autonomous robot's auditory system needs to undertake. Animal hearing systems include multiple transducers, and provide numerous outputs for different parts of the spectrum, whilst adjusting their sensitivity and selectivity dynamically. Current microphones provide a single electrical output, which is then either processed into a number of bandpass streams (maintaining precise timing), or into a sequence of FFT-based vectors, such as cepstral coefficients (losing timing precision). The proposed active MEMS microphone performs the spectral breakdown at transduction, providing an inherently parallel output whilst maintaining precise timing. Further, it is adaptive. This adaptive capability, non-existent in current microphones is important in hearing aids. Precise timing information is important for source direction identification using inter-aural time and level differences. Where there are multiple active sources, accurate foreground source interpretation requires some degree of sound streaming, requiring the ability to examine features of the sound, often in spectral areas which with relatively low energy.The active MEMS bandpassing microphone will consist of a membrane which will vibrate due to the external pressure wave. The membrane is physically linked to different resonant elements (bars) in the MEMS structure - these elements will have a range of resonant frequencies. Further, these bars will act as gates for MOS transistors, resulting in their vibration modulating the current passing through these transistors. The modulated current will be coded as a set of sequences of spikes, and these spikes processed to provide a signal to adjust the sensitivity of each of the resonators by using an electrostatic effect to change the response of the transistors to the vibration of the bars. The modulation will be used to adjust the gain so that quiet areas of the spectrum are selectively amplified and loud areas of the spectrum selectively attenuated. In this way, it will be possible to build an integrated MEMS/CMOS microphone which can attenuate loud areas of the spectrum concurrently with amplifying quiet areas of the spectrum. The spike coded output will be made available in a way compatible with the address-event representation (AER), making it compatible with existing and proposed neuromorphic chips form other laboratories.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/G063710/1","grantId":"EP/G063710/1","fundValue":"868885","fundStart":"2009-08-01","fundEnd":"2014-01-31","funder":"EPSRC","impactText":"  Our findings have not been used as yet.  ","person":"Rebecca  Cheung","coPersons":["Alister  Hamilton","John Thomas Stevenson"],"organisation":"University of Edinburgh","findingsText":" The key findings are:\n\n1. During the development of MEMS-RGT arrays, the bridge gates have been designed to cover the audible frequency range signals of 20Hz - 20kHz. Aluminium and tantalum have been studied as the material for the bridge gate structure. The downstream etch release technique employing oxygen/nitrogen plasma has been developed to release the bridge gate structure from a sacrificial layer. In the first iteration, aluminium bridge gates have been fabricated. The presence of tensile stress within aluminium had caused the aluminium bridge gates of length &amp;amp;amp;amp;gt;1mm to collapse. In order to address this issue, tantalum bridge gates have been fabricated in the second iteration. Straight tantalum bridge gates in tensile stress and buckled tantalum bridge gates in compressive stress have been characterised. The frequency range of 550Hz - 29.4kHz has been achieved from the fabricated tantalum bridge gates of length 0.57mm - 5.8mm. \n\n2. The channel and source/drain regions have been fabricated and integrated with the aluminium or tantalum bridge gate structures to create the MEMS-RGTs. In this study, the n-channel and p-channel resonant gate transistor (n-RGT and p-RGT) have been considered. The p-RGTs have been found to possess considerably less substhreshold currents than n-RGTs. The threshold voltage, transconductance and substhreshold current for both n-channel and p-channel resonant gate transistor devices have been characterised, where the channel conductance of the n-RGT and p-RGT devices has been modulated successfully and the tuning capability within the audible frequency range has been achieved from the tantalum bridge gates of the p-RGT devices. The characterisation and optimisation of the resonant gate transistor provide the first step towards the development of the adaptive RGT cochlear biomodel for the neuromorphic auditory system application.\n\n3. A spike event coded MEMS-RGT microphone model for neuromorphic auditory systems has been developed. Our microphone system directly converts acoustic signal into bandpassed filtered outputs and encode them as asynchronous spike time events. The microphone system alters its dynamic response by receiving inputs in the spike domain which are then decoded to vary the gate voltage of the MEMS-RGT. The MEMS-RGT sensor model has been simulated and the measurement results from the spike encoder chip for a simulated MEMS-RGT response have been achieved. A set of 10 MEMS-RGT sensors using an etch release process capable of releasing long resonant gate transistor bridges from the sacrificial layer have been fabricated (see point 2).\n\n4. An analogue low-noise MEMS interface circuit which has very small parasitic capacitance at the input node has been designed and fabricated. The circuit is suitable for the MEMS cochlea-mimicking acoustic sensors which are highly parasitic-sensitive due to their low intrinsic sensing capacitance. In order to reduce the electronic noise of the interface circuit, chopper stabilization technique is implemented, and an effective method to optimize the critical transistor size for best noise performance is derived. Simulation results show that, for a MEMS sensing structure with 200 fF static capacitance, the interface circuit achieves a 0.72 aF equivalent capacitance noise floor over 100 Hz to 20 kHz audio bandwidth. Results from fabricated devices have verified simulation results in the test laboratory and a journal paper presenting the scheme with results is under review for publication in IEEE Transactions on Biomedical Circuits and Systems.\n\n5. An analogue cochlea-mimicking filter has been modelled, designed and fabricated in analogue VLSI. The circuit design uses floating active inductors in high-Q and steep cut-off elliptic filters to achieve a response comparable with the biological exemplar. Our implementation offers the advantages of tuning with one variable parameter, high-Q and a steep cut-off response, providing an overall performance that closely matches the biological exemplar. Results from fabricated devices have verified simulation results and have been published in the journal IEEE Transactions on Biomedical Circuits and\nSystems.\n\n6. A simulated form of the output of the microphone (which codes the signals from multiple sensors) has been used in an experiment to test the effectiveness of the data so coded in differentiating different types of musical instruments. This experiment was carried out to assess the effeciveness of the proposed coding technique when applied to real sounds. Our findings can be taken forward by optimising our design and processing further, for example, by employing more robust materials and improved design concepts. Healthcare","dataset":"gtr"}