{"id":"56D59875-6C3C-4C03-80B9-4732D3400603","title":"A multi-scale model of binocular fusion in the human visual system","abstractText":"We have two eyes but see one world. Although this might seem obvious (there is only one world), there are conditions where we do see double. For example, hold your index finger up a few inches in front of your nose, then fix your gaze on a more distant object straight ahead; your finger will be clearly seen as two, side-by-side. Then, as you switch your gaze to the finger, the two will become one. This is binocular fusion, or 'single-vision', and it is achieved by the brain (the visual cortex, containing thousands of millions of nerve cells) piecing together the information from both eyes. As a result, your ability to detect very faint things, or to see fine details, is better with two eyes than one. Our research aims to study single-vision and double-vision in carefully controlled experiments, and to build a general explanation in the form of a computer model that identifies both the main mechanisms and how they serve to identify basic visual features such as lines and edges that may be the building blocks of perception. How is the binocular combination organized ? Does the visual system use only the combined (left+right eye) information, or does it also make use of separate responses from the left eye and right eye ? Or might it even use the difference between left and right views, as well as the sum ? Our experiments will get at these questions by looking at how well we can detect images that are, in some sense, opposite in the two eyes. This could be a pattern of light and dark stripes, where the light stripes in one eye are superimposed on the dark stripes of the other eye, or the stripes might increase in contrast for one eye while they decrease in contrast for the other. If the brain only had left+right information available, such opposites should cancel. Previous findings suggest that they don't cancel, and so other information must also be used. New experiments will test this further and clarify what the extra information may be. Whether we see things as single or double depends on how far apart the left and right eye's views are and, importantly, on how blurred or sharp they are. Our second set of experiments will carefully measure these effects using images (blurred edges) that have not been used before, but should give cleaner, more general results than previous studies. Vision in one eye can be dramatically suppressed or inhibited by events in the other eye, especially when images in the two eyes are very different. Bright, flashed images in one eye particularly tend to suppress weak, steady images in the other eye. Present evidence, however, suggests that such competition between the eyes is also part of the normal process of binocular combination. We aim to study several aspects of binocular fusion (the perceived position, contrast and blur of edges and lines), and to do so when the left and right images themselves differ in position, contrast, or blur. With these data, assisted by our computer model, we shall work out how the mutual suppression between the eyes, taking place in the brain, shapes the binocular fusion and appearance of visual features. This work will be of direct benefit to other scientists researching in various fields that are concerned with binocular vision: neuroscientists studying the cellular responses of the visual brain; vision scientists and psychologists studying sensation &amp; perception and brain-imaging; computer scientists interested in machine vision and robotics, especially 3-D vision; and optometrists concerned with vision correction and treatment of sight disorders. In optometry, our work may shed new light on 'monovision', where older patients (40+) are often successfully given different contact lenses in the two eyes - one for far, and one for near. By explaining how images with different blurs in the two eyes are combined by the brain, our research could lead to better understanding of monovision and to improvements in diagnosis and prescription.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=BB/H00159X/1","grantId":"BB/H00159X/1","fundValue":"354219","fundStart":"2009-10-01","fundEnd":"2012-09-30","funder":"BBSRC","impactText":"","person":"Mark Andrew Georgeson","coPersons":["Tim  Meese"],"organisation":"Aston University","findingsText":" Seeing with two eyes is generally better than one, but not always. Visual signals sent along the optic nerves from the left and right eyes are combined in the visual cortex of the brain. In binocular vision, different images in the two eyes can be 'fused' in perception, but little is known about the nature of fusion or how it is achieved. We studied fusion, and the failure of fusion (double vision), in carefully controlled psychophysical experiments using blurred edges. If fusion added or averaged the signals from each eye, we should expect binocularly fused edges to look increasingly blurred when they are shown in slightly different positions in the two eyes. We found that this was true when the two edges were physically added in the same eye, but not when one edge was shown to each eye. Binocular combination is not like addition, but more like multiplication. Neural systems can carry out mathematical computations.\n\nWe developed a new, quantitative, theory of binocular fusion and double vision that accounts for these results. The visual system first computes the gradients of luminance in each eye, then combines them (by a form of multiplication) across the eyes. These operations, in that order, are crucial to the success of the combination process. If the combined response is strong enough, we experience a single 'fused' image and the fused image correctly preserves the sharpness or blur of features from each eye. \n\nBut the fused (binocular) response is not the only game in town. The two eyes also assert themselves separately, and responses drawn from the left &amp;amp;amp; right eyes are in a 3-way competition with the fused response. If the images in the two eyes are different - in their position or blur - then the fused response gets weaker. Eventually it loses the 3-way competition and becomes strongly suppressed. Instead of fusion, we get double vision. This suppression of the binocular response is intimately linked to the classic phenomenon of binocular rivalry where left and right eye responses compete with each other. Our results and modelling suggest that underlying the dynamic complexity of rivalry - when fusion fails - there is a simple rule: at each location in visual space, the eye that has the steeper luminance gradient wins the competition - 'the winner takes all'. \n\nOur findings offer some insight and application in Optometry. As an alternative to bifocal glasses, optometrists may offer a prescription called monovision. This gives you a contact lens for far vision in one eye, and one for near vision in the other eye. The idea is that the brain may select and use the sharper parts of the two images. Our results show how this can work, and work more simply than one might think. In a blurred image the light is smeared out, and luminance gradients become shallower. At an early stage in the visual cortex, the brain can sense the steeper gradient, and suppress the other one. It may do this automatically, and simultaneously at all locations. It then assembles these fragments, some drawn from one eye, some from the other, into a coherent whole. Only the steeper gradients have been selected, and the scene is apparently sharp everywhere. \n \nHow do we know the brain is selecting the steeper gradients, rather than the sharper image content? This is shown by experiments where a sharper image is in one eye, with a blurred image in the other. The sharper image dominates. But luminance gradients increase with contrast, and so if we increase the blurred image contrast there comes a point at which the blurred image has the steeper gradients. We find that vision then switches to seeing the blurred image and suppressing the sharper one. This proves that gradients, not sharpness, control the competitive selection process. Nevertheless, in monovision, the sharper image also has the steeper gradients, so the gradient competition that we have uncovered does in fact select the sharper image content in this situation. Our findings offer some insight and application in Optometry, as described more fully above Digital/Communication/Information Technologies (including Software),Healthcare","dataset":"gtr"}