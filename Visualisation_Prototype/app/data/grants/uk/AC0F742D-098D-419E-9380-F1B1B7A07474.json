{"id":"AC0F742D-098D-419E-9380-F1B1B7A07474","title":"Video-based animation of people","abstractText":"The goal of this research project is to solve the fundamental problem of re-using multiple-view video capture of people to support interactive animation with the quality of the source video. Research will investigate the resampling of a multiple-view video database for interactive animation of people to enable user control of movement and viewpoint with video-quality rendering. The proposed research will address the underlying problem of representation of articulated and highly dynamic non-rigid structures in video to allow indexing, reuse and manipulation whilst maintaining the visual quality. Ultimately the challenge is to enable video-quality rending of real people by reuse of captured video sequences allowing user control of movement as in conventional animation. Recent research has demonstrated photo-realistic animation of faces and simple objects by resampling video sequences.This proposal aims to take video-based animation to complex articulated objects such as people without full 3D reconstruction which has been shown to result in loss of visual quality in previous work. The new challenge is to synthesise video sequences of novel movements from captured video of different motion. Animating people from video requires several key advances, including: a representation of human posture and movement which supports the generation of sequences of previously unseen movements; a representation of multiple-view video of articulated objects allowing efficient storage and indexing; algorithms to efficiently selecting the most useful examples for the synthesis of a new sequences from a large set of example sequences; and new video synthesis algorithms for articulated objects in previously unseen configurations. Animation of people directly from captured video has the potential to provide enabling technology for next-generation, video-quality content production in film, television and games. Video-based animation of people will allow powerful re-use and manipulation of captured video (e.g., generating novel body movements for an actor), together with seamless compositing within photo realistic scenes.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/E001351/1","grantId":"EP/E001351/1","fundValue":"349256","fundStart":"2007-04-02","fundEnd":"2010-08-01","funder":"EPSRC","impactText":"  Video-based animation of people introduced an entirely new approach to creation of animated content from video. This was the first project world-wide to demonstrate the use of video-based reconstruction of actor performance for the creation of photo-realistic animated content. The advantage of this approach is that it enables production of highly realistic animated content directly from video capture without the requirement for extensive artist/animator time in content creation. This has allowed creation of realistic animation content outside the big budget game industry by content producers such as broadcasters. VBAP provided the foundations for video-based animation which have received attention from both academia and industry. Transfer of this technology to enable co-production of animated content alongside broadcast production is the focus of the EU FP7 RE@CT project (http://react-project.eu) led by BBC R&amp;D. The approach is also the focus of ongoing research to allow the flexible creation of interactive educational content. Creative Economy,Education Cultural,Economic","person":"Adrian  Hilton","coPersons":["Jonathan  Starck"],"organisation":"University of Surrey","findingsText":" Key findings: \n\n- the first video-based creation of photo-realistic animated content from actor performance\n- a new approach to animated content production based on a new surface motion graph representation\n- high-accuracy reconstruction of dynamic surface shape of actors from multiple view video\n- photo-realistic free-viewpoint rendering of actor performance\n- a comprehensive evaluation of methods for measuring shape-similarity of people across different poses and the introduction of new validated methods\n- a framework for photo-realistic animated content production and rendering\n- fundamental advance demonstrating the principle of reuse of captured dynamic shape and appearance to produce animation by concatenation Findings have been taken forward in:\n(1) the development of a production pipeline for video-realistic animated content production\n(2) interactive real-time animation tools developed in the EU Project RE@CT led by the BBC\n(3) exploitation of the technology by SME Artifacto to develop and demonstrate animated content for educational museum applications and cultural heritage Creative Economy,Digital/Communication/Information Technologies (including Software)","dataset":"gtr"}