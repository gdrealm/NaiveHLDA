{"id":"7CC8332C-DED1-4B0E-A7D5-91DD1EA2E79C","title":"Fashion garment design, e-tailing and manufacturing with zero prototyping.","abstractText":"This project will carry out research to acquire the knowledge and skills required to simulate the behaviour of, and render\nphotorealistic fabric/garment, in real-time, to enable the design, e-tailing (electronic retailing on-line and in store) and\nmanufacturing of fashion clothing with zero physical prototypes. The innovation here is that no one today, anywhere in the\nworld, is delivering high quality, real-time fabric/garment behaviour simulation and photorealistic rendering matched to real\nfabric. This UK project team brings together the experience in simulation, photorealistic rendering, fashion and computer\nvision to make this a reality. This technology would enable new business models in the fashion industry, such that\ngarments could be offered to consumers prior to manufacture for interaction e.g. try-on and outfit mixing, and\npersonalisation e.g. fabrics, colours etc. before purchase. It would also encourage localised manufacture-on-demand to\nmeet shorter delivery times and support a revitalised UK fashion manufacturing economy. There are also applications for\nthis technology beyond the fashion industry, such as video games, movie production and advertising.\nOver the past decade the University of Surrey, Centre for Vision, Speech and Signal Processing has pioneered the\ndevelopment of video-based surface motion capture to allow the acquisition of complex non-rigid motion of real surface\ndynamics from multiple view video. Research has primarily focused on the use of surface motion capture to capture actor\nperformance to support video-realistic content production for film and interactive entertainment. Video-based\nreconstruction of surface motion allows the acquisition of highly non-rigid surfaces such as the loose dress of a dancing\nactor.\nThe goal of the proposed research is to exploit recent advances in surface motion capture to enable high-accuracy dense\nreconstruction of garment motion. This is not possible with existing motion capture technologies which require the\nplacement of markers as tracking fiducials on the cloth surface affecting the natural cloth motion and only allowing motion\ncapture at sparse locations. A critical advance in this research will be verfication of the accuracy of video-based surface\nmotion capture for measurement of dense non-rigid cloth motion. This will open-up the potential exploitation of surface\nmotion capture in both the immediate application of garment design and wider application as a tool for video-based measurement of human soft-body surface motion in clinical applications ranging from biomechanics to non-invasive\nmonitoring of movement during medical imaging.\nApplication of surface motion capture to verification of physics-based cloth simulation will allow validation of methods\nbeyond their qualitative use as artistic tools for computer generated imagery in film production. Research will introduce\nquantitative metrics for both direct evaluation of simple cloth motion under controlled conditions and full garment motion\ncapture where it is not possible to accurately measure the contact constraints driving the motion. This research will bridge\nthe gap between the real-world and physics-based simulation of complex dynamic scenes. Quantitative evaluation will\nvalidate the use of cloth simulation in garment design enabling an end-to-end zero-prototyping process from design to\nmanufacture for the fashion industry.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/M506801/1","grantId":"EP/M506801/1","fundValue":"150918","fundStart":"2014-10-20","fundEnd":"2016-04-19","funder":"EPSRC","impactText":"","person":"Adrian  Hilton","coPersons":["Jean-Yves  Guillemaut"],"organisation":"University of Surrey","findingsText":"","dataset":"gtr"}