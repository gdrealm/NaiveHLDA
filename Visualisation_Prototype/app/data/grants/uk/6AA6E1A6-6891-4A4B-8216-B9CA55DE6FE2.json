{"id":"6AA6E1A6-6891-4A4B-8216-B9CA55DE6FE2","title":"Representing and responding in the visual world: a new model of contextual cuing.","abstractText":"<p>One of the most fundamental psychological functions is the ability to recognize a familiar scene and perform an action relevant to it or an action relevant to some internal goal. Yet we currently have a very limited understanding of this fundamental aspect of human behaviour.</p>\n\n<p>The project aims to test a newly proposed computational model of this type of learning.This model learns about repeating scenes by creating memories for how specific objects within the scene are arranged with respect to the target object. The specific objectives of this research are to:</p>\n\n<ul>\n \n\n <li>Develop a model of contextual cue learning to further our understanding of the processes responsible for learning scene contingencies in the visual world. </li>\n\n <li>Test the predictions of this model against the predictions of the Brady and Chun (2007) model using several novel experimental designs.</li>\n\n <li>Use eye tracking technology to monitor contextual cuing, providing key data to the field to address fundamental unresolved questions about the role of attention in scene learning.</li>\n\n <li>Disseminate the findings to the academic community via high-profile publications and conference presentations, and to the wider public via suitable press releases.</li>\n\n</ul>","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/J007196/1","grantId":"ES/J007196/1","fundValue":"163320","fundStart":"2012-09-03","fundEnd":"2014-09-02","funder":"ESRC","impactText":"","person":"David Robert Shanks","coPersons":["Thomas  Beesley"],"organisation":"University College London","findingsText":" This project developed and tested a new model of visual search aimed at explaining how we learn to find objects in familiar environments. The predictions of the model have been confirmed by several experiments and computational modeling simulations. Furthermore, these predictions have also been explored using eye-tracking measures that allow us to study how people deploy their attentional resources during visual search in familiar contexts.\n\nThe conclusions of our studies have important implications for any attempt to design artificially intelligent algorithms that mimic humans' ability to deploy visual attention efficiently. They also provide a unique insight into the mechanisms of human learning and memory.\n\nThis research project has also consolidated a fruitful collaboration between David Shanks (PI of the project), Miguel A. Vadillo (now working at King's College London) and Tom Beesley (University of New South Wales) that remains fully active despite the end of the project. Thanks to the project we have also contributed to the development of better methods for the use of eye-tracking technologies in behavioural research. Our results will be of interest not only for experimental psychologists working in the area of human learning and memory, but also to researchers working on visual cognition in artificial intelligence.\n\nFurthermore, as a result of our research we have developed a new algorithm for the correction of eye-tracking data that is now available for any researcher working with these methods. Further details about these methods and potential applications of our research can be found at the websites of Digital/Communication/Information Technologies (including Software),Education,Electronics","dataset":"gtr"}