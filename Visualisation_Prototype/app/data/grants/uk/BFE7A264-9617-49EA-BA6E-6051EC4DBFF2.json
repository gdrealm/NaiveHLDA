{"id":"BFE7A264-9617-49EA-BA6E-6051EC4DBFF2","title":"Bayesian issues in ant navigation","abstractText":"Our brains have to deal with ambiguity and uncertainty, and an increasingly popular explanation of how they do so is based on Bayesian reasoning. In essence, this says we estimate the probability of a certain state of affairs (such as 'I am at home') on the basis of both current sensory inputs ('This looks like my house') and prior expectations ('Given my starting location, and the speed I was travelling, I wouldn't expect to be home yet'). Bayes theorem tells us how we should combine these factors to obtain the best estimate of our current state. But is this form of reasoning universal? An ideal way to investigate this issue is to look at 'simple' animals that have to solve analogous problems. And an effective way to test our understanding of what these animals do is to implement and test our hypotheses in robot models that operate in the same sensory environment. A clear example of an animal solving such problems is found in desert ants, who forage individually and without the use of chemical trails, yet can efficiently relocate their nest or a food source over long distances in barren or complex environments. Recent studies have shown that ants can individually learn and recall specific routes through cluttered environments that force detours and prevent the use of distant landmarks. Ant navigation depends on two main mechanisms: they can keep track of how far they have moved and in which direction from the nest and continuously update a vector that points back home; and they can recognise familiar visual surroundings and use these to determine which way to go. Do they integrate these cues in an optimal fashion? What if one or other cue is more or less variable? Can they use one of these cues to disambiguate the other? We can make the investigation of these issues rigorous and quantitative by drawing on methods developed for robot navigation. We will first determine what ants actually see as they develop new routes, by following ants as they forage, and capturing images from the ant's eye point of view. We will feed this information into algorithms that should be able to learn a map of the area. We can systematically vary the type of information available, its reliability, and the computational methods used to update the map, and compare the performance to ants. Further experiments to see what the ants do when the same variables are manipulated will serve to evaluate the models. Finally, the models will also be tested in the real world by implementing them on a small robot able to navigate in the ant environment.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=BB/I014543/1","grantId":"BB/I014543/1","fundValue":"325896","fundStart":"2011-08-01","fundEnd":"2014-09-30","funder":"BBSRC","impactText":"  Our field analysis has inspired the development of a novel sensor for robots resulting in a robot conference publication, patent application (pending). Commercialisation has already progressed through a Scottish Universities accelerator program with likely avenues being a university backed spin out and/or licence agreement. \n\nThe results have also been highlighted in several media reports, with a news feature on the BBC, and a documentary shown in north America. Aerospace, Defence and Marine,Education,Manufacturing, including Industrial Biotechology,Transport Cultural,Economic","person":"Barbara  Webb","coPersons":[],"organisation":"University of Edinburgh","findingsText":" We have tracked ants (using differential GPS and video) throughout their entire foraging life, demonstrating that they are able to acquire and recall visual route memories with only one or two trials. We have obtained experimental results demonstrating ants combine path integration with visual memory cues in a Bayesian optimal manner, but do so using a proxy estimate for uncertainty. We have built a virtual reality simulation of the real ant environment and used to assess a range of navigation models, including the first insect navigation model to be closely based on known neural circuits. We have also successfully tested the algorithms on a robot platform in the field. A closer look at the visual information available to ants has led to development of a novel skyline sensor which we have demonstrated can be used for robot navigation and is the subject of a submitted patent. Our discovery that ants use a proxy for weighting cues relative to their uncertainty has wide implications for the Bayesian brain hypothesis in other animals and humans. The connection we have drawn between navigation algorithms and the neural mechanisms of memory in insects can be taken forward in both fields. The results have potential application as low-cost and low-computation sensory methods that can be deployed on robots and autonomous vehicles. Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Electronics,Transport","dataset":"gtr"}