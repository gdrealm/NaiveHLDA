{"id":"A1C6CCEC-7D88-48AD-B1A4-E8C2306FD179","title":"Automated Plan-Based Policy-Learning for Surveillance Problems","abstractText":"Surveillance problems give rise to many challenges including the management of uncertainty in an unpredictable environment, the management of restricted resources and the communication of commitments and requests between multiple heterogeneous agent ``observers''. At the heart of surveillance problems lies the need to plan complex sequences of behaviour that achieve surveillance goals. These goals are typically expressed in terms of gathering as much information as possible given constraints, and communicating findings to a human operator. Planning is combinatorially hard, and planning problems involving metric resources, continuous time and concurrency, as would be required in the solution of non-trivial surveillance problems, are time-consuming to solve. This complexity is greatly exacerbated if uncertainty is captured explicitly within the planning domain models. Although online planning, and plan repair in the case of failure, are feasible in stable situations, they take too long in situations that are changing rapidly. Online planning also requires significant on-board computational resources, which are often not available in surveillance vehicles. Planning under uncertainty cannot therefore be done online in situations typical of many surveillance problems, where computational resources are limited and rapid responses are frequently required. On the other hand, forward planning is certainly required in order to avoid the observers behaving in a purely reactive (and therefore easily distracted) manner. \n\nSince online planning, and planning under uncertainty, are both unrealistic for large-scale, fast-moving surveillance problems, we propose an alternative approach based on plan-based policy-learning. We assume that time and resources are available offline to train effective policies. Our approach is based on Monte Carlo sampling: we sample many instances of the stochastic problem, each instance being a challenging temporal and metric planning problem. We then solve each instance using a high-performing planner, and then apply a classifier to learn a policy as a mapping from states to actions, using the set of solutions as input. We have already demonstrated the effectiveness of this approach in two single-agent cases: management of the loading of multiple batteries, and the control of an autonomous underwater vehicle following the edge of a patch (distinguished by high chlorophyll or high temperature readings) in the coastal waters of the Monterey Bay. We know from our work in both cases that the resulting policies can be very high-performing in terms of robustness to the high degree of uncertainty that often occurs in the physical execution environment. We are now proposing to scale up the approach we took in the batteries and patch-following cases, to the multi-agent coordination problem, addressing the challenges that arise when many agents are coordinating in solving a surveillance problem that requires the integration of multiple policies.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/J012157/1","grantId":"EP/J012157/1","fundValue":"370786","fundStart":"2012-09-01","fundEnd":"2016-02-29","funder":"EPSRC","impactText":"  The project is still underway, but has attracted interest from the aerospace and underwater autonomy sectors. We have been working in collaboration with BAE Systems, and have a jointly authored paper. Aerospace, Defence and Marine,Energy,Other Economic","person":"Maria  Fox","coPersons":["Derek  Long","Andrew Ian Coles"],"organisation":"King's College London","findingsText":" We have proposed a method for using forward search planning to undertake search-and-track missions under uncertainty. We use a search pattern based method, and plan search strategies over time. Our approach is more suitable than Bayesian methods when the search area is large and heterogeneous. We have extended our approach to handle probabilistic rewards, within a deterministic modelling framework. The project is not yet finished, so there remain some objectives still to complete. The approach we have developed is relevant in any context where autonomous vehicles are engaged in search and track missions. Aerospace, Defence and Marine,Creative Economy,Security and Diplomacy,Transport,Other","dataset":"gtr"}