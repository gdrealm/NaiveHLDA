{"id":"ECFFF4E5-BCF8-4AAA-9879-F6A43A949725","title":"Analysis of Facial Behaviour for Security in 4D (4D-FAB)","abstractText":"The overall aim of the project is the development of automated tools for automatic spatio-temporal analysis and understanding of human subtle facial behaviour from 4D facial information (i.e. 3D high-quality video recordings of facial behaviour). Two exemplar applications related to security issues will be specifically addressed in this proposal: (a) person verification (i.e. using facial behaviour as a biometric trait), and (b) deception indication. \n\nThe importance of non-obtrusive person verification and deception indication is undisputable - every day, thousands of people go through airport security checkpoints, border crossing checkpoints, and other security screening points. Automated, unobtrusive monitoring and assessing of deceptive behaviour will form a valuable tool for end users, such as police, justice and prison services. This is in particular important as currently only informal interpretations for detecting deceptive behaviour are used. In addition, the development of alternative methods for person verification that are not based on physical traits only but on behavioural, easily observable traits like facial expressions, would be of great value for the development of multimodal biometric system. Such multi-modal biometric systems will be of great interested to government agencies such as the Home Office or the UK Border agency.\n\nFor automatic deception indication we propose to develop methodologies for detecting 4D micro-expressions and their dynamics being typical of deceptive behaviour as reported by research in psychology. For automatic person identification we propose to increase the robustness of static face- image-based verification systems by including facial dynamics as an additional biometric trait. The underlying motivation is that the dynamic 4D facial behaviour is very difficult to imitate and , hence, it has natural resilience against spoof attacks. \n\nThe project focuses on 3D video recordings rather than on 2D video recordings of facial behaviour due to two main reasons: (1) increased robustness to changes in head-pose, and (2) ability to spot subtle changes in the depth of facial surface such as jaw clench and tremor appearance on the cheeks, which are typical of deceptive behaviour and cannot be spotted in 2D images. The research on 3D facial dynamics is now made possible by the tremendous advance of sensors and devices for the acquisition of 3D face video recordings.\n\nThe core of the project will deal with both the development of 4D-FAB research platform containing tools for human subtle facial behaviour analysis in 4D videos and the development of annotated data repository consisting of two parts: (1) annotated 4D recordings of deceptive and truthful behavior, and (2) annotated 4D recordings of subjects uttering a sentence, deliberately displaying certain facial actions and expressions, and spontaneously displaying certain facial actions and expressions. The work plan is oriented around this central goal of developing 4D-FAB technology and is carried out in 3 work packages described in the proposal.\n\nA team of 3 Research Associates (RAs), led by the PIs, and having the background in computer vision and machine learning, will develop 4D-FAB technology. The team will be closely assisted by 6 members of the Advisory Board:\nProf. Burgoon, University of Arizona, advising on psychology of deception and credibility\nProf. Cohn, Pittsburgh University / Carnegie Mellon University, advising on face perception and facial behaviometrics\nProf. Nunamaker, Director of BORDERS, US Nat'l Center for Border Security and Immigration, advising on making 4D-FAB useful for end users in security domain\nDr Hampson, Head of Science &amp; Technology, OSCT, Home Office, advising on making 4D-FAB useful for end users\nDr Cohen, Director of United Technologies Research Centre Ireland, advising on making 4D-FAB useful for end users \nDr Urquhart, CEO of Dimensional Imaging, advising on 4D recording setup design","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/J017787/1","grantId":"EP/J017787/1","fundValue":"1082120","fundStart":"2013-03-01","fundEnd":"2017-02-28","funder":"EPSRC","impactText":"","person":"Maja  Pantic","coPersons":["Stefanos  Zafeiriou","Daniel  Rueckert"],"organisation":"Imperial College London","findingsText":"","dataset":"gtr"}