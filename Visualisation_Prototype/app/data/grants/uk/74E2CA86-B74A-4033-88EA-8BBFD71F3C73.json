{"id":"74E2CA86-B74A-4033-88EA-8BBFD71F3C73","title":"Designing better hearing aids using physiologically inspired speech enhancement","abstractText":"Hearing aids can profoundly transform the lives of people with hearing impairments but in the UK alone about 6 million such people do not use them. An important reason for this is that conventional hearing aids don't make it easy to distinguish meaningful signals such as speech from background noise. The combination of a fully functioning ear and the brain are fantastically good at this job and easily outperform the best computerized speech-recognition apps when even just a small amount of noise is present. A conventional hearing aid amplifies both the speech and noise indiscriminately, so even though the neural pathways of the brain may be unimpaired the task of distinguishing speech from noise becomes much harder. Various approaches to automatic speech enhancement have been tried but none comes close to what nature can do.\nDespite the demand for better solutions, recent progress in research and development has been slow and no breakthrough technology has yet emerged. Speech enhancement strategies have been generally developed on the basis of mathematical, but not physiological principles. These methods, although based on fundamentally different strategies, have two things in common: first, they operate on signal features that rely primarily on the signals' local energy, and second, they have not improved speech intelligibility. Here, we propose overcoming this conceptual barrier by developing engineering solutions to the speech-in-noise problem that are based on physiological principles. The same technology will also be of benefit for automatic speech recognition systems, since the problems of both are similar.\nWe expect to see direct applications of our work to be implemented in hearing aids within the next 5 years. Two of the biggest companies in the world in their field (Siemens for hearing aids and Google for signal processing) demonstrate the interest, support and the confidence toward this approach. We have substantial experience with the whole development cycle: we have invented, designed, evaluated and implemented a noise reduction scheme that will be part of the next generation of Cochlea Ltd. cochlear implants. \nOur central hypothesis in this proposal is that the brain uses sparse coding when distinguishing meaningful signals from noise and it uses a dynamic dictionary for sound representation. We are going to investigate this coding mechanism in individual neurons in the auditory brainstem, and based on the results, will develop novel signal-processing strategies. We expect that these algorithms will be better than conventional algorithms and consequently can help hearing impaired. An animal model is essential to this project, because it is impossible to study responses of individual neurons from the auditory brainstem in humans. Sparse \nNeuron adapt their response because they have a limited dynamic rate which they constantly optimize in response to the environment in order to reduce redundancy and to maximise the information flow. In this project, we are going to extend the description of static neural response patterns to include a time varying and context sensitive components and we will measure these dynamic responses in single neurons in the brain stem. Knowing how neuronal responses change in noise will enable us to create a dynamic dictionary that can be used for sparsification. We expect that in this representation speech and noise is separable. \nWe will use these dynamic response pattern as the basis of a novel transformation and sparsification in order to enhance the components of speech that are relevant for understanding, thus improving speech intelligibility without reducing the quality. \nWe will evaluate the algorithm in substantial clinical trials.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/K020501/1","grantId":"EP/K020501/1","fundValue":"613105","fundStart":"2013-02-06","fundEnd":"2016-09-30","funder":"EPSRC","impactText":"","person":"Stefan  Bleeck","coPersons":["Matthew Christian Martin Wright","Thomas  Blumensath","Ian  Winter"],"organisation":"University of Southampton","findingsText":"","dataset":"gtr"}