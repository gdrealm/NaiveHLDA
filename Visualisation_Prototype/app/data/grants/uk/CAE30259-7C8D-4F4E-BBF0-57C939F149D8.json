{"id":"CAE30259-7C8D-4F4E-BBF0-57C939F149D8","title":"WhatIf: Answering &quot;What if...&quot; questions for Ontology Authoring","abstractText":"We have a richness of data about numerous aspects of our activities, yet these \ndata are only any use when we know what they are, agree upon what they are and \nhow they relate to each other. Semantic descriptions of data, the means by \nwhich we can achieve these aims, are widely used to help exploit data in \nindustry, academia and at home. One way of providing such meaning or semantics \nfor data is through &quot;ontologies&quot;, yet these ontologies can be hard to build, \nespecially for the very people that are expert in the fields whose knowledge\nis being captured but who are not experienced in the specialised &quot;modelling&quot; field. \n\nIn the &quot;what if...?&quot; project we look at\nthe problems of creating ontologies using the Web \nOntology Language (OWL). With OWL logical forms, computers can \ndeduce knowledge that is only \nimplied within the statements made by the modeller. So any statement made \nby a modeller can have a dramatic effect on what is implied. \nThese implications can be both &quot;good&quot; and &quot;bad&quot; in terms of the aims of the\nmodeller. Consequently, a \nmodeller is always asking themself &quot;what if...?&quot; questions as they model a field \nof interest. Such a question might be &quot;what happens if I say that a planet\nmust be orbiting a star?&quot; or &quot;what happens if I add in this date/time \nontology?&quot;. \n\nThe aim of the &quot;what if...?&quot; project is to\nbuild a dialogue system allowing a person building an ontology\nto ask such questions and get\nmeaningful answers. This requires getting the computer to determine what\nthe consequences of a change in the ontology would be and getting it to\npresent these consequences in a meaningful way. To do a good job,\nthe system will have to understand something about what the person is trying\nto do and what sorts of results will be most interesting to them. For this,\nwe need to understand more about \nhow ontologists model a domain and interact with tools; be able to model the \ndialogues between a human and the authoring system; achieve responsive \nauttomated reasoning that can provide the dialogue system with the information \nit nees to create that dialogue.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/J014354/1","grantId":"EP/J014354/1","fundValue":"542078","fundStart":"2012-09-17","fundEnd":"2016-06-30","funder":"EPSRC","impactText":"  IBM Italy has started to experiment with stream reasoning techniques delivered by the project.\n\niSOCO (Spain) are looking at our handling of Competency Questions to see it can be scaled up to a full Question Answering system. Digital/Communication/Information Technologies (including Software) Economic","person":"Kees  Van DeemterChristopher  Mellish","coPersons":["Jeff Z. Pan"],"organisation":"University of Aberdeen","findingsText":" It appears that ontology authoring can be made easier by computationally exploiting the presuppositions inherent in Competency Questions. We're developing a new interface, some aspects of which will have been tested. Many other aspects are yet to be tested.\n\nThe work is potentially applicable to all the areas below, as long as they have complex terminological information available in computer-readable form. Other","dataset":"gtr"}