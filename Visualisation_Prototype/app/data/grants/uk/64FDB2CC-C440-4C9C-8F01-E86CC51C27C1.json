{"id":"64FDB2CC-C440-4C9C-8F01-E86CC51C27C1","title":"Open3D: Collaborative Editing for 3D Virtual Worlds","abstractText":"Digital 3D models are used in almost all areas of design and engineering from drug discovery through to architectural design optimization. With the advent of new imaging technologies such as more advanced remote sensing systems and consumer 3D cameras, there is a new capability to capture models that are both deep and broad in detail.\n\nCurrently there is a range of different software packages for editing 3D data but each is rather specialised to its domain. If data is to be exchanged between different users then the most usual way of doing this is to export files from one machine, move the file and import it on another machine. This can be facilitated by various file-sharing systems, but the unit of access is a file on a local file system. This presents multiple problems: as models grow in complexity managing them in files becomes problematic, collaborative editing is very hard and tracking of changes becomes challenging. In addition in the next few years, we should expect 3D model sizes to grow in size and detail at increasing rates. This will be driven both by consumer editing and scanning tools, but also increasing use of commercially scanned and produced models. One can extrapolate from the current extensive but crude representations of cities on Google Earth, or the highly detailed, but ultimately limited in scale models in modern video games, to imagine that models will reach 10^9 - 10^11+ polygons in scale within the next decade.\n\nThere is a domain where collaborative access to large models has been solved: Internet storage of documents. Systems as diverse as Wikipedia and Google Docs demonstrate that by decoupling storage from viewing and editing, extremely large repositories of information can be built.\n\nIn Open3D we will design the necessary algorithms and services that allow the hosting of 3D models of such scale on the Internet. Such 3D models, however, are fundamentally different from text counterparts: 3D models extend across space (e.g. 2-manifold data), lack an obvious extrinsic parameterization, and can have large variations in local details; while, text documents have a natural linear ordering making them much simpler to work with. Our observation is that while models may be big, the spatial scope of an editing or visualisation is usually limited. Thus we can imagine a network protocol that can exchange model assets based on spatial queries, rather than file access. Further, we can imagine that we can perform locking and revision control on this model to prevent inconsistent model states across multiple editors. \n\nThrough Open3D's unique set of facilities we want to enable synchronous collaborative modelling of a unified model with the minimum of interference in the user experience. By doing this we hope to enable a new crowd-sourcing effort to develop large-scale models in a couple of domains. In particular, in our impact plan we target creating a virtual model of part of London, and an open access anatomical model of the human body.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/M013685/1","grantId":"EP/M013685/1","fundValue":"712097","fundStart":"2015-06-01","fundEnd":"2018-05-31","funder":"EPSRC","impactText":"","person":"Anthony  Steed","coPersons":["Niloy  Mitra","Anna L Cox"],"organisation":"University College London","findingsText":"","dataset":"gtr"}