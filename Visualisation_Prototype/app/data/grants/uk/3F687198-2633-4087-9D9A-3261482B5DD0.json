{"id":"3F687198-2633-4087-9D9A-3261482B5DD0","title":"Incorporating vertical disparity into computational models of depth perception","abstractText":"Our two eyes provide us with two slightly different windows on the world. Our brains combine these to give us a unified view of the world, while using the subtle differences between them to impart a rich perception of the world in 3D. Understanding this process will tell us more about perception in general, as well as suggesting how we might in future be able to help people in whom this process has failed, for example in squint. Our brains have developed very precise circuitry for controlling eye movements, in order to ensure that both eyes always look at the same thing and in order to minimise any vertical offsets between the images. When we look straight ahead, the two eyeâ€™s images differ only by horizontal offsets, reflecting the horizontal displacement of our eyes. However, when we move our eyes around a visual scene, small vertical disparities are inevitable. Does our brain predict the expected vertical disparities, given the current position of the eyes? Or does it simply allow for some range, treating vertical disparities as noise in the system? The answer will help us understand the sophisticated computations which underlie our effortless perception.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=G0601566","grantId":"G0601566","fundValue":"301248","fundStart":"2008-07-01","fundEnd":"2011-06-30","funder":"MRC","impactText":"","person":"JCA  Read","coPersons":[],"organisation":"Newcastle University","findingsText":"","dataset":"gtr"}