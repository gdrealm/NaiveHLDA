{"id":"8E0477C0-3CA3-40B5-BC13-899944E72676","title":"Amorphous computation, random graphs and complex biological networks","abstractText":"In this ``information age'', computation, communication and massive information handling have become the bread and butter of modern society. Internet networks, the web, and popular peer-to-peer networks are all examples of the transition we are witnessing from local, centralised computers to massive distributed networks of relatively low-power individual resources. These are our first glimpses of the amorphous computers of the future. More generally, amorphous computers include any large-scale network of computational units or processes that are connected through a flexible and constantly changing network of interactions. These may be swarms of microscopic robots or large sensor-arrays that monitor climate or pollution. The critically important feature common to these kinds of self-organising distributed systems is that the desired computation emerges and is not explicitly preprogrammed.The transition to amorphous computing brings with it enormous potential as well as risk (such as the virus epidemics that plague the internet). To exploit the advantages and avoid the dangers of amorphous computing, fundamentally new ways of coping with complexity are needed. To do so we plan to develop appropriate mathematical models and tools, on the one hand, and to derive appropriate engineering principles inspired by successful systems, on the other.One of the unifying features of amorphous computers is their active network structure. Thus, a natural mathematical entity for their description is the graph: a structure with nodes (processors) and edges (connections). Since by their very nature, the network structure of amorphous computers is non-prescribed, the study of random graphs is especially promising. To extend the theory of random graphs to real-world applications, new mathematics needs to be developed, including new families of random graphs, new tools for simulating their growth and dynamics and new methods for analysing the dynamics that takes place on these graphs. A key part of this proposal is the development of these tools and their application to specific models of amorphous computers, and ultimately to real systems (such as P2P networks and sensor arrays).One of the challenges of amorphous computing is to find useful analogies that provide insight into the requirements, capabilities and limitations of the systems at hand. In this proposal, we will draw inspiration from biological systems and the powerful computation they perform. Computational aspects of biological functions are found in almost any task: from evolution, though development, to information processing, and are evident on every level of organisation, including macro-molecules (e.g., protein folding), cells (e.g., regulatory networks of proteins and genes) and higher (neural networks and nervous systems). Built of microscopic, noisy and relatively unreliable components, biological systems are surprisingly effective and efficient. Unlike human-engineered computers, they are also dynamic and highly adaptive machines. They are typically distributed and decentralised, with each component following a set of local rules based on its environment to determine its actions. It is the emergence of a functional and coherent whole from an ensemble of simple and unreliable elements that we would like to capture for our own engineering purposes.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D00232X/1","grantId":"EP/D00232X/1","fundValue":"612868","fundStart":"2006-01-01","fundEnd":"2010-09-30","funder":"EPSRC","impactText":"","person":"Netta  Cohen","coPersons":["Martin Edward  Dyer","Colin  Cooper","Seth  Bullock"],"organisation":"University of Leeds","findingsText":"","dataset":"gtr"}