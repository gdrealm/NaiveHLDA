{"id":"AF6D24E3-238B-43B9-88C4-1AC4B0555540","title":"Classification decisions in machines and human brains","abstractText":"In our everyday interactions we encounter a plethora of novel experiences in different social contexts that require prompt decisions for successful actions. Extracting the key information from the highly complex input of the natural world and deciding how to interpret it is a computationally challenging task that is far from understood. In particular, our perceptual decisions are determined not only by the sensory evidence available but also by abstract rules that allow us to be flexible in interpreting novel experiences based on our previous knowledge about the likelihood of an event with a desired outcome, its social context, and the magnitude and rate of reward associated with the anticipated action choice. For example, deciding how to act (reserved vs. extroverted) when encountering an acquaintance depends on sensory evidence (we recognise the specific person or they simply appear familiar), our knowledge and feelings about this person based on previous encounters, the social context (business meeting or social event) and the reward associated with this social interaction (new friendship or partnership). We propose to examine the neural basis of perceptual decisions in complex, novel and uncertain environments that map sensory experiences into actions by bringing together interdisciplinary expertise in advanced mathematical approaches (i.e. machine learning), established behavioural methods and multimodal brain imaging (fMRI, MEG, EEG) techniques that allow us to study the human brain at work in real time. Our goal is to understand the neural computations that allow humans to make categorical decisions based on adaptive learning. This challenging problem of visual categorisation is known in engineering as the pattern classification problem. In this framework, we will examine how the human brain extracts important features from complex inputs and classifies them to meaningful perceptual categories by comparing the performance of human observers with that of statistical learning machines. The aim of this interdisciplinary project is threefold. First, we will develop and validate novel analysis methods for psychophysical and multimodal imaging data based on elegant mathematical approaches that test for feature selection and multi-dimensional classification in rich biological data sets. Second, we will use these machine classifiers as sensitive and powerful tools for decoding the internal representation of the physical world in the human brain. Third, we will optimise and constrain these algorithms based on biophysical models (human observers' performance, neural responses) that will allow closer comparison between machine and human classification and have direct applications for the design of artificial systems (e.g. expert systems for face, fingerprint or hand-writing recognition, gene or tumour classification). This collaborative work will initiate a new line of UK collaborative research that will bridge physical and biological sciences and provide novel insights and tools in understanding the link between behaviour and neural plasticity. Further, this research has implications for understanding the development of our social cognition functions, their disruption in ageing and neurological disorders and the potential for recovery of function through learning. In sum, the proposed work has strong potential for building and enhancing interdisciplinary, high-end, competitive research in the UK, improving the long-term quality of life through basic research with potential applications in engineering and medicine, and thus contributing to the general health and wealth in the UK.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=BB/E017436/1","grantId":"BB/E017436/1","fundValue":"936093","fundStart":"2007-04-01","fundEnd":"2010-10-31","funder":"BBSRC","impactText":"  The work advances our understanding of the human brain mechanisms that underlie our ability to learn. Our findings have potential applications in the development of training programmes tailored to individual needs in health (i.e. education, ageing) and disease (e.g. neurodegenerative disorders). Education,Healthcare Societal","person":"Zoe  Kourtzi","coPersons":["Si  Wu","Andrew Philip Bagshaw","Gareth Robert Barnes"],"organisation":"University of Birmingham","findingsText":" This is a Cognitive Foresight award that brings together experts in cognitive neuroscience (Kourtzi) physics (Barnes, Bagshaw) and mathematics (Wu) to understand the neural basis of perceptual decisions in the human brain. The proposal focuses on the development of a novel unified algorithmic approach based on machine learning systems for the analysis of multimodal imaging (fMRI, MEG, EEG) that will allow us to investigate quantitatively the link between physical input, neural processing, and human behaviour.\nDuring the first two years, this collaborative effort has resulted in several high-end publications across the team members focusing on computational (Neural Networks) fMRI (Neuron, J Neuroscience, J Neurophysiology) and MEG-EEG (NeuroImage, J Vision) studies as well as several presentations at UK and international meetings. Below we summarise the results from the main sets of studies completed as of now, while several other studies are still on-going. The methodology and findings emerging from this research provide the basis for current work in my lab that aims to understand the neural mechanisms that mediate experience-based plasticity in the human brain across the lifespan. \n\nComputational Studies: Our computational work (Neural Networks) focuses on statistical learning methods that are emerging as a valuable tool for decoding information from neuroimaging data. Noise in the brain imaging measurements and the limited number of training patterns typically recorded pose a challenge for the application of statistical learning methods in the analyses of brain data. To overcome this difficulty, we propose an approach of using prior knowledge from the behavioural performance of human observers in a task to enhance the training of Support Vector Machines (SVMs). Specifically, we collected behavioural responses from human observers performing a categorization task during scanning. We use the psychometric function generated based on the observers responses to different stimulus conditions as a distance constraint for training an SVM on the discrimination of brain imaging data (fMRI). Our findings confirm that this behaviour constrained SVM (BCSVM) outperforms standard SVM algorithms consistently. This methodology of constraining machine learning algorithms based on biophysical data allows closer comparison of machine and human classification performance.\nfMRI Studies: Our fMRI studies use advanced pattern classification techniques that take advantage of information across brain activation patterns to overcome the limitations of standard fMRI analysis methods and extract informative signals related to the perceptual interpretations of the visual input. \nIn a first set of studies (J Neurophysiology), we used these sensitive multivariate analysis methods to examine fMRI selectivity for global forms in the human visual pathways. We used Glass pattern stimuli, parametrically varying the perceived global form (concentric, radial, translational) whilst ensuring that the local statistics remain similar. Our findings demonstrate a continuum of integration processes that convert selectivity for local signals (orientation, position) in early visual areas to selectivity for global form structure in higher occipitotemporal areas. Interestingly, higher occipitotemporal areas discern differences in global form structure rather than low-level stimulus properties with higher accuracy than early visual areas while relying on information from smaller but more selective neural populations (smaller voxel pattern size), consistent with global pooling mechanisms of local orientation signals. These findings suggest that the human visual system employs a code of increasing efficiency across stages of analysis that is critical for the successful detection and recognition of objects in complex environments.\nIn a second set of studies (J Neuroscience), we asked which human brain areas contain information about diagnostic features that define perceptual categories and the rules that guide the observers' categorical decisions. In particular, we used psychophysics and fMRI pattern classification to predict the features critical for categorical decisions from brain activity when observers categorized the same stimuli using different rules. We reasoned that signals from brain areas encoding behaviourally relevant information would be decoded more reliably when we classify brain responses for stimulus categories based on the categorization rule used by the observers rather than a rule that does not match the perceived stimulus categories. Although a large network of cortical and subcortical areas contain information about visual categories, we showed that only a subset of these areas shape their selectivity to reflect the behaviourally relevant features rather than simply physical similarity between stimuli. Specifically, temporal and parietal areas show selectivity for the perceived form and motion similarity, respectively. In contrast, frontal areas and the striatum represent the conjunction of spatio-temporal features critical for complex and adaptive categorization tasks and potentially modulate selectivity in temporal and parietal areas. These findings provide novel evidence for flexible neural coding in the human brain that translates sensory experiences to categorical decisions by shaping neural representations across a network of areas with dissociable functional roles in visual categorization.\nIn a third study (Neuron), we investigated how category learning shapes decision processes in the human brain. We compared behavioural choices of human observers with those of a pattern classifier based on multi-voxel single-trial fMRI signals. Our findings show that category learning shapes processes related to decision variables in frontal and higher occipitotemporal regions rather than signal detection or response execution in primary visual or motor areas. In particular, fMRI signals in prefrontal regions reflect the observers' behavioural choice according to the learned decision criterion only in the context of the categorization task. In contrast, higher occipitotemporal areas show learning-dependent changes in the representation of perceived categories that are sustained after training independent of the task. These findings demonstrate that learning shapes selective representations of sensory readout signals in accordance with the decision criterion to support flexible decisions. On-going studies using simultaneous fMRI-EEG recordings investigate the temporal dynamics between occipitotemporal and frontal circuits that underlie the ability for flexible decisions. \nMultimodal Imaging Studies: The aim of these studies is to link EEG activity recorded in the fMRI scanner to the haemodynamic signals. The EEG signal measured on the scalp is a complex function of many (lead-field) parameters (such as conductivity and thickness of skull, scalp etc). These parameters vary from person to person. In contrast, the MEG is relatively insensitive to these parameters and has been shown to produce images which directly correspond to fMRI using very simple (single sphere or multiple local sphere) head models. The rationale is to tune the EEG lead-fields based on the MEG recordings using simple visual stimuli (already shown to correspond to fMRI images). Then to take these optimized lead-fields into the magnet. We have encountered a number of technical obstacles but are now at the point where we can produce EEG images, for simple visual stimuli, which concur with those obtained both with fMRI and MEG. In parallel with this activity we have examined pattern classification analysis of MEG/EEG recorded data on the same stimulus set (NeuroImage). This work shows that stimulus related information is not only contained in the electrical onset transient but also in the sustained oscillatory activity (or network state) that follows. This makes a robust link between the modalities all the more critical. The fMRI classifiers work on haemodynamic changes, but at this stage we do not know whether these changes are due to the network state, or the transient activity. Our on-going work shows that there appears to be both a behavioural and evoked response link to the pre-stimulus network state. The work advances our understanding of the human brain mechanisms that underlie our ability to learn. Our findings have potential applications in the development of training programmes tailored to individual needs in health (i.e. education, ageing) and disease (e.g. neurodegenerative disorders). Education,Healthcare","dataset":"gtr"}