{"id":"ED7E44E8-B86B-453E-8C14-C3D9293050F0","title":"Garbage Collection for Multicore Platforms","abstractText":"Developers are increasingly turning to languages like Java and C# for their ease of development, deployment and maintenance. Most applications for the foreseeable future will be written in languages supported by managed runtimes, running on multicore hardware. Particular benefits of managed runtimes include support for automatic dynamic memory management, or 'garbage collection' (GC) and threads. GC allows programs to recycle unused memory automatically, without error-prone programmer intervention. Threading allows a program to run different sequences of instructions in parallel; for instance, a web server might employ a separate thread for each incoming request from internet browsers.One of the most significant recent developments for language implementers is the development of multicore processors, with the number of cores deployed in commodity platforms expected to increase significantly over the next 5 years. The complexity of the processor's access to memory has also increased, in terms of levels of memory hierarchy and in the technology interconnecting processors. However, modern runtime technology has not evolved as fast as hardware technology, and how to fully exploit hardware parallelism remains an open question.This research asks, how can we exploit hardware parallelism, in particular by running multiple user program ('mutator') and GC threads? How can we avoid paying penalties for non-local memory access, but still benefit from multiple paths to memory? How can we take proactive advantage of locality properties? How can we minimise synchronisation between mutator and GC threads?Today's concurrent GC techniques avoid relocating live objects, so as to minimise the need for this synchronisation, but this leads to poor use of memory with many small holes but nowhere to accommodate larger objects ('fragmentation'). The standard fragmentation solution - periodic compaction phases - has high overheads, and often lacks portability or leads to throughput slumps before mutator threads can operate at full speed again. Memory management will be a bottleneck for the next generation of increasingly thread parallel software unless the problem of high performance GC for multicore can be solved. This proposal aims to address this key problem, reconciling compaction with concurrency and performance.We believe that the key to exploiting modern multicore architectures is a judicious division of effort between mutator and GC threads, in order not simply to avoid paying the price of accessing non-local memory, but proactively to process data while it is in the cache. It is almost always worth paying the cost of executing a few more instructions in order to avoid accessing non-local data. Thus, if a mutator thread is about to access data (and hence it is or soon will be in the cache), it should perform some GC work on that data immediately. Other data should be left to be handled by separate GC threads. At no time should all mutator threads be halted waiting for the collector. Our aim is therefore to provide high throughput and very low pauses, by utilising parallel copying collector threads, running concurrently and carefully coupled with mutators in order to leverage locality.This research will benefit GC researchers by broadening the design space and devising and evaluating new concurrent GC techniques, and developers in the broad community through enabling them to tune their applications and GCs to modern architectures. A high-performance GC tuned to modern multicore hardware will also lower the barrier to deployment of future software applications that expect to exploit multicore hardware fully. We will make all code developed freely available under an Open Source license. As well as disseminating our results through journals and conferences, we shall organise two workshops in order to build UK research strength in this field.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/H026975/1","grantId":"EP/H026975/1","fundValue":"383969","fundStart":"2010-09-01","fundEnd":"2014-02-28","funder":"EPSRC","impactText":"  Our findings have potential use for any organisation developing high performance garbage collectors. Our finding that, for certain special cases, software transactional memory may offer the same performance as Intel's hardware transactional memory extensions, while offering the advantage of portability, may have a wider application. Digital/Communication/Information Technologies (including Software),Education Economic","person":"Richard Elliott Jones","coPersons":["Frederick Robert Barnes"],"organisation":"University of Kent","findingsText":" 1) By comparing the cache behaviour of mutator insertion and deletion write barriers for concurrent/incremental collectors, in a VM, GC and hardware agnostic manner, we that deletion barriers generate more work for a concurrent GC than insertion barriers, but find that the time between triggering a write barrier on an object and subsequently using it can be much lower with a deletion barrier than an insertion barrier, suggesting that deletion barriers may lead to better cache performance than has hitherto been expected.\n\n\n\n2) Garbage collectors must update all references to objects they move. Updating is a lengthy operation but the updates must be transparent to the mutator running concurrently with the collector. The consequence is that no space can be reclaimed until all references have been updated. One solution is to replace direct references to objects with handles: these eliminate the updating problem and allow immediate reuse of the space used by evacuated objects.However, the execution time overhead of handles has led to them being abandoned by most modern systems. We demonstrate optimisations for handles that nearly eliminate their overhead compared with other widely used real-time collectors.\n\n\n\n3) Increasing levels of hardware parallelism are one of the main challenges for managed runtimes. Any concurrency or scalability improvements must be evaluated experimentally but application benchmarks available today may not reflect the highly concurrent applications we anticipate in the future and may also behave in ways that VM developers do not expect. We provide a set of platform independent concurrency-related metrics and an in-depth observational study of current state of the art benchmarks, discovering how concurrent they really are, how they scale the work and how they synchronise and communicate via shared memory.\n\n\n\n4) Experimental evaluation is key to systems research. Because modern systems, and especially concurrent systems, are complex and non-deterministic, good experimental methodology forces researchers to account for uncertainty. Unfortunately the standards of reporting in computer science are often poorly by comparison with other disciplines. One cause may be researchers' reluctance to spend large amounts of time conducting experiments in order to account sufficiently for variation. This paper provides for the first time a statistically rigorous methodology for repetition and summarization of results methodology for repetition and summarization of results. Time efficiency comes from two key observations. First, a given benchmark on a given platform is typically prone to much less non-determinism than the common worst-case of published corner-case studies. Second, repetition is most needed where most uncertainty arises (whether between builds, between executions or between iterations of a program). We capture experimentation cost with a novel mathematical model, which we use to identify the number of repetitions at each level of an experiment necessary and sufficient to obtain a given level of precision. We present our methodology as a cookbook that guides researchers on how to obtain reliable results. Our work is of significance to any vendor of managed runtime languages, such as Java or C#. We plan to make our tools and data open source in order to provide the greatest benefit to the community, academic and non-academic. Digital/Communication/Information Technologies (including Software)","dataset":"gtr"}