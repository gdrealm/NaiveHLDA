{"id":"4FAA567F-1839-4C87-90BD-C7B7303FFCAE","title":"Long-term, High Order Visual Mapping","abstractText":"By observing a static scene with a moving video camera, it is possibleto estimate the trajectory of the camera through the environment,simultaneously build a map of the environment simply by repeatedobservation of the motion of visual features in the videoimages. The robotics community generally refers to this problem asvision-based Simultaneous Localisation and Mapping (SLAM) and thecomputer vision community calls it Structure From Motion (SFM).It is currently possible perform real-time camera localisation andmapping (i.e. visual SLAM) in a small environment on any modernlaptop, suitable for applications such as augmented reality orproviding visual odometry to a service robot. However, currently themaps that are built to enable localisation are usually short-lived,difficult to interpret by a human, and are rarely re-used by devicesother than the ones used to build the map. These maps are also easilycorrupted by moving objects or other dynamics such as cyclic changes.A significant challenge now faced is to build maps that can adequatelyrepresent a non-static environment by taking account of movingobjects, evolve over long periods of time, and provide more usefulrepresentations of the world with high level information. Applicationswhich would benefit from the longer lasting, semantically meaningfulmaps include: personal robotics and assistive devices, beneficial inan aging society to confer greater independence to the infirm; changedetection for military and civilian surveillance such as in IED(imporvised explosive device) detection; driver assistance tools, forautomatic reasoning for vehicles in complex and clutteredenvironments. Our research therefore aims to address fundamentalissues in visual mapping in order to provide sound underpinnings forthe above commercial applications. More specifically, the focus ofthe current proposal is:(i) to build representations that can be updated to take into accountchanges in appearance and structure and be used by different visualsensors;(ii) to investigate representations and algorithms for extraction ofhigh-level semantic information to improve the mapping process,develop scene understanding, to provide a more natural interface tocognitive processing.The use of a mobile observer taking continuous measurements of theenvironment provides opportunities for learning and leveraging contextin novel ways. We aim to achieve our goals through combined use ofgeometric data (map), photometric data (the image stream) andhigh-level contextual information (in which observations areunderstood in terms of their relationship to the bigger picture ).In doing so we expect to build an environment model not as a simpleunstructured point cloud, nor as a flat collection of visual featuredescriptors, but as a semantically meaningful hierarchy. Such arepresentation would clearly be of great benefit for high-levelreasoning and human interaction. Moreover we argue that it is onlythrough such higher-level representations that the robustness requiredfor truly long-term mapping will emerge.We aim to support these theoretical and practical advances inalgorithms and representations for visual mapping, with real, robustimplementations, which run in real-time.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/H050795/1","grantId":"EP/H050795/1","fundValue":"767540","fundStart":"2010-06-10","fundEnd":"2014-06-09","funder":"EPSRC","impactText":"","person":"Ian  ReidDavid William Murray","coPersons":[],"organisation":"University of Oxford","findingsText":"","dataset":"gtr"}