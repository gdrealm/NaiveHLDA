{"id":"FE28B9C9-C2A2-4F43-8E63-BA7977D44EFD","title":"Emotion Classification in Contempory Music","abstractText":"The aim of the project is to develop software which can automatically classify the emotional content of any piece of music. The recent increase in popularity of large personal digital music collections and online music retailers has led to a need for new, interactive access methods. Current interfaces to large music databases only allow users to search for music by genre, artist, or similarity to other music items.There is very little research in the area of automatically extracting the emotional content of music. Existing methods have been tested only on classical music pieces, and these algorithms have tended to rely on a fairly limited set of musical features. There is a variety of music features such as mode (a given series of musical intervals), tonality (the relationship between pitches in the music), and pitch (perceived frequency) which are key to expressing emotion in the composition of music. The project aim is to develop software that uses these features to more accurately identify the emotional content of any piece of musicAllowing the user to browse for music by its emotional effect represents a step toward addressing the needs and preferences of the user in music information retrieval. This technology will allow the user to easily select a subset of their own personal music database to suit their current mood. Software like this is a good example of how technology can seamlessly merge into our daily activities.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/F00558X/1","grantId":"EP/F00558X/1","fundValue":"82245","fundStart":"2007-11-01","fundEnd":"2010-10-31","funder":"EPSRC","impactText":"  The findings from my research have been cited in the academic research of others. This has crossed disciplines, has been predominantly in the are of music psychology, and has influenced research in the area of health and wellbeing.  ","person":"Donald  Knox","coPersons":["Raymond  MacDonald"],"organisation":"Glasgow Caledonian University","findingsText":" This project aimed to develop audio signal analysis algorithms which automatically classify music in terms of the emotion it expresses. The project focused on the analysis of digital audio files with the aim of extracting a large number of acoustical and structural parameters. This stage of analysis is followed by statistical classification schemes used to group these parameters in terms of their importance to the expression of musical emotion. In particular, this project concentrated upon western contemporary music - this being both the most popular with listeners, and difficult to classify by automatic means.\n\nA main output from the project is the development of emotion classification algorithms, which more accurately label popular music for emotion. Another output is identification of an audio analysis feature set most salient to the expression of emotion in western contemporary music. A full description of the operation of these algorithms is presented in published outputs, both complete and in preparation. \n\nAn key route this research has taken recently is the analysis and mood classification of music chosen by participants in psychological studies of music listening for health and wellbeing. For example the use of preferred music listening in studies of pain perception and tolerance. The algorithms allow analysis of music used in these experiments in unprecedented detail, and allow examination of the role of particular acoustical parameters and expressed emotion in music chosen to be particularly beneficial as regards reduction of anxiety and tolerance of pain. The findings are discussed in the Journal of the Acoustical Society of America (Knox et al, JASA Vol. 130, No. 3. Sept 2011). Music browsing and recommendation technology is a key area where the techniques developed in this project may have potential commercial benefits. A key means by which listeners access music is through large online music databases such as Spotify and Last.fm. These systems host millions of songs, and are dependent upon music recommendation algorithms which seek to recommend music to the listener. This recommendation might be made on the basis of the content of the music, the music choices of peers, and so-on. A key reason given for music listening is ‘how it makes me feel’, and emotion expressed by the music plays a role in influencing the music choices made by the listener. Digital/Communication/Information Technologies (including Software),Healthcare","dataset":"gtr"}