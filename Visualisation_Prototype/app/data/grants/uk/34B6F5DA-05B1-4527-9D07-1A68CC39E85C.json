{"id":"34B6F5DA-05B1-4527-9D07-1A68CC39E85C","title":"Vocal Learning in Adulthood: Investigating the mechanisms of vocal imitation and the effects of training and expertise.","abstractText":"We are genetically programmed to acquire spoken language from our environment, and infants can master native pronunciation in multiple languages without explicit tuition. However, in adolescence and adulthood we have a limited capacity to achieve accurate pronunciation of unfamiliar languages, and even highly competent users of a language learned in adulthood might speak with a strong, non-native accent. The UK currently lies behind other EU nations in foreign language skills at school and in the workplace, therefore research into skill development has important educational and economic implications.\n\nPrevious research has used functional MRI to measure how the activity of functional systems in the brain changes as new speech sounds are learned. This work has described the integration of novel speech sounds into a talker's existing speech repertoire as it becomes more familiar. Within this, however, some talkers are more successful than others at attaining native-like pronunciation of new sounds, and this variability is correlated with the activation, size and structural composition of specific brain structures.\n\nTo date, the cognitive neuroscience of speech learning has assessed performance by measuring or judging the sounds of speech. However, there isn't a simple one-to-one relationship between how speech sounds in the air, and the underlying movements in the vocal tract. Therefore, an important missing piece of the puzzle is an understanding of how vocal articulations relate directly to brain activation during learning. Recent developments in MRI have shown that rapid 'real-time' anatomical scans can be used to create videos of the interior of the mouth and vocal tract, such that we can view how the lips, tongue and voice box are moved and configured to perform speech. We propose to combine real-time MRI with measures of brain structure and function to investigate the relationship between brain and behaviour during the learning of new speech sounds.\n\nOur project will focus on short-term learning of novel and unfamiliar vocal sounds by native speakers of English, where the participants will aim to imitate the sounds accurately and with native-like pronunciation. In an MRI scanner, listeners will repeatedly produce these novel sounds, as well as native sounds of English, while scans of the brain will measure neural activity. Interleaved with these scans, we will collect real-time images of the vocal articulators during imitation. Acoustic recordings will be made using an in-scanner microphone, and we will additionally collect high-resolution images of brain structure from each participant. With these data, we will investigate vocal learning in terms of i) the functional brain systems supporting learning, ii) the acoustic accuracy of vocal output and iii) the accuracy of the movements generating the sounds, as well as the relationship between these elements. Further, we can explore how individuals differ in their performance of vocal learning in terms of meeting these acoustic and motor targets, and how this relates to their brain structure and function. Across a series of experiments, we will also investigate how novel sounds are sequenced into new words, and assess the effects of expertise on vocal learning by comparing English speakers with highly-proficient students of modern languages and professional beatboxers.\n\nOur proposed approach is truly novel, with potential to make groundbreaking developments in the cognitive neuroscience of vocal communication. To deliver the project, we have assembled a uniquely qualified research team with shared and individual expertise in phonetics, cognitive neuroscience and MRI. The data will directly inform our understanding of language learning and accent acquisition. Further, our new methodology has potential future application to other questions, such as the assessment of brain and behaviour relationships in patients with speech impairments following brain injury.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/L01257X/1","grantId":"ES/L01257X/1","fundValue":"364898","fundStart":"2015-01-12","fundEnd":"2018-01-11","funder":"ESRC","impactText":"","person":"Carolyn  McGettigan","coPersons":["Marc Eric Miquel"],"organisation":"Royal Holloway, University of London","findingsText":"","dataset":"gtr"}