{"id":"AF98B59A-A54A-4973-9992-1CA54F060FCF","title":"Neuromorphic Sensorimotor Integration for Legged Locomotion (NSILL)","abstractText":"During walking, a robot must use several senses to guide its movements. For example, it may need to avoid obstacles, to lift its legs over bumps, or to take a longer stride to avoid a gap. Basic reflexes respond to direct contact (or lack of contact) with uneven ground, but walking would be aided by sensing the ground surface variation or obstacles in advance. It would help to literally see what is ahead . In living animals, walking patterns often depend on a Central Pattern Generator (CPG) to generate a regular gait. The CPG output must, however, learn to control walking on complex and unfamiliar terrain - it must use the animal's senses to adjust walking patterns. Alternatively, the patterns might emerge from distributed control in which each leg influences its neighbours. This approach might be advantageous when the 'pattern' becomes very irregular due to complex terrain.These biological solutions to the problem of walking suggest engineering solutions for walking robots. We will design and build biologically inspired systems using analogue/digital silicon chips, controlling a 6-legged robot. There are three research strands. 1) A CPG chip that learns to generate adaptive walking patterns. Biological CPGs are extremely flexible for producing different rhythms. Neuromodulators, central commands and input signals all influence the pattern produced by a CPG. They do so by altering both the electrical and chemical properties of individual neurons and the coupling between different groups of neurons. For example, visual inputs can cause an animal to break into a gallop. We have previously developed a CPG circuit capable of producing a wide range of animal gaits. We will now build this novel CPG in silicon and test it on a 6-legged insect-like robot, designed and built during the project. We will then evaluate its ability to produce sufficiently flexible output to deal with complex terrain, and compare it to a more distributed control system, or to a suitable hybrid of these two forms of walking control.2) A vision chip that estimates the distance to objects in an image. Neuromorphic vision sensors have been built for edge detection, velocity- and depth-sensing. These are, however, isolated case studies that do not integrate vision with other senses for robotic applications. We will design a silicon chip that implements a novel vision depth sensing method, developed under a previous grant and based on a spiking neuronal model. This stylised early vision model will consist of a 2-D array of light-sensitive transistors with the ability to perform both edge sensing and depth detection. 3) A biologically-inspired chip that integrates senses to make decisions. This chip will combine the output of the visual processor (detected objects and their depth) with additional senses (touch and joint angle sensors) to adjust the walking patterns to achieve smooth, stable movement across rough ground. In particular it will learn to use the visual depth information to anticipate movements required to avoid collisions and maintain stable footing. We will test the methods in simulation, then use software on microprocessors to test the results on real robots. We will then create a chip which will translate the sensors' view of the world into appropriate modulation of the walking controller. The final stage of the project will be the integration of all three chips on to the 6-legged robot to produce a new walking robot with explicit biological antecedents. The project will thus advance research in neuromorphic VLSI and sensor-motor integration, with direct applications in mobile robots for domestic applications and work in hazardous, difficult and unknown environments. It will also help to identify some of the basic computing and control principles in the nervous system.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/E063322/1","grantId":"EP/E063322/1","fundValue":"856352","fundStart":"2007-10-01","fundEnd":"2011-06-30","funder":"EPSRC","impactText":"  They have not yet been used, as the robot system was not completed during the time of the p[project.  ","person":"Alan  Murray","coPersons":["H Martin Reekie","Barbara  Webb","Robert Kerr Henderson"],"organisation":"University of Edinburgh","findingsText":" The key finding was that it is possible to control leg movement in an insect-like robot using a neurally-inspired algorithm implemented as a neuromorphic silicon chip. Further development work would put the entire robot system together and thus create a flexible, robust system for locomotion in hazardous and unpredictable environments (eg defence or industrial decontamination). Aerospace, Defence and Marine,Construction","dataset":"gtr"}