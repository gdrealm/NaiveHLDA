{"id":"DEA12FE7-DB53-4BB5-B311-CAAE42F007C5","title":"Hybrid Static / Dynamic Optimisations for Many-Cores: Breaking the Memory Wall","abstractText":"Fueled by an exponential growth in computing capacities, society's reliance on information and computer systems has grown to encompass most activities and aspects of our lives. Mobile computing devices alone are set to outnumber humans in 2014, each such device providing more computational power than the supercomputers used to put men on the moon. Yet despite this exponential growth, society still hungers for more: consumers want new and improved smartphones and computers; scientists want to run more precise simulations, solve bigger problems or get results faster; we explore new computationally intensive technologies to bring forward the next generation of tools, from self-driving cars to robotic surgery. However, the &quot;free lunch&quot; is over: processors are no longer getting faster. Hard physical limits, such as energy and power density, have brought this success story to an abrupt end. To avoid this impasse, all major manufacturers are now offering an exponentially increasing number of processing units, or cores, per chip.\n\nWith ubiquitous parallel hardware and stagnating single processor performance, the only way forward is to improve the scalability and efficiency of parallel execution. In this context, the critical impediment to performance is the widening gap between the computing capabilities of many-core architectures and their limited off-chip memory bandwidth: the memory wall. Traditional solutions attempt to reduce off-chip communications by improving data locality, which means that computations are scheduled in such a way that intermediate results are not sent back to main memory and then re-loaded on chip. Common approaches are either static, with an optimising compiler determining a program schedule such that all intermediate results fit within the available cache memory, or dynamic, when a runtime environment builds the schedule during execution.\n\nThe main criticism of these techniques is that: (1) static approaches are very limited in scope, only applicable to restricted classes of computations; and (2) dynamic approaches are unaffordable, as finding the optimal schedule is generally more expensive than the gain. Current state-of-the-art approaches favour inexpensive dynamic heuristics, albeit imprecise and sub-optimal. The research hypothesis of this project is that near-optimal dynamic schedules can be built efficiently, provided that the work is partitioned between the compiler and the runtime system. Alone, the compiler cannot optimise many important programs due to static analysis shortcomings when dealing with recursion or complex, dynamically allocated, data structures. However, if the compiler performs best effort static optimisations and prepares the ground by providing the runtime environment with tractable subproblems, which are cheap to solve with the accurate information typically available during execution, then such a hybrid optimisation scheme becomes profitable and will lead to significant performance and scalability gains.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/M004880/1","grantId":"EP/M004880/1","fundValue":"99988","fundStart":"2015-03-02","fundEnd":"2016-06-01","funder":"EPSRC","impactText":"","person":"Antoniu  Pop","coPersons":[],"organisation":"The University of Manchester","findingsText":"","dataset":"gtr"}