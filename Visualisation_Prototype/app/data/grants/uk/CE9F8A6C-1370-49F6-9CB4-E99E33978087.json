{"id":"CE9F8A6C-1370-49F6-9CB4-E99E33978087","title":"Perceptual Sound Field Reconstruction and Coherent Emulation","abstractText":"The project is concerned with the development of a new 5--10 channel audio technology which would improve over existing ones in terms of (a) realism, (b) accuracy and stability of the auditory perspective, (c) size of the sweet spot, and (d) the envelopment experience. Since the new technology aims to create a 360 degrees auditory perspective, the reproduction will take place over speakers positioned at vertices of a regular polygon. Each speaker will consist of two components, one which will radiate the direct sound field toward a listener, and another which will reproduce diffuse sound field by introducing additional scattering. The goal of the particular tasks, listed below, is to find optimal ways to capture sound field cues and render them using the proposed playback system in a manner which would provide the most convincing illusion of the original or desired sound field.(i) Optimal microphone arrays for the proposed play-back system will be investigated. Arrays considered will consist of microphones placed in the horizontal plane at the vertices of a regular polygon, with the number of microphones equal to the number of speakers. For each array, different diameters, in the range from near coincident up to somewhat beyond the optimal value, and different microphone directivity patterns will be considered. These studies will be repreated for a few diameters of the speaker configuration to investigate if the optimal array diameter depends on the size of the speaker lay-out, and if so to characterize that dependence. Possible dependencies between the optimal microphone directivity patterns and array diameters will be also investigated and characterized. Arrays will be evaluated in critical listening tests according to criteria (a)--(d) stated in the above. Experiments will be guided by simulations which would provide initial objective assessment of ITD and ILD cues generated within the listening area. In parallel, mathematical models of sound fields generated by the proposed technology will be investigated, which could provide some additional insight into the optimal microphone array design. (ii) The impact of play-back with cross-talk cancellation will be be systematically investigated. Existing cross-talk cancellation algorithms will be first used, and if necessary, new algorithms which are numerically efficient and effective in a range of listening environments will be developed. Then optimal microphone arrays for play back with cross-talk cancellation will be investigated, i.e. the work described under (i) will be repeated for reproduction with cross-talk cancellation. Finally, optimal systems with and without cross-talk cancellation will be compared.(iii) Algorithms for direct/diffuse sound field separation will be studied. When the number of instruments does not exceed the number of microphones, multichannel equalization techniques can be used to find dry source signals, which can then be convolved with direct/reverberant parts of room impulse responses to obtain direct/diffuse sound field components, respectively. Multichannel equalization in audio is, however, particularly challenging owing to excessively long impulse responses, and we will develop numerically efficient algorithms for multichannel equalization for audio applications. Then we will study psychoacoustic approximation to direct/diffuse sound field decomposition with no restriction on the number of sources. (iv) Combinations of near-coincident directional microphone arrays, for acquiring direct sound field cues, and widely spaced arrays based on omni-directional or bi-directional microphones, for acquiring diffuse sound field cues, will be systematically investigated in critical listening tests according to criteria (a)--(d). This approach will be evaluated in comparison with the approach described in (i)--(iii) where the same array is used for both sound field components.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/F001142/1","grantId":"EP/F001142/1","fundValue":"389807","fundStart":"2008-02-18","fundEnd":"2011-08-17","funder":"EPSRC","impactText":"  The project was of the fundamental research nature, so it hasn't produced non-academic impact yet, but there is a high potential for impact outside of academe. It was was concerned with multichannel systems for perceptual sound field synthesis and reproduction. The field of spatial sound has so far been mainly geared towards creating special effects and providing a pleasing listening experience, rather than rooted in solid engineering or science. We established a scientific framework for the analysis and design of multichannel systems based on concise modelling of underlying psychoacoustic phenomena. That framework enabled the development of a new multichannel audio technology which improves over state-of-the-art systems in terms of accuracy and stability of the auditory perspective. We also developed a super-real-time software implementation for virtual reality applications, based on further psychoacoustic approximation, as well as a new class of underlying microphones. The initial motivation for this work was the recording of music performances that allow for convincing spatial reproduction and broadcasting. It turns out, however, that a much larger market for our technology lies in virtual reality applications, including gaming, as well as augmented reality as pursued by Google. Contemporary composers, too, are frequently attempting to place their sounds within a specific auditory landscape. Archaeologists, anthropologists, and art historians are trying to recreate the acoustics of important historical venues. We will therefore endeavour to engage in multidisciplinary collaborations involving ICT (i.e. spatial sound) and music, and the humanities, as well as reaching out to the rich cultural and entertainment milieu of London and engage with institutions like the Royal Opera House, Royal Festival Hall, and Tate Modern in joint projects involving sound recording, music, and multimedia performances and installations.\n\nWhile commercial impact hasn't materialised yet, several companies have shown interest in our intellectual property arising from this project.  ","person":"Zoran  Cvetkovic","coPersons":[],"organisation":"King's College London","findingsText":" There are several key findings of the project:\n\n1) The first scientific and systematic framework for the design of multichannel audio systems based on perceptual criteria.\n\n2) A particular class of multichannel systems for recording and spatially convincing reproduction of acoustic performances.\n\n3) A method for modelling the perception of locatendess of phantom sources created by multichannel systems.\n\n4) A new class of high practical high order differential microphone.\n\n5) A method of super-real-time rendition of perceptually convincing reverberation of acoustic spaces.\n\n6) It has been demonstrated that non-coincident microphone arrays are capable of capturing song field cues needed for its spatially stable reconstruction. Outcomes of this research are directly applicable to a wide range of multichannel audio technologies, from performance recording for record labels, sound production for film, and broadcasting, through gaming, virtual and augmented reality, to acoustics simulation in architectural design and microphone manufacture. This research lays down scientific foundations for research in the direction of perceptual sound field reconstruction using low-count multichannel systems. It further provides a new class of microphones which opens up possibilities for new developments in sound recording technologies. Creative Economy,Digital/Communication/Information Technologies (including Software),Electronics","dataset":"gtr"}