{"id":"7E485C46-6022-4B29-979C-D5E5FB0A7CE1","title":"'Hate' Speech and Social Media: Understanding Users, Networks and Information Flows","abstractText":"<p>This project aims to study the 'social media ecosystem' to better understand how the complex combination of user behaviours, global communication networks, and flows of information interact to promote hateful and socially disruptive content.</p>\n\n<p>The project will empirically explore the balance between community, social cohesion, identity and freedom of speech within digital society, economy and culture. Policy makers, commercial providers and relevant regulatory agencies require empirical data and social scientific interpretation in order to shape policy formulation, intervention and inform wider debates about the emerging contours, rights and obligations of digital citizenship in a 21st Century Democracy.</p>\n\n<p>This project will contribute to this emerging civil requirement. The main deliverable of the project will be a computational tool, informed by social science knowledge, that will allow users to forecast the spread of hateful content over digital networks, providing an opportunity for intervention before such content 'goes viral' potentially causing harm to individuals, minority groups and communities. This digital tool will be hosted alongside others on the Collaborative Online Social Media ObServatory (COSMOS) and will generate computational social scientific insight into antagonistic online behaviour.<br /><br />&nbsp;<br /><br />&nbsp;<br /><br />&nbsp;<br /><br />&nbsp;</p>","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/K008013/1","grantId":"ES/K008013/1","fundValue":"100213","fundStart":"2013-03-31","fundEnd":"2014-08-30","funder":"ESRC","impactText":"","person":"William  Housley","coPersons":["Peter  Burnap","Alexander  Voss","Omer  Rana","Rob  Procter","Matthew Leighton Williams","Adam Michael Edwards","Vincent  Knight"],"organisation":"Cardiff University","findingsText":" Hate Speech and Social Media: Understanding Users, Networks and Information Flows\n\nBackground\nThe rapid and widespread uptake of social media platforms such as Twitter, Facebook and YouTube has created new ways for people to interact and to share information. This brings both benefits and risks for civil society and new challenges for agencies responsible for ensuring the boundaries of acceptable and legal behaviour are not crossed and, if they are, that appropriate action is taken. In this respect, the proliferation of so-called 'hate speech' in social media is an area of growing concern, as recent high profile examples confirm. The most senior prosecutor in England and Wales recently acknowledged the harm that can be caused by hate speech on social media and explained that &quot;banter, jokes and offensive comment are commonplace and often spontaneous&quot; and &quot;communications intended for a few may reach millions&quot; (BBC, 2012). For the social sciences, the migration of hate speech to social media platforms affords new opportunities to study hateful and antagonistic behaviours, to understand the impact of social media and to identify ways in which agencies can respond more effectively to its threats and consequences. \n\n\nThe key substantive research questions of the project are:\n\na. Can we identify hateful and antagonistic social media content, as well as attempts to counter it, in terms of key events, linguistic characteristics, sentiment and tension?\nb. Can we profile hateful and antagonistic social media networks in relation to user behaviour and interaction, building on the previous question to develop a typology of users (e.g. antagonists, influencers, propagators, reactors etc.)?\nc. Can we triangulate the above analysis with other forms of open data, such as new Google Trends metrics to validate the propagation of hateful content into online environments beyond social networks?\nd. Can we utilise the data derived from the above questions to build a probabilistic modeling methodology using Bayesian Belief Networks that could forecast the emergence and evolution of information flows (Procter et al., 2013) within social media networks through which hate-related content is transmitted? \ne. Can the model and methodology inform the social scientific interpretation of how hateful content travels and is impeded online, drawing on social scientific concepts such as responsibilisation (Garland, 2001) and nodal governance (Shearing &amp;amp;amp;amp; Wood, 2007) as framing devices? \n\nUnderpinning the aims and research questions is a particular approach that the interdisciplinary team (Social Science and Computer Science) of applicants have developed over the past two years, which has been termed Collaborative Algorithmic Design (Edwards et al. 2013, Housley et al., 2014). This involves the combination of measurement; construct validation; and interpretation through an iterative process. For example, operationalising social science theoretical propositions through the practical design and codification of computational tools and methods, which in turn produce results that are subjected to further critical interpretation and refinement.\n\n\n\nSignificant new knowledge generated \n\no Identified five equality strands for inclusion in study (race, religion, disability, sexual orientation and gender)\no Identified five corresponding 'hate-speech' antecedent trigger events that generated a significant amount of Twitter traffic. \no Built an ensemble machine classifier to identify tweets containing hateful content in each equality strand (See IPP paper:http://ipp.oii.ox.ac.uk/2014/programme-2014/track-a-harnessing-the-crowd/modelling-and-prediction/pete-burnap-matthew-l-williams-hate) \no Built models to predict the size and survival of hateful information flows\no Found that online hate speech did not propagate beyond 48 hours following the Woolwich terror attack\no Social factors, rather than content or temporal factors of the tweet explained the most variance in both size and survival dependent measures\no An increase in 100 Google searches for the term 'Woolwich' increased the rate of retweets by a factor of 1.50 (50 per cent)\no An increase in 100 news headlines about the event increased the rate of retweets by a factor of 1.05 (5 per cent)\no Tweets containing positive sentiment were statistically more likely to propagate in terms of size and survival\no Tweets continuing hashtags and URLs were also more likely to be retweeted\no Tweets containing hateful content were less likely to contain URLs but more likely to contain hashtags\no In the size model Far Right Political Agents were the least likely to be retweeted in volume (besides Other Agents)\no Tweets emanating from far right political agents (e.g. BNP) were the most likely to survive longest 36-42 hours after the event, at which point they lost ground to political agents, news agents and other agents, whose information flows lasted the longest in the study window (14 days)\no Information flows emanating from Police Agents outlast all other agents but the Far Right in the 36-42 hour window\no In summary, information flows emanating from Police Agents following the terrorist event were most likely to be large and to be long-lasting (bar the Far Right) in the impact and inventory periods (Cohen 1972) following the terrorist attack, while information flows emanating from Far Right Political Agents were likely to be small in size, but the most long lasting in the same periods \no The five corpora contained evidence of counter-speech that has been analyzed using relevant Discourse Analytic methods in order to generate relevant 'actor' and 'activity' typologies for counter- hate speech.\no The qualitatively generated typologies of counter hate-speech have been used to configure the human coding exercise that has informed the building of a counter- hate speech classifier for each equality strand.\no Advanced empirically informed theoretical understanding of social media and hate speech e.g. the role of issue attention cycles and interactional chains on social media.\n\nNew or improved research methods or skills developed \n\no Developed a hate speech classifier using an ensemble of machine learning techniques (see IPP paper:http://ipp.oii.ox.ac.uk/2014/programme-2014/track-a-harnessing-the-crowd/modelling-and-prediction/pete-burnap-matthew-l-williams-hate). \no Applied zero-truncated and zero-inflated negative binomial regression models to predict the size of information flow propagation following trigger antecedent events to hate speech on Twitter.\no Applied Cox proportional hazards and Kaplan Meier estimation to determine the survival of information flows following trigger antecedent events to hate speech on Twitter.\no A twitter 'thread' capture digital tool has been developed through this project and incorporated on the COSMOS platform. This was developed in order to capture twitter threads and exchanges that concerned hateful and antagonistic content. The COSMOS platform was released in September, 2014.\no Applied computer assisted Discourse Analytic techniques to counter-hate speech Twitter threads.\no The project has developed a mixed methods (Qualitative and Quantitative) approach to social media research.\no We have pioneered and explored the use of crowdsourced human coding techniques for feature identification in ways that inform machine learning techniques and classifier development for sociologically informed analyses of social media information flows.\n\nImportant new research resources identified \n\no Identified Twitter data archive as a key source of information that can be repurposed to serve the needs of the social science community in the pursuit of understanding contemporary social problems as part of COSMOS programme. \n\nImportant new research questions opened up \n\nOne of the most important and new research questions opened up is the extent to which social media is self-regulating in the context of hate speech and other forms of 'digital wildfire'.\n\nParticularly noteworthy new research networks, collaborations or partnerships, or combinations of these \nThis project has directly led to a follow on project with partners at Oxford University entitled Digital Wildfire: (Mis)information flows, propagation and responsible governance? (ES/L013398/1). This project is funded by the RCUK Global Uncertainties Programme. Specifically we will be applying the techniques and the coded and collated data sets generated during the course of this project for the follow on digital wildfire study.\n\nIncreased research capability generated from training delivered in specialist skills \n\nIn addition to the new methods identified above this project has been central to the COSMOS programme for observing and analyzing social media communications and repurposing these for social research (Housley et al, 2014). The project has been central to driving the development and testing of the COSMOS platform and its suite of tools, helping prepare the way for the release last month (September, 2014) of COSMOS desktop. At the time of writing COSMOS Desktop has been downloaded by the social research community two hundred times and rising. The work produced by this project has been communicated to key steering committee partners; including the Welsh Government and Association of Chief Police Officers. The project has also produced a number of papers in top social and computer science journals; including Social Network Analysis and Mining and Big Data and Society (see publications). A number of papers have also been delivered at academic institutions that include Oxford (Oxford Internet Institute) and Warwick Universities (Centre for Interdisciplinary Methodologies). One of the main ways in which impact from this project will be taken forward is through the development of the Twitter capture function and refinement of the Tension Analysis tools hosted on the recently released desktop COSMOS platform (September, 2014). The platform has been released to the UK social science community on a not-for profit license. It is being used to inform training in digital social research methods and social media analytics aswell as support research. This project was critical in supporting and refining the tools offered through the COSMOS platform. In addition, a key set of outputs from this project included the securing of a two year SAGE fellowship based at Cardiff University, School of Social Sciences and a number of follow on funded projects, in particular 'Detecting Tension and Cohesion in Local Communities with Social Media', funded by Airbus Group, and 'Digital Wildfire: (Mis)information flows, propagation and responsible governance', funded by ESRC (Global Uncertainties). This has ensured that the key findings, research methods and skills developed can be sustained and inform future work in this critical area of privately and publicly funded research. This project has been successful in making links between private and public funding. In conclusion, the project contributed to the development of algorithms and a version of the COSMOS platform being used for a new BBC Radio 5 Live programme where trending social media topics and items inform discussion and public engagement (http://www.bbc.co.uk/blogs/5live/posts/5-live-Hit-List). Aerospace, Defence and Marine,Agriculture, Food and Drink,Communities and Social Services/Policy,Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Environment,Government, Democracy and Justice,Security and Diplomacy","dataset":"gtr"}