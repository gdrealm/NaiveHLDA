{"id":"9ED502D4-566A-4E4E-82DA-7F17C838714E","title":"Learning to see in depth: neural models of binocular stereopsis","abstractText":"When you go to see a 3D movie, you are provided with a pair of glasses to be worn while in the cinema. You then experience a vivid awareness of the three-dimensional shape of the objects and people in the movie, which appear to leave the screen and occupy space within the room. This occurs because the glasses allow the cinema to present two slightly different versions of the movie to your left and right eye.\n\nThe purpose of this proposal is to determine how your brain is able to interpret these differences between what is seen by your two eyes. We know that this is achieved by neurons in the brain that respond to these differences. We will establish how it is able to interpret these, to provide you with a clear appreciation of the three-dimensional shape of objects.\n\nThis research is important in providing a good theoretical understanding of binocular vision, so that we may develop successful therapies for conditions such as amblyopia and strabismus (&quot;lazy eye&quot; and &quot;squint&quot;) in which binocular depth perception may be impaired or absent. \n\nIt is also important in enabling designers of movies and virtual reality systems to make the results as &quot;real&quot; as possible. This research will help us to understand the binocular image differences that our brains respond to, and how it uses these to determine three-dimensional shape. This can then be used to directly inform the design of virtual reality systems.\nFinally, it is important in allowing engineers to develop robots and vehicles that can &quot;see&quot;; what we learn about how this is achieved by our brains is very valuable in developing artificial, computer vision.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=BB/K018973/1","grantId":"BB/K018973/1","fundValue":"300051","fundStart":"2013-10-01","fundEnd":"2016-09-30","funder":"BBSRC","impactText":"","person":"Paul Barry Hibbard","coPersons":[],"organisation":"University of Essex","findingsText":" The project has been running for 13 months. The goals for the first year of the grant were (i) to create the image database and (ii) to complete the first Independent Component Analysis study. \n\n(i) Image database. We have devised an improved methodology in which, in additional to capturing 3D objects, we will create and provide software for creating scenes. The advantage of this approach is that it removes many of the difficulties faced in calibration, and allows great flexibility in generating images. For example, it allows for the parametric variation of viewing parameters (e.g vergence and focus) while viewing the same scene - something that would have been beyond our original approach. Development of the code for this has progressed well. We have also been successful in producing example scans of individual objects. The plans for the database software have been advertised at the Scottish Vision Group in the first instance, to elicit feedback from relevant users on how to optimize its functionality. The abstract of this presentation will be published in iPerception. The first stage of image collection has been completed, and the coding for calibration of these images is ongoing.\n\n2. Independent Component Analysis. The first part of this has been completed and submitted to Journal of Vision, where it is currently in the review process. The reviewer comments describe the work as 'commendable' and that we 'have done a nice job in [our] attempt to tackle a big question'. We also presentied an extension of this work at the Vision Sciences Society in May 2014 (to be published in Journal of Vision), with a view to submitting our second journal paper by the end of 2014. \nIn addition to performing Independent Component Analysis, we have also applied Independent Subspace Analysis. This works towards our goal of understanding binocular encoding beyond the initial stage of individual filters, with a view to establish the necessary invariances (e.g. to luminance phase) to create reliable disparity sensitivity. We have also submitted two other papers funded by this research to Vision Research, and another to Journal of Vision (i.e. 4 papers have been submitted within the first year of the project). We will be making code and images available, and these have the potential for impact in computer vision and the creative industries. Aerospace, Defence and Marine,Digital/Communication/Information Technologies (including Software),Culture, Heritage, Museums and Collections","dataset":"gtr"}