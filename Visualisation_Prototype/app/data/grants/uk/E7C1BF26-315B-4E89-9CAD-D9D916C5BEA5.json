{"id":"E7C1BF26-315B-4E89-9CAD-D9D916C5BEA5","title":"Hardware Acceleration of Co-Simulation for the Study of Extreme Weather Events","abstractText":"This is a proposal for a two-month research visit to the Disaster Prevention Research Institute (DPRI) of the University of Kyoto in Japan, to work with Prof. Tetsuya Takemi of the Atmospheric and Hydrospheric Disasters Division on hardware acceleration of co-simulation of extreme weather events. In particular, our aim is to accelerate co-simulation of the Weather Research and Forecasting (WRF) model and custom simulators such as the Large Eddy Simulator, and to reduce the run times for combined simulations by an order of magnitude. This reduction in run time will allow scientists to perform simulations of extreme weather events at much higher precision.\n\nThis visit is a follow-on visit from our previous visit in 2012, which established to collaboration and led to a publication at the HPCS conference.\n\n** Focus of the Project \n\n* Numerical Weather Prediction Models\n\nThe particular NWP applications to be used in the proposed work are:\n- The Weather Research and Forecasting Model (WRF). This is the leading model in climate research. It is an open-source (http://wrf-model.org/) next-generation mesoscale numerical weather prediction system designed to serve both operational forecasting and atmospheric research needs. However, because of the complexity of its design, the WRF model currently does not make use of hardware acceleration (except for a small number of experimental modules).\n- The Large Eddy Simulator is developed at the DPRI specifically to study the effects of severe weather events such as hurricanes on urban areas. \n\n* Co-simulation\n\nThe focus of the project is co-simulation, an approach where two simulators run in parallel and the outputs of one simulator serve as inputs for the other. Co-simulation is a very important mechanism to achieve more efficient NWP simulations: many scientists develop custom simulators that however rely on inputs from existing simulators such as WRF. This is in particular the case in the study of severe weather events where the scientists want to change the governing equations: modifying the WRF core is generally not an options because of the complexity of the system. However, the current approach, which involves running WRF and writing the results of the run to a file, then reading the generated data into the custom simulator, is extremely ineffective because of the need to generate huge amounts of data and store them on hard disks. Hard disk access is typically 1000x slower than memory access. Having to read input data from disk at every time step of the simulator results in very slow operation. In co-simulation, the data generated by the first simulator (WRF) is transferred via memory to the second simulator (e.g. LES) at every time step. \n\n* Accelerating the process\n\nThe code for the WRF model is very complex. We have shown in that there is scope for accelerating WRF, but it will take several years to have a fully accelerated version of WRF. Consequently, for this research visit, we plan to use WRF in its current form, and run it on a compute cluster using MPI, which is the most efficient way to run WRF. \n\nHowever, in practice creating a GPU-capable version of a small custom simulator is feasible and an expert can do this in a few weeks (we have for example already created a GPU-capable version of the LES). By running the second simulator on a GPU or other accelerator, we achieve full co-simulation at the speed of the WRF simulation. During the research visit, we want to create the system that will make co-simulation between WRF and a GPU-accelerated simulator possible.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/L026201/1","grantId":"EP/L026201/1","fundValue":"22144","fundStart":"2014-09-01","fundEnd":"2014-11-30","funder":"EPSRC","impactText":"","person":"Wim  Vanderbauwhede","coPersons":[],"organisation":"University of Glasgow","findingsText":"","dataset":"gtr"}