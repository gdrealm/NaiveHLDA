{"id":"A093C27E-6340-4253-9105-5428B4457300","title":"Theory And Applications of Induction Recursion","abstractText":"Computers are good at adding billions of numbers in microseconds. Humans, on the other hand, are good at abstract thinking. This is exemplified by the development of philosophy, literature, science and mathematics. These observations have deep consequences for programming and the design of programming languages. The overarching concern of much research in computer science is to minimize the difference between how humans conceptualise programs and how those programs are implemented in a programming language. To achieve this, we do the same thing humans have been doing for 5000 years as we try to understand the world around us. That is, we construct mathematical models --- in this case, mathematical models of computation - and then reflect that understanding of computation within the design of programming languages. Thus, there is a symbiotic relationship between mathematics, programming, and the design of programming languages, and any attempt to sever this connection will diminish each component. Recursion is one of the most fundamental mathematical concepts in computation. Its importance lies in the ability it gives us to define computational agents in terms of themselves - these could be recursive programs, recursive data types, recursive algorithms or any of a myriad of otherstructures. The original treatments of recursion go back to the 1930s where the concept of computability was formalised via the theory ofgeneral recursive functions. It is virtually impossible to overestimate how recursion has contributed to our ability to computeand to understand the process of computation. Is it possible that there is anything fundamental left to say about recursion? We believe there is. Our central insight is this: when defining a function recursively, the inputs of the function are usually fixed in advance. But what if they are not? What if, as we build up the function recursively, we also build up its inputs inductively? The study of functions defined in this way is called induction recursion and this proposal aims to develop the theory and applications of induction recursion.Our central ambition is to turn induction recursion, which is currently known only to a relatively small number of researchers within type theory, into a mainstream technique within the programming language community. This will require both the theoretical development of induction recursion so as to give us more ways to understand it, but also case studies and examples to make it more accessible to programmers. Fortunately this is an excellent time to do this research! The categorical study of data types has advanced to the stage where the theoretical tools are now in place to tackle inductionrecursion. Perhaps even more fundamentally, dependently typed programming languages in the shape of Epigram and Agda have advancedto the stage where our ideas can be implemented in code and hence the benefits of induction recursion can be made directly available toprogrammers in a form they understand. We can supply them with code to play with! Indeed, we hope to go even further an explore the extent to which induction recursion can form the basis of a programming language. In summary, this proposal takes state of the art ideas in theoretical computer science and will aim to turn them directly into state of the art techniques within programming languages. Such combinations of theory and applications going hand in hand together is often the hall mark of good science!","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/G033374/1","grantId":"EP/G033374/1","fundValue":"104925","fundStart":"2009-10-01","fundEnd":"2013-03-31","funder":"EPSRC","impactText":"  *** Coalgebras ***\n\nWork is on the way of implementing coalgebras based on copattern matching in the theorem prover Agda. Agda is increasingly used for industrial applications. It has been used for specifying railway interlocking systems, especially by the Research Center for Verification and Semantics (CVS) of the National Institute of Advanced Industrial Science and Technology (AIST) in Japan, http://ocvs.cfv.jp/webmap_E/access.html. Note as well that we have used it in our collaboration with the railway group of Siemens at Chippenham for verifying real world interlocking systems, see below. \n\nWe should note that the theorem prover Coq, which is very close to Agda has recently made a big impact. It is considered by Microsoft as &quot;one of their systems&quot; (as told by a representative of Microsoft Research at POPL 2013). The industrial software SPARK Ada, which is a programming language for developing verified critical systems, allows since its 2014 version to prove theorems, which cannot be verified by automated theorem proving, interactively in Coq. We hope that eventually our concepts of coalgebras will be implemented in Coq as well. One route towards is to wait for a successful implementation in Agda and corresponding case studies.\n\n*** Use of dependent type theory in verification of railway interlocking systems ***\n\nThis research has received partial support by Siemens, Chippenham. We have succeeded in fully verifying concrete British railway interlocking systems in the theorem prover Agda using a combination of interactive and automated theorem proving.\n\n*** Fibred Data Types and Inductive-inductive definitions ***\n\nWhile having great potential in influencing the design of interactive theorem provers such as Agda and Coq in the future, this research requires more work in defining the rules in such a way that they can be implemented and in carrying out case studies.\n\n*** Inductive-recursive Definitions in theorem provers ***\n\nThere is a discussion in Coq whether to extend it by allowing inductive-recursive definitions. One reason is that increasingly examples of using inductive-recursive definitions naturally have occurred. Another reason is that the Coq community is well aware that Agda, which is their main competitor, supports inductive-recursive definitions already. \n\n*** Inductive-inductive Definitions ***\n\nThe discovery of surreal numbers as an example of inductive-inductive definitions seems to be a great tool for popularising our new concepts. Surreal numbers have been first published in a popular science book, and it is easy to fascinate the audience with an interest in extending our number system. Unfortunately, we haven't reached the point where these concepts really are taken on by popular culture. Therefore, more work needs to be done in order to have a true cultural impact. Digital/Communication/Information Technologies (including Software),Education,Transport Cultural,Economic","person":"Anton  Setzer","coPersons":[],"organisation":"Swansea University","findingsText":" *** Inductive-inductive definitions ***\n\nThis is a major achievement of this grant to have discovered a novel variant of induction-recursion called induction-induction. Inductive definitions allow to define a set inductively: We have rules for introducing the elements of this set, and the set consists of everything introduced this way. An example is the set List of lists of natural numbers: we have that the empty list (called nil) is an element of List, and if we have a natural number n and a list l, then we obtain a new list by adding this natural number in front of this list. The new element is called (cons n l). We use here functional style of writing the application of function, in mathematical style the element (cons n l) would be written as cons(n,l). Now List is everything that can be introduced using the operations nil and cons. We call nil and cons the constructors of List.\n\nInductive-recursive definitions, the topic of this grant, extends inductive definitions by allowing to define a set inductively while recursively defining a function from this set into another type. The main example is a universe, which consists of a set of codes for sets U, defined inductively. It comes together with a function T, defined recursively, which takes each element of U and computes the set it denotes. For instance we have a constructor which introduces a code for the natural numbers in U, and the corresponding recursion rule, which maps this code to the set of natural numbers. In general in induction-recursion the recursively defined function has one computation rule for each constructor of the inductively defined set. \n\nIn truly inductive-recursive definitions induction and recursion cannot be separated without some sophisticated encoding (one needs in addition in case of large induction-recursion the existence of large universes). An example is the so called Pi type. The introduction rule says that if we have an element a of type U and a function mapping (T a) to U then we obtain a new element of type U. There is a natural set (the Pi type) to which this new element is mapped by T. We see that the introduction rule for U refers to the recursively defined function T, so U and T need to be defined simultaneously. \n\nIn induction-inductive definitions the recursively defined function T is replaced by an inductively defined set which depends on the first inductively defined set. Again both operations cannot be separated without some special encoding.\n\nInductive-inductive definitions occur naturally in mathematics. An example are Conway's surreal numbers, which were first presented in a popular style book written by Knuth. Here the set of surreal numbers is defined inductively while simultaneously defining a &amp;amp;lt; relation on them inductively. When presenting them, complications arise because the standard framework of mathematics allows only inductive definitions. In some way Conway and Knuth reduce inductive-inductive definitions to inductive definitions, which makes it difficult to understand surreal numbers. We believe that presenting surreal numbers as inductive-inductive definitions is much more intuitive, and allows to define them directly as the simultaneous inductive definition of a set of surreal numbers together with a &amp;amp;lt; relation on it. Another example where inductive-inductive definitions occur naturally are ordinal notation systems. Here a set of ordinal notations (which are transcend numbers) is defined inductively while defining the less than relation inductively.\n\nInduction-recursion occur naturally when one wants to formulate models of type theory inside type theory. The main idea is that one defines a set of types inductively while defining the elements of those types recursively. Induction-induction occurs naturally when defining the syntax of type theory: As an example we consider the rules for defining contexts and the rules for defining the Pi-type as mentioned before: \n\nThe rules for deriving contexts correspond to the inductive definition of a set of contexts. Types depending on a context Gamma form a set (Type Gamma), which is defined inductively. Consider the rule for extending a context Gamma by adding a new type A to the context. In dependent type theory, A might depend on Gamma. So the rule takes a context Gamma, an element A of (Type Gamma) and returns a new extended context (Gamma , A). When introducing the Pi type, we take a type A in context Gamma, a type B in the extension of this context by A, and return a type in context Gamma. If we formalise it we take an element Gamma of Context, an element A of (Type Gamma), an element B of (Type (Gamma , A)) and return an element (Pi Gamma A B) in (Type Gamma).\n\nIn this example we see that the constructors for Contexts occur in the rules for the constructors for (Type Gamma). This makes induction-recursion very complicated. It means that when defining constructors for (Type Gamma) we can refer on an arbitrary function corresponding to the type of the constructor for context extension. Note that the constructor for context extension has type (Gamma : Context) -&amp;amp;gt; Type Gamma -&amp;amp;gt; Context, so the constructors for (Type Gamma) refer to a function which goes from Context and some other arguments into Context.\n\nIn order to get control over this complexity, we used the notion of a Dialgebra. Inductive data types correspond to so called F-algebras. An F algebra consists of a set A (the inductively defined set), a function F mapping sets to sets (which are the arguments of the constructor) and the constructor c : F A -&amp;amp;gt; A. Therefore F-algebra have an operation c which allows to introduce (construct) elements of the set A. Dualising means to invert the direction of the functions. If we dualise F-algebras we obtain F-coalgebras, which have the form e : A -&amp;amp;gt; F A, where e is called a destructor (or an observation). F-coalgebras have an operation which allows to analyse (deconstruct) elements of A. Dialgebras are a combination of both, they are functions f : F A -&amp;amp;gt; G A, where both F and G are functors. The use of dialgebras allows to formulate the introduction and elimination rules for inductive-inductive definitions in a more abstract way. A notion of initiality was defined and we showed (article by Altenkirch, Morris, Nordvall Forsberg and Setzer) the equivalence of the rules for initial algebras based on dialgebras and the elimination rules. This is important since it is not per se clear whether the elimination rules defined are the correct ones. The notion of initiality is more natural, and the fact that both rules are equivalent demonstrates that we have chosen the correct elimination rules.\n\n*** Fibred Data Types ***\n\nThe key question in the grant was to give a categorical representation of the rules of induction-recursion, so that they can be generalised. Induction-recursion considers the case where we have an inductively defined set U and a recursively defined function T : U -&amp;amp;gt; D for some type D. The goal was to generalise this to a more general setting as follows: We first combine U and T into a type (Fam D) of families of type D, which are pairs consisting of a set U and functions T : U -&amp;amp;gt; D. Let index be the function mapping such a pair to U. (Fam D) and index are an example of a so called split fibration, a concept well known in category theory.\n\nWe generalised the notion of induction-recursion by replacing this concrete split fibration by an arbitrary split fibration. This generalise inductive-recursion to many more general settings. We considered (LICS article by Ghani, Malatesta, Nordvall Forsberg and Setzer), the following generalisations: 1) Universes of setoids (i.e. U is a setoid and T forms families of setoids over U; here a setoid is a set together with an equality relation on it). 2) Universes of relations (i.e. replacing T : U -&amp;amp;gt; D by T : U x U -&amp;amp;gt; Set). 3) Categories of families. 4) Indexed induction-recursion. 5) Containers and indexed containers. This generalises induction-recursion to many more examples. So instead of defining a new calculus for each instance we have one general framework which can be instantiated to each case.\n\nBecause of the more categorical approach, we obtained as well a more natural explanation of the rules of induction-recursion. A particular problem is the delta constructor, which allows to extend an inductive-recursive definition by adding on inductively argument. It originated from the informal principles in induction-recursion, but looked quite ad hoc. Using fibrations the rules for delta became very natural. \n\n*** Copatterns ***\n\nAnton Setzer has with his coauthors Andreas Abel, David Thibodeau and Brigitte Pientka developed a concept of representing coalgebras, in which the duality of coalgebras and algebras is fully explored (POPL 2013 and RTA-TLCA 2014).\n\nAs mentioned before, initial algebras correspond to inductively defined structures. The rules for List mentioned above express that a List is everything which can be defined using the constructors nil and cons. \n\nCoalgebras are instead sets determined by their elimination rules. For instance the set of streams of natural numbers is the coalgebra with eliminators (deconstructors, observers) head : Stream -&amp;amp;gt; Nat and tail : Stream -&amp;amp;gt; Stream. Intuitively, a stream is any element which allows to define the result of applying head and tail to it. Whereas an element of List is everything which can be constructed, an element of Stream is everything which can be deconstructed. By iteratively applying head/tail to a stream we can unfold it into an infinite list. This shows that final coalgebras allow to define largest fixed points of operators, instead of least fixed foints, as it is the case with inductively defined sets.\n\nTraditionally, in functional programming largest fixed points are representing differently by using codata types. In case of Stream this means that we have a constructor cons taking a natural number, a stream, and constructing a stream. However, while in inductive data types we allow only finitely many applications of a constructor (in a more general setting this will be well-founded many applications) in case of codata types we allow infinitely many applications. Therefore (cons 0 (cons 0 (cons 0 (...)))) is an element of the codata type Stream. We immediately get a problem, namely that this is an infinite term, so we obtain non-normalisation. This is in particular a problem in dependent type theory: During type checking equality between terms needs to be checked, which is done by evaluating terms to normal form and then comparing their normal forms. This is not possible if one allows full evaluation of a stream to (cons 0 (cons 0 ( cons 0 (...)))).\n\nIf we instead look at the coalgebra approach, this problem vanishes. The stream consisting of an infinite sequence of 0 is defined as the element zeros of Stream such that (head zeros) = 0 and (tail zeros) = zeros. zeros is in normal form, and therefore a finite object. Its infinite nature is revealed by the fact that one can arbitrarily many times apply head/tail to it, and then unfold it to an infinite stream. Each time one unfolds zeros one has to pay a price, namely to apply a deconstructor to it. That one needs to invest something in each step of unfolding is the reason why one does not obtain a problem with normalisation.\n\nIn order to preserve normalisation for codata types and allow for decidable type checking, sophisticated restrictions have to be applied to when a reduction is carried out (i.e. when we can unfold zeros to (cons 0 zeros) ). It has been well known for a long time that because of this the theorem prover Coq violates subject reduction. This means that there is a term t of type A, which has a reduction to a term t' which is not of type A. Note that Coq is now a widely used interactive theorem prover. It has been adopted by Microsoft as &amp;amp;quot;one of their systems&amp;amp;quot; (phrase used by a representative of Microsoft research). It can be used for verifying critical systems in the industrial system SPARK Ada. In Agda, the interactive theorem prover we are using mainly, the subject reduction problem in Coq was repaired by adding severe restrictions to the rules of coalgebras. However, these restrictions are so severe that coalgebras are very difficult to use in Agda.\n\nBecause of this we believe that the theory of coalgebras has great advantages. We developed a small programming language in which algebras and coalgebras are completely dual. Algebras are defined by constructors, coalgebras by deconstructors (observations). For algebras the elimination principle is given by pattern matching. In case of List pattern matching means that we can define a function from List into another set, provided we define what to do in case this element is nil and in case it is (cons n l). We introduced the dual of pattern matching, which is called copattern matching. Being the dual of pattern matching, which is an elimination principle, copattern matching needs to be an introduction principle for Coalgebras. It expresses that we can define an element s of type Stream provided we define (head s) and (tail s). Copattern means that for defining s we apply head and tail to it, and then have the obligation of returning a result in each case.\n\nIn our joint POPL 2013 paper we introduced a calculus which allowed to combine algebras and coalgebras, patterns, and copatterns, nesting of both and even mixing both. A crucial result is to show that in this calculus we obtain subject reduction. In our RTA-TLCA 2014 we showed that these mixed nested patterns/copatterns can be reduced to unnested ones.\n\n*** Extended Predicative Mahlo Universe ***\n\nThe data type of inductive-recursive definitions is using the principles which in its simplest form occurred in the Mahlo universe developed by Anton Setzer. The Mahlo universe is a set U with a function T from U into Set. Whenever we have a function f from so called families of U into families of U, we obtain a subuniverse U_f of U which is closed under f and a new element of U. \n\nThe problem is that the constructor of U for forming U_f refers to a total function which essentially goes from U to U (more precisely from (Fam U) to (Fam U) ). So the reason for introducing U_f as an element of U refers to all of U, which includes the element U_f introduced. This is a form of impredicativity. Impredicativity means here that we have an introduction rule for a set which refers to all of this set, including the element being introduced. Because of this impredicativity there is lot of controversy about whether the Mahlo universe is acceptable in Martin-Loef Type Theory or not. \n\nIn our new approach, Anton Setzer and Reinhard Kahle investigated this principle in the context of Feferman's systems of explicit mathematics, which can be considered as an untyped variant of Martin-Loef Type Theory. Setzer and Kahle showed that in explicit mathematics one can define a version of the Mahlo universe which can be considered as predicative (we call it &amp;amp;quot;extended predicative&amp;amp;quot;). The main reason that it is predicative is that the introduction rule for elements in U does no longer depend on a total function f : Fam(U) -&amp;amp;gt; Fam(U). Instead it depends on a partial function f which is sufficient to allow to define a universe U_f closed under f. \n\nThe extended predicative Mahlo universe allows to define an elimination rule. Note that an elimination rule is in case of the type theoretic Mahlo universe inconsistent. \n\nWe are currently working on extending this setting to proof theoretically much stronger universes such as the so called Pi_3-reflecting universe.\n\n*** Use of dependent type theory in verification of railway interlocking systems ***\n\nAnton Setzer has with his PhD student Karim Kanso explored how to verify railway interlocking systems in the interactive theorem prover Agda based on Martin-Loef Type Theory. This was a cooperation with Invensys Railsystems, a company recently taken over by Siemens. One goal of this project is to detect new applications of advanced data types such as induction-recursion, induction-induction and coalgebras in this area. We discovered occurrences of induction-recursion and coalgebras. The use of induction-recursion was however easily reduced to normal induction. Therefore more work needs to be done before we discover induction-recursion in an industrial settings.\n\nSetzer and Kanso have developed concepts for combining automated and interactive theorem prover in the context of type theory. This allows to verify using SAT solvers and model checkers concrete railway interlocking systems from the British railway system. They were able to show using interactive theorem proving that the resulting systems are safe. A lot of work has been carried out by Kanso in implementing the integration of SAT solvers and model checkers into Agda. It turned out that model checkers could only applied in small examples, whereas the use of SAT solvers was greatly successful, and allowed to fully verify concrete railway interlocking systems. \n\nIt turned out that this approach allows to reduce the validation problem. It is a general problem when proving software to be correct to check that the specification against which one checks the software is actually correct. In case of railway interlocking systems one usually proves that the system fulfils certain verification conditions (signalling principles). For instance one verifies that two signals giving access to the same railway segment are not green at the same time. It is not per se clear that if those conditions are fulfilled the system is safe. That this is the case is usually checked manually by domain experts. The problem is that there can be errors in those checks as there can be errors in the original program. Another approach taken is to show that a program refines another abstract program, which is considered to be safe. Again the problem is that the domain experts need to show that the abstract program is safe.\n\nInstead of this approach, Setzer and Kanso introduced a model of the railway system with abstract trains. They were able to show that the system is safe: there are never two trains in the same train segment, so trains do not crash. And if a train passes a set of points, this set of points is locked, so trains do not derail. \n\nThere is still a gap between the specification and the requirements (safety of the interlocking system), but the gap is much more narrow. In the approach automated theorem was used to show that the system fulfils certain verification conditions, and interactive theorem proving was used to show that the verification condition imply safety as formulated by the model.\n\nTherefore the approach taken allowed to narrow the validation gap and demonstrated that it is possible to verify real world interlocking systems in the theorem prover Agda. *** Inductive-inductive definitions ***\n\nThe next step in this project is to generalise induction-induction to more general settings so that, instead of having two levels (A : Set, B : A -&amp;gt; Set), arbirtarily many levels are allowed. Ideally we would even combine induction-induction and induction-recursion. At the moment the technicalities are very complicated and hinder further development. If such an extension is worked out it could be the basis for the restriction of Agda to a theoretically better understood concepts. Agda is very generous at the moment. It is not clear whether it is with this full generality sound. We should note that this is a problem with most interactive theorem provers. A lot of extensions are added, in order to make the theorem provers expressive enough to handle large and complex problems. These extensions are often added without being well understood. Therefore for most interactive theorem provers it is not clear that with all the extensions added they are still sound. Usually this is not a problem, because the base theory is well understood and sound.\n\nAnother step would be to carry out more case studies on induction recursion. We plan as well to write articles which make this knowledge accessible to people outside dependent type theory, including mathematicians without a background in logic. Especially popularising the use of surreal numbers might be a gateway to popularising inductive-inductive definitions.\n\n*** Fibred Data Types ***\n\nThe next step is to fully work out the rules resulting from the examples already given and to explore how these concepts in those more general settings applied. Ideally, Once these rules are well worked out a next step would be to implement them in an interactive theorem prover such as Agda or Coq.\n\n*** Copatterns ***\n\nWork is already on the way of implementing copatterns and coalgebras in the theorem prover Agda. Ideally it would be implemented as well in the more popular theorem prover Coq, however our influence on this theorem prover is limited. However, if it is a success story in Agda it might motivate the Coq community to implement this notion as well.\n\n*** Extended Predicative Mahlo Universe ***\n\nWe have already started the writing of a journal article in which the model of the extended predicative Mahlo universe is worked out. The next step would be to extend this approach to more advanced universes such as the Pi_3 reflecting universe. A great step would be to introduce an interactive theorem prover for Feferman systems, similar to Agda. An implementation existed, but the implementation has unfortunately been abandoned. Having such a system would allow to popularise the findings of this research greatly. We believe that such a theorem prover might be useful, including for future industrial applications.\n\n*** Use of dependent type theory in verification of railway interlocking systems ***\n\nOne goal is to make sure that the work by Karim Kanso will be fully integrated into the theorem prover Agda as part of future Agda Intensive Meetings (AIM) which take place biannually. We are currently working on implementing security protocols in Agda and representing coalgebras in Agda. This will help to get more examples of case studies of the use of Agda for verifying concrete software. Aerospace, Defence and Marine,Creative Economy,Digital/Communication/Information Technologies (including Software),Education,Security and Diplomacy,Transport","dataset":"gtr"}