{"id":"AE4C9B94-74FE-4318-98C8-FA53D4F9BB0F","title":"AABAC: Adaptive Asynchronous Brain-Actuated Control","abstractText":"This proposed project aims to develop a novel adaptive and asynchronous brain-computer interface (BCI) system for brain-actuated control of intelligent systems and robots. Recent advances in science and technology have shed light on the possibility of fusing human's brain with intelligent machines to carry out challenging tasks that the state of the art autonomous machines cannot undertake. BCI is one of the key technologies to make this possible. A BCI system detects and analyses brain waves, e.g., electroencephalography (EEG) signals, in order to understand a user's mental states, and then translates the mental states into commands for communicating with and controlling computers, robots, and other systems. Almost all the current EEG-based BCI systems of high accuracy use synchronous protocols and recognise two mental states only. Their disadvantages include low information transfer rate and unnatural user interface, which impose severe limitations on BCI systems for real-world applications. Based on our previous research in BCI and related areas, we believe that it is now very timely to develop adaptive and asynchronous BCI systems that not only have the advantages of using asynchronous protocols, such as high information transfer rate and natural operation mode, but also benefit from adaptive learning so as to improve the system's accuracy and robustness. Apart from adaptive learning, in order to achieve high accuracy and robustness, this proposed programme will investigate novel effective indicators for onset detection and optimal timing schemes for asynchronous mental state classification, discover or invent new feature spaces on which it would be easier to classify EEG patterns, and develop new methods for increasing the number of control commands mapped from a limited number of mental states. The methods developed hereby will be assessed through extensive experimentation with real-time brain-actuated control of an intelligent wheelchair and a robotic arm.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D030099/1","grantId":"EP/D030099/1","fundValue":"180462","fundStart":"2006-02-01","fundEnd":"2009-07-31","funder":"EPSRC","impactText":"","person":"Stephen  Roberts","coPersons":[],"organisation":"University of Oxford","findingsText":" When we talk about interfacing with a computer we typically mean typing at a keyboard or using a mouse. This project investigates using a new communication channel - the EEG. The EEG, or electroencephalogram, is electrical activity recorded from the scalp and produced by neurons in the brain. The development of a Brain Computer Interface, or in our case, an EEG-based communication device, requires the raw EEG signal to be converted into a new output channel through which the brain can communicate and control its environment. \n\n\n\nThis projects builds on twenty years of research in the brain sciences and on recent developments in adaptive computing. In the 1970s it was discovered that subtle changes occur in the EEG when we plan movements. These changes are called Movement-Related Desynchronisations (or MRDs for short) because when movements are planned the activity of neurons in the motor cortex becomes desynchronised. But the MRD signals are tiny. They are rarely bigger than a few tens of microvolts and are often buried beneath other signals. We therefore need to use advanced pattern recognition methods to detect the MRD signals.\n\n\n\nOur experiments have shown that it is possible to robustly control a variety of devices using these brain-only signals.  Digital/Communication/Information Technologies (including Software),Healthcare,Other","dataset":"gtr"}