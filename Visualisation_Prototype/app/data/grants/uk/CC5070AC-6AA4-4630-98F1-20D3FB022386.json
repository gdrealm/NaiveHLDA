{"id":"CC5070AC-6AA4-4630-98F1-20D3FB022386","title":"How do ants use encode &amp; identify natural panoramic scenes?","abstractText":"Panoramic scenes are important to many navigating animals in providing directional signals (home is left of the hill), compass direction (valley runs north-south), and a rough sense of place (we are nearly home). But how large natural scenes are encoded or recognised is almost unknown. We will explore this topic in ants for its intrinsic interest, as a new approach to studying insect pattern vision, and more broadly because the way that a low resolution and relatively simple visual system deals with natural scenes relates to current areas of neuroscience, computer vision and robotics. Walking ants are good insects for such a study as their scanning and viewing movements while recognising scenes and approaching patterns can be monitored at high resolution to give both the orientation of an ant's body axis and its position, allowing us to infer how a scene is imaged on the retina. The design of experiments can be kept simple following our finding that the directional responses of desert ants to a real panorama can be elicited by a crude facsimile of the skyline of that panorama. It hints at possible features that ants use for scene identification, such as peaks and troughs in the skyline. Also, as distance and compass information are not essential for scene recognition, it is realistic to study aspects of it in the lab. Additionally, the old but long-ignored result that na&iuml;ve ants exposed to a large visual stimulus tend to face its centre of mass gives us a new way to analyse how ants integrate information across a large scene. Our major research questions are: How do ants scan and view patterns during recognition? Ants and bees simplify the computational problems of pattern recognition by adopting stereotyped viewing strategies. We will analyse these strategies while ants inspect, recognise and use panoramic visual scenes of different sizes. Pilot data show that desert ants in the field rotate to scan a scene before correcting their course, or if the sceneis unfamiliar. Videos of this scanning will reveal the relationship between viewing direction and guiding elements in the panorama. In the lab, the fixity or variability of viewing behaviour during scene recognition and the changes induced by scene transformations will be examined for clues to the coordinate system of scene encoding (retinotopic, compass-based, or intrinsic to the scene). How do ants integrate information over a large area? As a new approach to analyzing the visual processing that occurs across large scenes, we will study the ants' computation of the centre of mass of a stimulus. Because this aiming behaviour needs no training, we can test a large variety of stimuli and analyse how different areas and features of a scene combine in the estimate of a scene's centre of mass. Our aim is to produce a model of this processing that can predict an ant's directional response to most scenes. How are components of panoramic scenes encoded? That a panorama can be recognised through its simulated skyline means that a significant part of the scene is captured by the skyline contour. One likely form of skyline encoding is as a sequence of oriented edges. Another possibility is that the shape of scene components - peaks or troughs - is encoded by the separation between skyline inflections and the centre of mass of a component. By training ants to distinguish between shapes (initially isosceles and scalene triangles), we will investigate whether ants use these or other visual 'primitives'. How do ants use panoramic scenes? We will examine in the field the ways that information from natural panoramas (1) provides directional information for guidance, (2) acts as a contextual cue for priming the appropriate spatial memories for ants that are trained to two foraging routes, and (3) interacts with compass information in scene recognition.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=BB/H013644/1","grantId":"BB/H013644/1","fundValue":"493732","fundStart":"2010-04-11","fundEnd":"2013-10-10","funder":"BBSRC","impactText":"  Our research has formed the basis of public engagement activities and has also inspired research on robot navigation algorithms. Aerospace, Defence and Marine,Education Societal","person":"Paul  Graham","coPersons":["Thomas  Collett"],"organisation":"University of Sussex","findingsText":" We have identified key processes by which insect use simple visual heuristics to guide their paths through the world These findings may highlight possible ideas for robot navigation systems Aerospace, Defence and Marine","dataset":"gtr"}