{"id":"935BBBF9-48E5-411B-B778-D206E3209C09","title":"The use of prior assumptions in human visual processing.","abstractText":"The complex pattern of light entering our eyes as we view the world is used to recover the three-dimensional structure of our environment. To do this quickly and efficiently our visual system makes certain assumptions. For example, in the absence of other information, we assume that objects are illuminated from above ('light-from-above prior'). Imagine an egg sitting in the sun. Shading makes the egg bright on the top and darker underneath. Without seeing the light-source we assume that it is overhead and use this assumption to help determine the shape of the egg, i.e. convex. In contrast, if you held up an open egg-box, each depression would be dark at the top and brighter at the bottom, helping you to see it as concave. The 'light-from-above' prior helps us to estimate the shape of an object from its shading pattern: a process called 'shape-from-shading' (SFS). We are interested in whether visual assumptions ('priors') are innate or learnt in response to interactions with the environment. Chickens always interpret shading patterns as if the light source was overhead, even if raised in an environment where light always comes from below. In contrast, humans trained in an environment where the light-source is always to one side learn to interpret objects accordingly. A series of experiments will investigate just how adaptable the human visual system is. Observers will view and touch virtual objects via a 'robot arm' that allows us to manipulate whether the objects feel convex or concave. With this method we will train people to believe that objects are lit from the side or from below. We will measure how this training affects the interpretation of other, novel objects, and how long the effects last. We can thus uncover how and over what time-scale the human visual system adapts to changes in its environment.A concave object (e.g. dimple) is easy to find amongst many convex objects (e.g. buttons), based on differences in the shading patterns. This convex / concave visual search task is easiest if the objects are lit from above, consistent with the 'light-from-above' prior. This provides a useful method to investigate the 'light-from-above' prior and how it interacts with other visual scene information.The mechanisms for implementing the 'light-from-above' prior could be very simple or quite complex. For example, evidence is mixed on whether the 'light-from-above' prior moves with the head, such that if you were upside-down you would assume that objects were lit from below. We can investigate this by asking observers to perform visual search tasks with their head or body at different orientations. We can also ask whether SFS is affected by context. For example, if surrounding objects are clearly lit from the side, then the visual system might also interpret central objects as if they are lit from the side. Visual search performance may also change when observers actively move the light source.Visual search behaviour will be compared to shape judgements (convex vs. concave) and judgements about how light or dark objects appear. All of these tasks use the 'light-from-above' prior but may be differentially affected by contextual manipulations. For example, head position might affect shape judgements but not visual search. Differences between the tasks will inform us about the divergence of mechanisms behind various judgements involving shape and shading.This work is of great relevance to scientists interested in the assumptions that the visual system uses; little research has investigated how priors are learnt, how general they are and how they are affected by contextual information. More broadly, anyone using remote presentation of visual or touch information (e.g. virtual reality, remote surgery) should be aware of the assumptions that observers use to interpret displays. For example, display orientation and previous experience could dramatically affect 3D perception, especially under diminished cue conditions.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D039916/1","grantId":"EP/D039916/1","fundValue":"125452","fundStart":"2006-03-20","fundEnd":"2009-01-19","funder":"EPSRC","impactText":"","person":"Wendy Jo Adams","coPersons":[],"organisation":"University of Southampton","findingsText":"","dataset":"gtr"}