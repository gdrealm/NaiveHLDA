{"id":"FB01E113-3F52-47F2-B0CC-7E53C04285B5","title":"Brightness Evaluation and Measurement (with Application to Airport Lighting)","abstractText":"Human perceptions of spaces, architecture, objects and people are dependent on the light that let's us see the world around us. When the sun goes down we are dependent on artificial light. We use light not only to see what we are doing, but also for appearance and for safety. The most obvious applications of lighting systems for safety reasons are traffic signals and street lights. However, have you ever thought of the importance of lighting in other forms of transportation, namely aviation?Safety is a concern of everyone who flies or contemplates it. However, no other form of transportation is scrutinized and investigated as closely as commercial aviation. Indeed in no other use of lighting is standardisation more important than in airport landing lighting. The lighting systems used at airports are intended to guide pilots during the visual appraisal of an airport, landing and also the take-off phases of their flight. Considering that aviation spans the globe, aircrews worldwide must be provided with consistent lighting information.This research looks at developing a novel autonomous and intelligent device that will be able to examine airport landing lighting and determine whether it is operating at the correct brightness and uniformity as dictated by aviation governing bodies.This device in its most basic form will consist of a video camera that is mounted inside an aircraft. The position of the camera will be such that it can make a video of what the pilot will see during an approach to an airfield. The video will then be analysed by a computer in a number of steps which is referred to as post-processing. Initially the video clip must be separated into a series of images, at a rate of 15 images or frames per second. Assuming that a complete approach to an airport will last approximately one minute, then this will require the analysis of 900 images.Each image will show the airfield lighting pattern. If we know the position of each light (or more technically a luminaire) in the real world and also have a mathematical description for the properties of the video camera, it is possible to determine the position and orientation of the video camera at the instant each image was taken. This position can be used with the aircraft's positioning system to make sure the video camera is in the best position for making measurements.The second step is then to uniquely identify each luminaire within the pattern and extract its total pixel grey level. Essentially when a camera is used to take an image of a luminaire, the total pixel grey level for that luminaire is related to its brightness. However distance is also a factor. If a camera is used to take an image of a luminaire at various displacements, then the pixel information will vary. However, the intensity of the luminaire should remain constant. As such, the distance information derived as well as the total grey level information for each luminaire will be used to derive an intensity value for that luminaire. Any given luminaire will be visible in at least 200 of the captured images because it disappears as the aircraft flies over it.In essence this means that a given luminaire can be tracked through the image sequence, allowing approximately 200 intensity values to be derived for the luminaire at different displacements. This allows a profile for the luminaire to be built up. Aviation standards dictate that luminaires within the landing pattern should have a certain luminous intensity. The intensity values that are derived from the measurement system can be compared to the expected values for each luminaire. Consequently, it will be possible to determine if the pattern is operating within the standards.This research is completely novel in that no other system can monitor the complete airport landing pattern and no other system integrates a number of sensing technologies to optimise the performance.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D05902X/1","grantId":"EP/D05902X/1","fundValue":"126667","fundStart":"2006-10-01","fundEnd":"2009-09-30","funder":"EPSRC","impactText":"","person":"Karen Rosemary Rafferty","coPersons":[],"organisation":"Queen's University of Belfast","findingsText":"","dataset":"gtr"}