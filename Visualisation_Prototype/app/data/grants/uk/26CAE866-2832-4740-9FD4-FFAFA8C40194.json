{"id":"26CAE866-2832-4740-9FD4-FFAFA8C40194","title":"Digital Music Lab - Analysing Big Music Data","abstractText":"Music research, particularly in fields like systematic musicology, ethnomusicology, or music psychology, has developed as &quot;data oriented empirical research&quot;, which benefits from computing methods. In ethnomusicology particularly, there has been a recent growing interest in computational musicology and its application to audio data collections. Similarly, the empirical study of performance of Western music, such as timing, dynamics and timbre and their relation to musical structure has a long tradition. However, this music research has so far been limited to relatively small datasets, because of technological and legal limitations. \n\nOn the other hand, researchers in Music Information Retrieval (MIR) have started to explore large datasets, particularly in commercial recommendation and playlisting systems (e.g. The Echo Nest, Spotify), but there are differences in the terminologies, methods, and goals between MIR and musicology as well as technological and legal barriers. The proposed Digital Music Lab will support music research by bridging the gap to MIR and enabling access to large music collections and powerful analysis and visualization tools. \n\nThe Digital Music Lab project will develop research methods and software infrastructure for exploring and analysing large-scale music collections. A major output of the project will be a service infrastructure with two prototype installations. One installation will enable researchers, musicians and general users to explore, analyse and extract information from music recordings stored in the British Library (BL). Another installation will be hosted by the Centre for Digital Music at Queen Mary University of London and provide facilities to analyse audio collections such as the I Like Music, CHARM and the Isopohnics datasets, creating a data collection of significant size (over 1m pieces). \n\nWe will provide researchers with the tools to analyse music audio, scores and metadata. The combination of state-of-the-art music analysis on the audio and the symbolic level with intelligent collection-level analysis methods will allow for exploration and quantitative research on music that has not been not possible at this scale so far. \n\nThe results of these analyses will be made available in the form of highly interactive visual interfaces. Musical questions we will explore include: how does performance style change change over time in relation to a particular genre or style, in classical, world, jazz, or popular music; how might performances of a given genre vary by geographical location; how does a performer's individual performance aesthetic develop over their lifetime; how might we identify the influence of one performer on another. Starting points for the analysis will be questions of musical timing and structure in piano music as well as in folk songs. We will also explore more generic musicological questions, such as the role of specific instruments in different cultures using data mining on the collection level, e.g. for relating similarities on the signal and metadata level. The resulting derived data that can be aggregated for research use, and the annotation of audio files with metadata, using all open standards such as the Music Ontology. \n\nThe use of the proposed framework will be demonstrated in musicological research on classical music (building on the AHRC-funded CHARM and CMPCP research centres), as well as in folk, world and popular music. All results will be made available as open data/open source software. We feel that this project has the potential to bring together communities from musicology and MIR to mutual benefit.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=AH/L01016X/1","grantId":"AH/L01016X/1","fundValue":"451751","fundStart":"2014-01-02","fundEnd":"2015-04-01","funder":"AHRC","impactText":"","person":"Tillman Erik Weyde","coPersons":["Jason Antony Dykes","Emmanouil  Benetos","Nicolas  Gold","Simon  Dixon","Mark  Plumbley","Stephen  Cottrell","Mahendra  Mahey"],"organisation":"City University London","findingsText":"","dataset":"gtr"}