{"id":"DEA00450-A533-4150-A43B-83470B47F012","title":"Integrated Visualization of Multiple Data Streams for Command Control Interfaces (CCI)","abstractText":"Visualization is generic enabling technology, but most visualization systems have not been designed to accommodate the complexity of dynamic input data streams in many real world applications. For example, in a typical traffic control centre, there are many different data streams, such as video streams from traffic cameras, partial traffic information collected from GPS devices, accident reports via radio and emergency services, satellite images (e.g., Google earth), traditional maps, and other related information such as concerts and sports events. However, these data streams are usually displayed separately. Traffic controllers have to gather information from different displays simultaneously and build a mental image about the global situation.\n\nAlthough there are geographical information systems that can display multiple maps using a classic technique called map overlay, the use of such a mechanism in applications such as traffic control centre, is rare. This is partly because that geographical information systems typically rely on a small number of visual channels, such as colour lines, patches, and text labels. It is rather easy for different maps to use similar visual mappings, creating conflicts in the combined visualization. Furthermore, temporal data (such as videos and time series) are becoming common in many applications. The depiction of such data is typically in the form of animation, tracking lines and heatmap (using colour to show the level of changes). Tracking lines and heatmaps are typically in conflict with the underlying geographic maps and satellite images respectively, while animation suffers from a number of perceptual and cognitive shortcomings and is not suitable for continuous monitoring and objective evaluation. For example, watching animation requires time and full attention. If a traffic controller is watching a previously-recorded event unfolding, he/she cannot pay attention to the current situation. So the challenge is how can one visualize &quot;time&quot; (i.e., temporal data) without using &quot;time&quot; (i.e., video or animation).\n\nIn this project, we will develop two pieces of novel techniques. We will increase the number and types of the visual channels that can be used in multi-stream visualization, while develop a set of conflict diagnostic facilities, which algorithmically measure the quality deficiency due to conflict visual mappings associated with different layers. The diagnostic facilities can give warnings to the users as the potential risks of confusion and misunderstanding caused of conflict use of visual channels. In addition, we will design a set of new forms of temporal visualization that enable uses to visualize &quot;time&quot; without using &quot;time&quot;.\n\nWe will develop a demo system, where different data streams can be plugged-in and play. The system will be supported by a dashboard, running on a tablet computer such as iPad. Through the dashboard, the users can activate and deactivate individual data streams, select appropriate visual channels, receive advice from the conflict diagnostic facilities, control the appearance of each layers, and manger the order of different layers. We will evaluate the demo system in two applications, risk visualization in resilience and archeological data visualization.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/J020435/1","grantId":"EP/J020435/1","fundValue":"110513","fundStart":"2012-05-30","fundEnd":"2013-05-29","funder":"EPSRC","impactText":"","person":"Min  Chen","coPersons":["Anne Elizabeth Trefethen"],"organisation":"University of Oxford","findingsText":"","dataset":"gtr"}