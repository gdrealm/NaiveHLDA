{"id":"3C158598-11E5-4178-976A-27790E395282","title":"S3A: Future Spatial Audio for an Immersive Listener Experience at Home","abstractText":"3D sound can offer listeners the experience of &quot;being there&quot; at a live event, such as the Proms or Olympic 100m, but\ncurrently requires highly controlled listening spaces and loudspeaker setups. The goal of S3A is to realise practical \n3D audio for the general public to enable immersive experiences at home or on the move.\n\nVirtually the whole of the UK population consume audio. S3A aims to unlock the creative potential of 3D sound and deliver to listeners a step change in immersive experiences. This requires a radical new listener centred approach to audio enabling 3D sound production to dynamically adapt to the listeners' environment. Achieving immersive audio experiences in uncontrolled living spaces presents a significant research challenge. This requires major advances in our understanding of the perception of spatial audio together with new representations of audio and the signal processing that allows content creation and perceptually accurate reproduction. Existing audio production formats (stereo, 5.1) and those proposed for future cinema spatial audio (24,128) are channel-based requiring specific controlled loudspeaker arrangements that are simply not practical for the majority of home listeners. S3A will pioneer a novel object-based methodology for audio signal processing that allows flexible production and reproduction in real spaces. The reproduction will be adaptive to loudspeaker configuration, room acoustics and listener locations. The fields of audio and visual 3D scene understanding will be brought together to identify and model audio-visual objects in complex real scenes. Audio-visual objects are sound sources or events with known spatial properties of shape and location over time, e.g. a football being kicked, a musical instrument being played or the crowd chanting at a football match. Object based representation will transform audio production from existing channel based signal mixing (stereo, 5.1, 22.2) to spatial control of isolated sound sources and events. This will realise the creative potential of 3D sound enabling intelligent user-centred content production, transmission and reproduction of 3D audio content in platform independent formats. Object-based audio will allow flexible delivery (broadcast, IP and mobile) and adaptive reproduction of 3D sound to existing and new digital devices.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/L000539/1","grantId":"EP/L000539/1","fundValue":"5415200","fundStart":"2013-12-12","fundEnd":"2018-12-11","funder":"EPSRC","impactText":"  Listener centred spatial audio reproduction for immersive spatial audio experience at home and improve content accessibility for the hearing impaired. Creative Economy,Digital/Communication/Information Technologies (including Software),Culture, Heritage, Museums and Collections Cultural,Societal,Economic","person":"Adrian  Hilton","coPersons":["Filippo Maria Fazi","Trevor John Cox","Philip Arthur  Nelson"],"organisation":"University of Surrey","findingsText":"","dataset":"gtr"}