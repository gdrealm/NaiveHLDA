{"id":"9AA25411-9B15-491A-B5A5-24AADE5A9514","title":"Metrology Guided Radiotherapy","abstractText":"Radiotherapy cures local cancer by repeatedly targeting a tumour with small doses of radiation in 'fractions'. Though healthy tissues are irradiated, image assisted pre-treatment planning keeps this to a minimum. CT scans allow the body surface, tumour and critical organs to be seen to scale, so that the optimum shapes and directions of a set of radiation beams can be calculated. These are used daily in a treatment regime that may last weeks. The corresponding dose distribution is estimated and radiobiology can be used to predict the probabilities of cure and complications. How a patient will move or change during treatment itself, is unknown. Hence, an expert specifies a tolerance margin around the tumour and assumes everything else will stay as seen in the pre-treatment CT scan. On this simplified basis the patient is positioned on each day of the treatment.When treatment is in progress, and radiation is being directed at the tumour, there is no monitoring of the patient's position or internal anatomy. Hence, a precisely planned treatment is delivered in a manner that is effectively blind. This situation persists, despite complex new treatments and image guided radiotherapy (IGRT) that now includes 'cone beam' imaging (CBI), which the investigators helped to develop. IGRT radiation dose and CBI practical limitations are new causes for concern. MEGURATH introduces metrology guided radiotherapy (MGRT), where the patient is measured, imaged and modelled during treatment delivery. It researches non-invasive, radiation-free, real-time 3D patient positional monitoring based on optoelectronic sensors using structured light to map the body surface. A prototype system, with unrivalled performance, has been successfully piloted by the investigators in the treatment room. This will be developed to include radical concepts of multi-colour, adaptive sensing, where the structured light projected onto the body surface is first pre-adapted to the shape information available in patient's CT planning scan and then refined during use. The MEGURATH sensors will be synchronised with novel low radiation dose CBI based on acquiring images of the patient between treatment beams. This approach has been piloted by the investigators along with an innovative CBI collimator design that has the potential to halve patient dose, yet improve contrast in the reconstructed volume image. In a feedback loop, the CBI will then be optimally corrected for measured motion that is not necessarily periodic. Reconstructive imaging will then be combined with dynamic deformation modelling, to quantify changes in the shapes and positions of the tumour and nearby organs. Pilot work using sensor measurements to deform treatment plans has been reported by the investigators. Extending this approach across the irradiated part of the body will make it possible to describe the shape changes that occurred in the patient during irradiation. This will be the first time that a point by point model of the patient during treatment has been constructed from live measurements. In turn, this will finally make it possible to use radiobiology to calculate the probabilities of tumour cure and complications for the treatment actually delivered, and to compare this with the treatment that was planned.MEGURATH has strong, diverse theoretical components. It also has an ambitious programme for the translation of science and technology into the first purpose built IGRT research facility in the UK. It is materially supported by the manufacturers of IGRT and treatment planning equipment. Hence, it offers a unique opportunity to advance clinical practice beyond IGRT to MGRT and to use the skills of scientists, mathematicians and clinicians to address cancer treatment at some of the most significant and mobile disease sites, not least breast, lung and pelvis.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D077540/1","grantId":"EP/D077540/1","fundValue":"325753","fundStart":"2007-01-16","fundEnd":"2010-04-15","funder":"EPSRC","impactText":"  The particularly novel contributions this research has made are in developing new algorithms for segmentation, volume registration, surface modelling, and object tracking. The original algorithms developed for organ segmentation include: a new hybrid algorithm implemented in the level set framework; segmentation with imposed topological constraints; interactive organ delineation utilising combinatorial optimisation; segmentation with learned prior shape constraints. The original algorithms developed for registration include: a flexible particle registration technique and various novel diffeomorphic registration approaches. Another important contribution includes marker tracking and CBCT motion corrected reconstruction. A number of the corresponding software tools, implementing these algorithms, have been made publically available. One measure of the impact the research has made is the high number of the software downloads. Another example of the impact the research has made is that many of the algorithms developed during the research have been successfully used for other medical and biomedical applications including segmentation and deformation estimation of myocardium in tagged MR images, segmentation of extraocular muscles and facial articulation recognition, thus proving their generality and flexibility. Digital/Communication/Information Technologies (including Software),Healthcare Economic","person":"Bogdan Jozef Matuszewski","coPersons":["Lik-Kwan  Shark"],"organisation":"University of Central Lancashire","findingsText":" Radiation therapy exploits the extra susceptibility of many cancers to repeated assault by radiation when compared to healthy tissues. The radiation beams are applied sequentially to a target volume from several different directions. The treatments are commonly divided into daily fractions, delivered over several weeks. Though healthy tissues are also irradiated, image assisted pre-treatment planning keeps this to a minimum. CT scans allow the body surface, tumour and critical organs to be seen to scale, so that the optimum shapes and directions of a set of radiation beams can be calculated. These are used daily in a treatment regime that may last weeks. The corresponding dose distribution is estimated and radiobiology is used to predict the probabilities of cure and complications. How a patient will move or change during treatment itself is unknown. Hence, an expert specifies a tolerance margin around the tumour and assumes all other tissues will stay as seen in the pre-treatment CT scan. On this simplified basis the patient is positioned on each day of the treatment.\n\nPrior to Megurath, when treatment was in progress and radiation directed at the tumour, no monitoring was conducted of the patient's position or internal anatomy. Hence, a precisely planned treatment was delivered in a manner that was effectively blind.\n\nMegurath pioneered metrology guided radiotherapy (MGRT), where the patient is measured, imaged and modelled during treatment delivery. It successfully introduced data from a non-invasive, radiation-free, real-time surface sensor employed for 3D patient positional monitoring and deformation measurement into the treatment room. Together the X-ray and optical modalities have produced spatially and temporally corresponding dynamic measurements of internal anatomy, body surface and skin features during irradiation, enabling estimation of the target tissues deformation and determination of the impact this deformation has on planned versus delivered radiation dose.\n\nMegurath was a three stream project with three partners each delivering specific aspects of the work. Each partner held a separate grant under a common case of support and work programme. The primary contribution of this grant, was the development of novel medical image analysis methods providing support for clinical objectives of the project. Megurath image analysis software consists of a number of advanced tools for noise removal, feature detection, correspondence search, tracking, segmentation, registration and surface manipulation. \n\nParticularly important novel results have been obtained for tumour/organ segmentation with imposed shape and topological constraints; fast interactive organ delineation; flexible registration techniques enabling prediction of tissues deformation from measured organ surface deformations; segmentation and registration utilising statistical models; robust markers tracking in sequence of CT images; model-base surface registration enabling also efficient surface categorisation. These algorithms have been described in various publications and disseminated nationally and internationally.\n\nMany of the algorithms developed in this work have been successfully used for other medical and biomedical applications including segmentation and deformation estimation of myocardium in tagged MR images, segmentation of extraocular muscles and facial articulation recognition, thus proving their generality and flexibility.\n\nConsiderable cross-disciplinary follow-on work was funded from the EPSRC Cross-Disciplinary Feasibility Account programme Many of the image processing algorithms developed during this research project have been successfully used for other medical and biomedical applications, including: segmentation and deformation estimation of myocardium in tagged MR images, segmentation of extraocular muscles, segmentation of cellular structures or face and facial articulation recognition, thus demonstrating their generality and flexibility. It is also expected that the proposed methodologies will be used in a wide spectrum of other applications, beyond the medical image processing domain. This is evident from a broad spectrum of applications for which the hybrid level set segmentation algorithm (developed on the project) is used by the research community. Additionally the findings of this project were instrumental for outlining the work for the EPSRC funded ECSON and TeRaFS projects. One of the aspects of the project has focussed on efficient surface measurements and analysis. These results can have possible implications for the novel ways of surface sensing with numerous possible applications, e.g. in interactive video games. Indeed such ideas have been at the origin of the recently awarded FP7 funded SEMEOTICONS project. Digital/Communication/Information Technologies (including Software),Healthcare","dataset":"gtr"}