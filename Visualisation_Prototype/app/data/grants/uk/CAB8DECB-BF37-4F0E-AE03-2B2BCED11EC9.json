{"id":"CAB8DECB-BF37-4F0E-AE03-2B2BCED11EC9","title":"Word segmentation from noisy data with minimal supervision","abstractText":"In recent years, the field of natural language processing (NLP) has made great advances in a wide range of areas, such as machine translation, document summarization, and topic identification. However, much of this success is due to systems that are built using large quantities of human-annotated data in a supervised machine learning approach. This means that languages with fewer annotated resources (low-density languages) are left without much useful language technology. An important direction in NLP research is therefore to improve our ability to develop successful systems using as little annotated data as possible. Research on completely unsupervised systems is particularly interesting not only for its potential to broaden the reach of NLP technology, but also because it may shed light on the ways in which human infants manage to learn language with little or no explicit instruction.We propose to focus on the particular problem of word segmentation, and to develop a new type of probabilistic model, the infinite noisy channel model, for solving this problem in settings where little or no annotated data is available. Word segmentation refers to the problem of identifying word boundaries in either text or speech. It arises in NLP systems for many Asian languages, where words are not separated by whitespace, and also for infants learning language, because most spoken words are not separated by pauses. Previous work on unsupervised word segmentation has assumed that every time a particular word occurs, it is realized in exactly the same way. However, this is not the case for infants learning language (since words are subject to phonetic variability and noise in pronunciation), nor is it always true in NLP (if the input text contains errors, such as those produced by an optical character recognition system). Our new model will address this shortcoming by simultaneously performing word segmentation and correction of noise and variability, to recover a sequence of de-noised words from the unsegmented noisy input. We plan to develop two different versions of our model. One of these will be designed to correct for phonetic variability, and will be evaluated as a cognitive model of human language acquisition. With this model, we hope to gain insight into the computational mechanisms that allow infants to successfully extract words from noisy input, and in particular to show that the Bayesian inference techniques used in our model are a plausible explanation of infants' learning behavior. The second version of our model will be designed to correct for errors resulting from optical character recognition, and will be evaluated as a word segmentation and error-correcting NLP application in several different languages. We hope to show that the model reduces the number of character errors in the document while also producing successful segmentations. We expect these improvements to be particularly pronounced in low-density language situations.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/H050442/1","grantId":"EP/H050442/1","fundValue":"281783","fundStart":"2011-01-24","fundEnd":"2014-04-23","funder":"EPSRC","impactText":"  To date, the findings have been used by other researchers in low-resource speech technology to develop better methods for addressing this task. They have also been used by language acquisition researchers to inform further work (both computational and behavioural) aimed at understanding the fundamental processes of early language acquisition in infants.  ","person":"Sharon  Goldwater","coPersons":[],"organisation":"University of Edinburgh","findingsText":" We have developed a model of early language acquisition in infants, when infants are learning to segment the speech stream into individual words. Unlike previous models, our new model integrates the segmentation process with the process of learning about phonetic variability. The performance of this model more closely matches what we know about infant segmentation than do previous models, providing evidence that, like our model, infants are learning about segmentation and phonetic processes simultaneously. We have also investigated the effects of non-linguistic contextual information on the word learning process, showing that this kind of information can be helpful for phonetic learning even if the learner does not have detailed knowledge of word meanings. Some of our early results were used as inspiration for work developed during and following the 2012 JHU CLSP Workshop on Zero-Resouce Speech Technologies and Models of Early Language Acquisition, a two-week hands-on workshop attended by around 25 researchers, which has led to several publications and ongoing collaborations. We expect that our more recent work on contextual information in phonetic learning will inspire follow-on behavioral experiments to test our hypotheses regarding early word representations and contextual information. Digital/Communication/Information Technologies (including Software),Education,Healthcare","dataset":"gtr"}