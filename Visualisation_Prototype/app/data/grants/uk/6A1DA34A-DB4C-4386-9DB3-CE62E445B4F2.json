{"id":"6A1DA34A-DB4C-4386-9DB3-CE62E445B4F2","title":"Speech Animation using Dynamic Visemes","abstractText":"This project will investigate new methods for automatically producing speech animation. For animators in the movie industry this is typically a tedious, iterative process that involves key-framing static lip-poses and then handcrafting a blending function to transition from one key pose to another. In is not uncommon for an animator to spend several hours producing animation for just a few seconds of speech. \n\nWe have previously worked on identifying a new dynamic unit for speech animation, termed dynamic visemes, and have shown that these units produce better animation than more traditional phoneme-based units. In this project we will integrate dynamic visemes into state of the art approaches to further improve upon the quality of automated animation that is currently possible. Furthermore, we will investigate how dynamic visemes relate to speech acoustics so that animation can be generated directly from the voice of an actor.\n\nWe will build tools that can be implemented in commercial animation pipelines so animation studios can use our tools as a basis for animating any speech on their own models. This will leave their artists free to focus on the overall performance of the character.\n\nThe proposed project is ambitious in its aims, proposing a new approaches for producing better speech animation. However, the impact of the work is wide reaching and has the potential to influence the production of speech content in all animated movies and computer games.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/M014053/1","grantId":"EP/M014053/1","fundValue":"343515","fundStart":"2015-07-22","fundEnd":"2018-07-21","funder":"EPSRC","impactText":"","person":"Ben  MilnerBarry-John  Theobald","coPersons":[],"organisation":"University of East Anglia","findingsText":"","dataset":"gtr"}