{"id":"3E91917B-2C3A-4995-BC42-47726EEB47CE","title":"Digital Wildfire: (Mis)information flows, propagation and responsible governance","abstractText":"The rapid growth of social media platforms such as Twitter has had a significant impact on the way people can connect and communicate instantaneously with others. The content that users put onto social media platforms can 'go viral' in minutes and that content, whether text, images or links to other sites, can have profound effects on events as they unfold. This can be both for the good or the bad. In times of disaster, tweeting about events can call people to help from around the globe. But people can also spread dubious and dangerous information, hate speech and rumours, via social media. This type of behaviour has been called &quot;digital wildfires&quot;. A World Economic Forum report indicates two situations in which digital wildfires are most dangerous: in situations of high tension, when false information or inaccurately presented imagery can cause damage before it is possible to correct it. The real-world equivalent is shouting &quot;fire!&quot; in a crowded theatre - even if it takes a moment for realisation to spread that there is no fire, in that time people may already have been crushed to death in the scramble for the exit. Another dangerous situation is when widely circulated information leads to 'groupthink' which may be resistant to attempts to correct it. These digital wildfires can seriously challenge the capacity of traditional media, civil society and government to report accurately and respond to events as they unfold. But how people communicate in these digital social spaces is not well understood; users may not fully understand how these spaces 'work' as channels of communication and so what constitutes appropriate and responsible behaviour may be unclear. The challenge then is to develop appropriate ways of governing these spaces and how to apply and use them responsibly.\n \nThis project will attempt to address this challenge by framing the study in a programme of work known as Responsible Innovation in ICT and by developing a methodology for the study and advancement of the responsible governance of social media. A key question is to what extent do people in these spaces 'self-regulate' their behaviour? If this is evident then there is a case for exploring how self-correction mechanisms may be amplified so that false rumours are identified more quickly. The legitimacy of new governance mechanisms may be enhanced if they respect and build on such existing self-governance techniques.\n \nDrawing on a range of methods we will examine how social media are used, how people consume information they find there and what roles they play in its production; how (mis)information flows as they spread in real-time. We will draw on a selection of case studies of rumour and hate speech sourced from our recent and on-going research in social media. From the analyses we will produce a digital tool to detect and visualise rumour, misinformation and antagonistic content and how this relates to self-regulative behaviour such as counter speech, dispelling of rumours and verification practices, so that people are able to make better-informed decisions on how to manage emerging situations in response to real-world events. We will also conduct fieldwork at various sites (police, social media platforms, Google, civil rights organisations, news media) to investigate how stakeholders respond to challenges presented by events where misinformation, rumour and antagonistic content via social media may be a concern, for example, during sporting events, civil disturbance and electoral campaigns. From our analyses the project will develop an ethical security map for the practices of governing the use of social media. We will complement this ethical security map with a range of outputs for broader impact such as, engaging with secondary schools, where we will develop a reflection and training module on digital wildfire for young people - one of the largest age groups actively using social media and also a relatively vulnerable social group.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/L013398/1","grantId":"ES/L013398/1","fundValue":"198753","fundStart":"2014-11-18","fundEnd":"2016-11-17","funder":"ESRC","impactText":"","person":"Marina Denise Anne  Jirotka","coPersons":["Matthew Leighton Williams","Adam Michael Edwards","William  Housley","Omer  Rana","Bernd Carsten Stahl","Peter  Burnap","Rob  Procter"],"organisation":"University of Oxford","findingsText":"","dataset":"gtr"}