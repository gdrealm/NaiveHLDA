{"id":"18EC19C4-98AE-4A9E-AB79-4C01E64F85A8","title":"Embodied Language Production","abstractText":"We use language to record, preserve and communicate about events, (e.g., reporting a kicking event by saying &quot;A waitress kicks a clown&quot;). But how do speakers encode an event into speech sounds? To do so, speakers need to start from a message and then find words for the message and arrange them into a sentence. However, how speakers construct a message out of, e.g., seeing an event, rarely has been empirically addressed. A standard view assumes that message construction mainly concerns searching concepts in long-term memory for event participants (e.g., CLOWN, WAITRESS) and their relation (e.g., KICK). One problem with this account of language production is that the message is devoid of the rich perceptual, motor and affective (i.e., sensorimotor) content we perceive of an event. For example, the perception of the kicking event above offers the visual imagery of a waitress, a clown and the act of kicking. It has been shown that when people *comprehend* a sentence describing an event, they mentally replay or simulate the sensorimotor content implied in the event, but it yet remains to be explored whether similar sensorimotor simulation is used when they *produce* a sentence to describe an event.\n We propose that in language production, speakers use the sensorimotor content to mentally simulate or replay an event they want to speak about. Since sensorimotor content is perspective-specific (e.g., the sensorimotor experience of a kicking event is different for the kicker and the kickee), we hypothesise that speakers prefer to take the perspective of a more similar event participant and to choose a grammatical structure (e.g., active vs. passive) in which the perspective participant is realised as the subject of the sentence. Such an account explains the general finding across languages that speakers tend to use a more human/animate concept as the subject of a sentence (e.g., &quot;A clown is hit by a stone&quot; rather than &quot;A stone hits a clown&quot;).\n The proposal presents the first attempt to explore language production in terms of embodied cognition (i.e., cognition as mental simulation of sensorimotor content). We examine whether speakers employ perspective-specific sensorimotor simulation in constructing a message out of an event and whether sensorimotor simulation in the message affects the subsequent choice of grammar. In the first series of studies, we ask speakers to describe a picture (e.g., &quot;The waitress passes the clown a ball&quot;) while tracking their computer mouse trajectories as a measure of whether they mentally simulate the movement in an event while speaking. In the second series of studies, we aim to explore whether different perspectives of the same event (e.g., a waitress kicking a clown) result in different sensorimotor simulations (let/foot movement from the waitress' perspective but pain from the clown's perspective) by recording speakers' electrophysiological activities. In the third series of studies, we investigate whether speakers tend to take the perspective of an event participant that is more similar to them in gender or emotion and realise that participant as the subject of the sentence (e.g., &quot;The clown is kicked by the waitress&quot; by male speakers). We aim to achieve two main objectives via these studies. Theoretically, the project presents an empirical investigation of conceptualisation, an important but rarely investigated area, and will provide a new perspective (embodied cognition) on language production. Methodologically, we will develop novel paradigms for investigating experienced-based knowledge/thoughts and how they drive symbolic behaviours (e.g., sentences).\n Through the project, I aim to develop my skills in theoretical construction in language and cognitive sciences, in using of neuroscientific research methods to study language and cognition, and in using computational models to implement my theoretical proposals.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=ES/L010224/1","grantId":"ES/L010224/1","fundValue":"149161","fundStart":"2015-03-01","fundEnd":"2016-03-23","funder":"ESRC","impactText":"","person":"Zhenguang  Cai","coPersons":[],"organisation":"University College London","findingsText":"","dataset":"gtr"}