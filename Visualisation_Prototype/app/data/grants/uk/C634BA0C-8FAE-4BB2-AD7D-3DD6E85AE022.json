{"id":"C634BA0C-8FAE-4BB2-AD7D-3DD6E85AE022","title":"Tensorial modeling of dynamical systems for gait and activity recognition","abstractText":"Biometrics such as face, iris, or fingerprint recognition have received growing attention in the last decade, as automatic identification systems for surveillance and security have started to enjoy widespread diffusion. They suffer, however, from two major limitations: they cannot be used at a distance, and require user cooperation, assumptions impractical in real-world scenarios. Interestingly, psychological studies show that people are capable of recognizing their friends just from the way they walk, even when their gait is poorly represented by point light display. Gait has several advantages over other biometrics, as it can be measured at a distance, is difficult to disguise or occlude, can be identified even in low-resolution images, and is non-cooperative in nature. Furthermore, gait and face biometrics can be easily integrated for human identity recognition.Despite its attractive features, though, gait identification is still far from being ready to be deployed in practice. What limits its adoption in real-world scenarios is the influence of a large number of nuisance factors which affect appearance and dynamics of the gait. These include, for instance: walking surface, lighting, camera setup (viewpoint), but also footwear and clothing, objects carried, time of execution, walking speed. Similar issues are shared by other applications of motion classification, such as action and activity recognition. Multilinear or tensorial models, in which a number of (nuisance) factors linearly mix to generate what we observe (in our case the walking gait), have been proven in the recent past to be able to describe the influence of such factors, for instance in the context of face recognition. However, video sequences are more complex objects than single images. We first need to represent video footages in a compact way.Encoding the dynamics of videos by means of some sort of dynamical model has been proven effective in both action recognition and gait identification, in situations in which the dynamics is critically discriminative. Besides, the actions of interest have to be temporally segmented from a video sequence, while actions of sometimes very different lengths might have to be compared. Dynamical representations are very effective in coping with temporal detection and compression, and indeed several researchers have explored the idea of encoding motions via linear, nonlinear, stochastic or chaotic dynamical systems.In this project, therefore, we propose to develop a novel, general framework for the classification of video sequences (with a focus on the walking gait), based on the application of tensorial decomposition techniques to image sequences represented as realizations of suitable dynamical models.The proposed framework will allow us to deal with the issue of the nuisance factors which greatly affect identification from gait and activity recognition in a principled way. The main goal is to push towards a more widespread diffusion of gait ID, as a concrete contribution to enhancing the security levels in the country in the current, uncertain scenarios. With their implications for crime prevention and security, biometrics and surveillance are fast growing business areas, a fact reflected by the increasing number of government-sponsored initiatives in the area in most advanced economies. In addition, the techniques devised in this proposal are extendable to action and identity recognition with immense commercial exploitation potential, ranging from content-based video retrieval from repositories such as YouTube, to HMI, to interactive video games, etcetera.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/I018719/1","grantId":"EP/I018719/1","fundValue":"98363","fundStart":"2011-06-30","fundEnd":"2014-01-11","funder":"EPSRC","impactText":"  Our findings have been the basis for follow up research in a number of application scenarios: action recognition in the wild, EEG emotion classification for the design of robotic avatars, pedestrian behavior analysis and driver's monitoring in the automotive industry, the early diagnosis of dementia via machine learning in the healthcare context.  Societal,Economic","person":"Fabio  Cuzzolin","coPersons":[],"organisation":"Oxford Brookes University","findingsText":" The project is exploring different routes to the computer analysis of human motion captured by traditional cameras. In particular, we are interested in testing the possibility of recognizing people's identities at a distance, from the way the walk, or from their gesturing style. The problem is made extremely difficult by the presence of numerous factors which affect recognition, such as different camera viewpoints, illumination conditions, clothing. We have also explored the use of new modeling techniques to automatically learn, represent and recognize complex human activities as those captured by videos stored on YouTube and elsewhere. In the first step crucial information needs to be extracted from these videos. Based on those measurements, the system automatically learn which parts of the video are the most &quot;discriminative&quot; (relevant for recognition purposes) and assembles them in a coherent hierarchy able to describe complex activities, or the presence of multiple actors.\n\nWe have obtain significant preliminary results which show that, via these new modelling techniques, recognition rates considerable improve over the current state of the art. Most significantly, we can also localize the presence of an action in space and time within a given video sequence. The societal impact and market potential of reliable automatic action recognition is enormous. Human-machine interfaces allowing humans to gesturally interact with their laptops, smartphones and even cars are being envisaged right now. ABI Research forecast that 600 million smartphones with gesture recognition features will be shipped in 2017 (http://blog.geoactivegroup.com/2012/07/new-applications-for-gesture.html). EyeSight (http://www.eyesight-tech.com/) already produces software solutions that &quot;allow users to control mobile and portable devices with simple hand gestures&quot;. Smart rooms are being imagined, in which people are assisted in their everyday activities by distributed intelligence in their own homes (switching lights when they move through the rooms, interpreting their gestures to replace remote controls and switches, etcetera). At the Consumer Electronics Show in Las Vegas in January, Mercedes-Benz showed an experimental system (DICE) which lets drivers perform basic functions with a hand gesture. Given our rapidly ageing population, semiautomatic assistance to non-autonomous elderly people and remote clinical monitoring are rapidly gaining interest. A hand-gesture recognition system that enables doctors to manipulate digital images during medical procedures has recently been tested at the Washington Hospital (www.whcenter.org). Security personnel can be assisted by algorithms able to signal anomalous events to their attention for surveillance purposes, improving the general level of security of the European Union (and of senstive areas such as airports or train stations in particular) in uncertain times such as ours. In the US, DARPA's Video and Image Retrieval and Analysis Tool (VIRAT) and Persistent Stare Exploitation and Analysis System (PerSEAS) programs may soon enable better warfighter analysis of huge amounts of data generated from multiple types of sensors. Companies are investing in &quot;behavioral&quot; biometrics, based on people's distinctive gait pattern, to\n\nachieve a significant competitive edge. Finally, techniques able to efficiently datamine the thousands of videos people post, say, on Facebook or YouTube are in dire need: the potential of a &quot;drag and drop&quot; application, similar to that set up by Google for images, able to retrieve videos with a same &quot;semantic&quot; content is easy to imagine. All these companies are investing huge money on internet video retrieval as the\n\nnext level in the browsing experience. Truly robust action recognition is likely to contribute enormously (via significant gains in productivity) to boost all these economic sectors in the near future. A number of routes are open for the exploitation of the results of this project.\n\nNew consoles (e.g. Microsoft's Kinect) have opened up novel directions in the gaming industry: yet, these only track the user's movements, without any real interpretation of their actions which could &quot;spice up&quot; the gaming experience. Intelligent action recognition can render games which merely track the user's body posture out of fashion: however, gesture recognition with kinect is still in its infancy (http://www.youtube.com/watch?v=H1wIQ2o4INo). We are exploring the possibility of a collaboration with Sony Entertainment (which has a successful history of KTP project with our group) along these lines. \n\nWe have had a series of promising meetings with Magna International (http://www.magna.com/), the car component company, for a collaboration on pedestrian behavior interpretation in low speed (e.g. parking lot) scenarios, and on driver's gesture recognition inside the car.\n\nTogether with Professor Helen Dawes we are also exploring the possibility of using gesture recognition techniques to monitor patients' disease progression from their homes via the analysis of the quality of their exercises, labelled according to standard clinical scales such as SARA (http://cms.brookes.ac.uk/staff/FabioCuzzolin/grants/i4i.pdf).\n\nThe results of this project have led to spin off grant applications to the Leverhulme Trust (http://cms.brookes.ac.uk/staff/FabioCuzzolin/grants/leverhulme12video-outline.pdf), NIHR (see above) and the European Union (via an ERC Consolidator grant).\n\nFinally (but the list is not exhaustive), we are considering a new EPSRC application on brain wave remote control based on the tensorial/multilinear analysis developed in this project for identity recognition from gait, as they can be very effective for the classification of EEG signals as well. Digital/Communication/Information Technologies (including Software),Healthcare,Manufacturing, including Industrial Biotechology,Security and Diplomacy","dataset":"gtr"}