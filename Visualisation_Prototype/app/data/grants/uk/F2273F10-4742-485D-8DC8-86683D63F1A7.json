{"id":"F2273F10-4742-485D-8DC8-86683D63F1A7","title":"Study of regularisation methods in machine learning","abstractText":"Over the past decade the availability of powerful computers has opened the doors to the use of machine learning techniques in complex application domains such as those arising in computer vision, speech recognition, computational linguistics, marketing science, and bioinformatics, to mention but a few.A central approach in machine learning which has proved valuable in the above domains consists in computing a function from available data by minimising a regularisation error functional which balances different error/penalty criteria. For example, the regularisation error functional may involves the combination of a data term, measuring the empirical error on the data and a penalty term measuring the function complexity. The goal of this visit, during the period of January--June 2006, is to continue to explore both the theoretical and practical implications of the regularisation approach in machine learning as well as produce a first draft of a book on this topic. Prof. Micchelli shares a strong interest with Dr. Pontil in machine learning and the proposed visit will be the first opportunity for them to work together for an extensive period of time.Prof. Micchelli ranks high among the world leaders in computational mathematics. He has made fundamental contributions to that field, especially to problems concerning approximation, representation and estimation of functions. His work has been influential not only in mainstream mathematics but also in nearby fields, particularly in statistics and computer science. He is in the recent ISI list of 200 mathematicians world-wide who are most highly cited.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D052807/1","grantId":"EP/D052807/1","fundValue":"10886","fundStart":"2006-03-01","fundEnd":"2007-03-31","funder":"EPSRC","impactText":"","person":"Massimiliano  Pontil","coPersons":[],"organisation":"University College London","findingsText":" New properties of certain machine learning algorithms based on the minimisation of regularisation functions. \n\nAmong other results, we derive a necessary and sufficient condition for the validity of the Representer Theorem (RT) in machine learning. The RT is a cornerstone result in machine learning which has been applied widely in the field. Previous work provided only a sufficient condition for the\nvalidity of the RT. In this work we prove that this condition is also necessary. This has important consequences on the applicability of the RT to machine learning algorithms. Furthermore, we propose a more general form of the RT which applies to matrix learning problems. Rigour: our\nanalysis is based on advance tools from linear algebra and it requires some non-trivial technical lemmas which are of independent Several researchers working on machine learning have followed up our work. Education","dataset":"gtr"}