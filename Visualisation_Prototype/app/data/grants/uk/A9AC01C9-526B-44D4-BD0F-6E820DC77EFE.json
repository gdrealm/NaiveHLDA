{"id":"A9AC01C9-526B-44D4-BD0F-6E820DC77EFE","title":"Multi-modal object tracking in a network of audiovisual sensors","abstractText":"The aim of this project is to develop a unified scheme cooperative multi-modal and multi-sensor tracking. The multi-sensor network will be composed of stereo microphones coupled with omni-directional and with pan-tilt-zoom cameras. Sound information will be used to discriminate ambiguous visual observations as well as to extend the coverage area of the sensors beyond the field of view of the cameras. Although single modality as well as multi-modality trackers have achieved some success, a number of important tracking issues remain open for enabling the adoption of these algorithms in real-world scenarios. Among these issues, three important inter-related problems will be addressed in this project, namely the definition of a generic and flexible feature representation for a target, a reliable mechanism to update the target model based on incoming observations, and a robust multi-sensor handover strategy. First, we will develop a robust and adaptive representation of objects based on their acoustical and visual attributes while moving across the network of heterogeneous sensors. Next, object models will be defined based on the observation that temporal representation of a target is expected to lie in a low-dimensional manifold in the high-dimensional multi-modal feature space. Finally, the object model will be used to control and guide the evolution of the target state in order to help intra-sensor occlusion handling and inter-sensor handover. To evaluate the tracking scheme, we will create a test corpus and its associated ground-truth data for use in the project as well as for distribution to the research community to facilitate comparisons.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/D033772/1","grantId":"EP/D033772/1","fundValue":"125526","fundStart":"2006-08-01","fundEnd":"2008-07-31","funder":"EPSRC","impactText":"","person":"Andrea  Cavallaro","coPersons":[],"organisation":"Queen Mary, University of London","findingsText":"","dataset":"gtr"}