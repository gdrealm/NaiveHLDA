{"id":"FED8BF3F-3B6B-4526-8C21-4BD05E3A027B","title":"Feasibility study - The coloured brain: a photorealistic virtual model of living brain tissue","abstractText":"Although cadaver dissection is widely accepted as being the 'gold standard' for anatomy education, its availability and usage is decreasing due to financial and ethical pressures. Even for those with access to cadaveric-based training, they find that the differences between the colour and appearance of living tissues that may be observed in the operating theatre are vastly different from what they first observed with the dead tissues of a cadaver. Their anatomy knowledge must therefore adapt to the reality of their working environment. Digital anatomy tools can provide a partial alternative to cadavaric-based training. One of the limitations here, however, is that grey scale or pseudo colour are typically used when rendering the anatomy as 3D models. Although we can attempt to use colours that more closely match that of real tissues, or maybe a texture map, it is difficult to reproduce an exact match of the colours and shading of living tissues. In computer graphics a technique that can be used for photorealistic rendering is to apply a bidirectional reflectance distribution function (BRDF), which is a 4-dimensional function that defines how light is reflected at an opaque surface. BDRFs have not yet been extensively applied to digital anatomy models.The aim of this feasibility study is to develop and pilot techniques that will allow us to significantly improve the quality of virtual anatomy teaching tools by incorporating the appearance of live tissues. It will bring together the research expertise in computer modelling and material capture as well as access to operating theatre and teaching forum. We propose to combine the knowledge and technological achievements of two labs to realise this unusual collaboration: Marina Bloj is a colour scientist with a background in physics; Nigel John is an established expert with over 15 years experience in medical virtual environments and data visualisation. This collaborative project will allow us to integrate techniques from these two groups for the first time and establish the platform for future extended collaborative projects.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/G055246/1","grantId":"EP/G055246/1","fundValue":"20084","fundStart":"2009-10-01","fundEnd":"2010-02-28","funder":"EPSRC","impactText":"  The realistic rendering technique has been used for some of the surgical simulators that we continue to develop at Bangor University Education,Healthcare Societal","person":"Nigel W John","coPersons":[],"organisation":"Bangor University","findingsText":" From calibrated photography of exposed brain tissue and suitable alternatives,experiments provided data for a bidirectional reflectance distribution function, which was then used for rendering. Employing a GPU, real-time visualization of the brain's surface supported ambient occlusion, advanced texturing, subsurface scattering, and specularity. The technique can be used in any software that is rendering anatomy models. Digital/Communication/Information Technologies (including Software),Education,Healthcare","dataset":"gtr"}