{"id":"601D1FE7-B889-4DCA-8C38-A1A3F60FD6B1","title":"New pathways to hearing: A multisensory noise reducing and palate based sensory substitution device for speech perception","abstractText":"Disabling hearing loss is a global problem that affects nearly half a billion people. Furthermore, it is a problem that is growing with an aging population and has clear negative functional, social, emotional, and economic impacts. In the United Kingdom, adult onset hearing loss is predicted to be one of the top ten disease burdens by 2030 (WHO). Commercially available correction for hearing loss is mostly limited to hearing aids and cochlear implants. These devices suffer from signal processing and sensory transduction limitations. On the signal processing side, they struggle with the separation of speech from noise, often from other voices in social situations - the cocktail party phenomenon. On the transduction side, devices continue to rely on the damaged cochlea as the channel of communication. The aim of this proposal is to address these limitations through multisensory remapping at both the signal processing and transduction stages. \nWe will address signal processing limitations by introducing a new multisensory algorithm that will aim to recover the auditory signal from talking faces. The moving face can provide a source of information that is independent of environmental noise. Facial movement can also be used to enhance the signal to noise ratio of audio-only based speech. The new method can also recover facial movement from auditory signals alone so that speech perception might continually benefit from known improvements associated with being able to see the face, even when it is not present, as when the recovered face is presented on a device carried by the listener (e.g. a smart phone or Google Glass). \nWe will address signal transduction limitations by building on recent successes in supplementing vision through high-density tactile stimulation of the tongue and previous work demonstrating promise for supplementing word learning through tactile stimulation. In particular, we will build a novel non-invasive conformable high-density electrode array that provides electrotactile stimulation of the hard palate. This is the first device with high enough channel density to realistically provide, in tactile form, the spatial information about sound frequency available along the healthy cochlea. By putting it on the hard palate, this device will be the first sensory supplementation device to have direct access to sensorimotor brain circuitry important for speech learning and perception through the trigeminal nerve. \nFinally, we will use behavioural and brain imaging methods to experimentally test the combined use of these signal processing and transduction innovations for hearing supplementation. From past experience with more primitive devices (e.g. The Tickle Talker), we expect people will be able to rapidly learn words and transfer training to novel words in new contexts. We expect training to be enhanced by combined presentation of audio to the hard palate and the face to a portable display device, so learning can occur in natural contexts. We will test the ability of participants to use the device for speech perception behaviourally and use functional imaging to look for indications of activation or modification of speech circuits in the brain after training. This work will contribute to our understanding of multisensory signal processing algorithms for hearing devices, auditory-to-tactile hearing supplementation, and multisensory brain plasticity. Success with this experimental device would warrant clinical trials to supplement hearing in individuals with hearing loss and bring these innovations to market as a new device to help with the social and economic challenges posed by disabling hearing loss.","grantUrl":"http://gtr.rcuk.ac.uk/projects?ref=EP/M026965/1","grantId":"EP/M026965/1","fundValue":"700744","fundStart":"2015-12-31","fundEnd":"2018-12-30","funder":"EPSRC","impactText":"","person":"Jeremy I Skipper","coPersons":["Martin  Sereno","Alan  Johnston"],"organisation":"University College London","findingsText":"","dataset":"gtr"}